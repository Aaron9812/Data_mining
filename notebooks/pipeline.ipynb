{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "from src.data.preprocessing import load_data, preprocess, train_tfidf, split_data, upsampling, get_features, setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires datasets library (use pip)\n",
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprossesed data\n",
    "df['preprocessed'] = preprocess(df['tweet'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get n_usermentions and get seperate hashtags\n",
    "df = get_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trained tfidf vectorizer\n",
    "tfidf = train_tfidf(df['preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data on specified column\n",
    "df_train , df_test = split_data(df, 'preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample data\n",
    "df_train_up = upsampling(df_train)\n",
    "df_train_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does all of the above (wip)\n",
    "tfidf, df_train, df_test = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There is {} training data, of which {}% is hate speech '.format(df_train['label'].count(), round(df_train['label'].sum()/df_train['label'].count()*100,2)))\n",
    "print('There is {} test data, of which {}% is hate speech '.format(df_test['label'].count(), round(df_test['label'].sum()/df_test['label'].count()*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "from src.models.Naive_Bayes import train_mvb_bayes, train_mn_bayes, test_model, get_impact_words\n",
    "from src.data.preprocessing import load_data, preprocess, train_tfidf, split_data, upsampling, get_features, setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mvb = pd.DataFrame(['precision', 'recall', 'accuracy', 'F1'])\n",
    "results_mn = pd.DataFrame(['precision', 'recall', 'accuracy', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: my in and for you a i the to user\n",
      "hate: in libtard to is of are you a the user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Don't Remove Stopwords, No Emojis, No Stemming, No Upsampling \n",
    "tfidf, df_train, df_test = setup(rem_stop=False, do_stem=False, do_lem=False, split=True, upsample=False, do_emojis=False)\n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['Only Tokenization'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['Only Tokenization'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: life im time u positive happy thankful day love user\n",
      "hate: liberal racist politics white black â¦ amp trump libtard user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, No Emojis, No Stemming, No Upsampling \n",
    "tfidf, df_train, df_test = setup(rem_stop=True, do_stem=False, do_lem=False, split=True, upsample=False, do_emojis=False)\n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['Remove Stopwords'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['Remove Stopwords'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: eyes heart happy positive thankful day love smiling face user\n",
      "hate: liberal racist politics white black … amp trump libtard user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, Emojis, No Stemming, No Upsampling \n",
    "tfidf, df_train, df_test = setup(rem_stop=True, do_stem=False, do_lem=False, split=True, upsample=False, do_emojis=True)\n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['Emojis'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['Emojis'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: eye heart posit happi thank love day smile face user\n",
      "hate: polit liber racist white … black amp trump libtard user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, Emojis, Stemming, No Upsampling \n",
    "tfidf, df_train, df_test = setup(rem_stop=True, do_stem=True, do_lem=False, split=True, upsample=False, do_emojis=True)\n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['Stemming'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['Stemming'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 495.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: eye heart posit happi thank love day smile face user\n",
      "hate: polit racist liber white … black amp trump libtard user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, Emojis, Stemming, Upsampling \n",
    "tfidf, df_train, df_test = setup(rem_stop=True, do_stem=True, do_lem=False, split=True, upsample=True, do_emojis=True)\n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['Upsampling'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['Upsampling'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 494.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: eyes heart happy positive thankful day love smiling face user\n",
      "hate: liberal racist politics white black … amp trump libtard user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, Emojis, No Stemming, Upsampling \n",
    "tfidf, df_train, df_test = setup(rem_stop=True, do_stem=False, do_lem=False, split=True, upsample=True, do_emojis=True) \n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['All_but_stemming'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['All_but_stemming'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 502.07it/s]\n",
      "c:\\Users\\jonas\\OneDrive - bwedu\\Studium_Master\\1_FSS_2022\\Data Mining [IE 500]\\Projekt\\Code\\Git\\Data_mining\\src\\data\\preprocessing.py:118: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  return pd.Series(nltk.word_tokenize(text.lower()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: im eyes heart happy positive thankful day love smiling face\n",
      "hate: like liberal racist politics white black … amp trump libtard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, Emojis, No Stemming, Upsampling, No user string\n",
    "tfidf, df_train, df_test = setup(rem_stop=True, do_stem=False, do_lem=False, split=True, upsample=True, do_emojis=True, no_user=True) \n",
    "mvb = train_mvb_bayes(df_train, tfidf)\n",
    "mn = train_mn_bayes(df_train, tfidf)\n",
    "results_mvb['no_user'] = test_model(mvb, df_test, tfidf)\n",
    "results_mn['no_user'] = test_model(mn, df_test, tfidf)\n",
    "get_impact_words(df_train, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 973.16it/s]\n",
      "c:\\Users\\jonas\\OneDrive - bwedu\\Studium_Master\\1_FSS_2022\\Data Mining [IE 500]\\Projekt\\Code\\Git\\Data_mining\\src\\data\\preprocessing.py:118: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  return pd.Series(nltk.word_tokenize(text.lower()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_hate: im u amp happy eyes heart day love smiling face\n",
      "hate: people politics racist white black like libtard … trump amp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords, Emojis, No Stemming, Upsampling, No user string, Countvectorizer\n",
    "count, df_train, df_test = setup(rem_stop=True, do_stem=False, do_lem=False, split=True, upsample=True, do_emojis=True, no_user=True, vectorizer='count') \n",
    "mvb = train_mvb_bayes(df_train, count)\n",
    "mn = train_mn_bayes(df_train, count)\n",
    "results_mvb['count_vec'] = test_model(mvb, df_test, count)\n",
    "results_mn['count_vec'] = test_model(mn, df_test, count)\n",
    "get_impact_words(df_train, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Only Tokenization</th>\n",
       "      <th>Remove Stopwords</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>Upsampling</th>\n",
       "      <th>All_but_stemming</th>\n",
       "      <th>no_user</th>\n",
       "      <th>count_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.961326</td>\n",
       "      <td>0.511737</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.559292</td>\n",
       "      <td>0.546689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.377232</td>\n",
       "      <td>0.368304</td>\n",
       "      <td>0.388393</td>\n",
       "      <td>0.388393</td>\n",
       "      <td>0.729911</td>\n",
       "      <td>0.709821</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.956359</td>\n",
       "      <td>0.956046</td>\n",
       "      <td>0.932270</td>\n",
       "      <td>0.938214</td>\n",
       "      <td>0.940404</td>\n",
       "      <td>0.938527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.542536</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.553259</td>\n",
       "      <td>0.601656</td>\n",
       "      <td>0.616877</td>\n",
       "      <td>0.623889</td>\n",
       "      <td>0.621022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  Only Tokenization  Remove Stopwords    Emojis  Stemming  \\\n",
       "0  precision           0.965714          0.988024  0.972067  0.961326   \n",
       "1     recall           0.377232          0.368304  0.388393  0.388393   \n",
       "2   accuracy           0.955420          0.955420  0.956359  0.956046   \n",
       "3         F1           0.542536          0.536585  0.555024  0.553259   \n",
       "\n",
       "   Upsampling  All_but_stemming   no_user  count_vec  \n",
       "0    0.511737          0.545455  0.559292   0.546689  \n",
       "1    0.729911          0.709821  0.705357   0.718750  \n",
       "2    0.932270          0.938214  0.940404   0.938527  \n",
       "3    0.601656          0.616877  0.623889   0.621022  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mn.to_csv(\"C:/Users/jonas/OneDrive - bwedu/Studium_Master/1_FSS_2022/Data Mining [IE 500]/Projekt/esults_mn.csv\", sep=';', decimal=',')\n",
    "results_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Only Tokenization</th>\n",
       "      <th>Remove Stopwords</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>Upsampling</th>\n",
       "      <th>All_but_stemming</th>\n",
       "      <th>no_user</th>\n",
       "      <th>count_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.536379</td>\n",
       "      <td>0.537288</td>\n",
       "      <td>0.537288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.368304</td>\n",
       "      <td>0.350446</td>\n",
       "      <td>0.395089</td>\n",
       "      <td>0.352679</td>\n",
       "      <td>0.747768</td>\n",
       "      <td>0.707589</td>\n",
       "      <td>0.707589</td>\n",
       "      <td>0.707589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.953387</td>\n",
       "      <td>0.952761</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>0.952917</td>\n",
       "      <td>0.931488</td>\n",
       "      <td>0.936649</td>\n",
       "      <td>0.936806</td>\n",
       "      <td>0.936806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.525478</td>\n",
       "      <td>0.509740</td>\n",
       "      <td>0.553991</td>\n",
       "      <td>0.512156</td>\n",
       "      <td>0.604693</td>\n",
       "      <td>0.610202</td>\n",
       "      <td>0.610790</td>\n",
       "      <td>0.610790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  Only Tokenization  Remove Stopwords    Emojis  Stemming  \\\n",
       "0  precision           0.916667          0.934524  0.926702  0.934911   \n",
       "1     recall           0.368304          0.350446  0.395089  0.352679   \n",
       "2   accuracy           0.953387          0.952761  0.955420  0.952917   \n",
       "3         F1           0.525478          0.509740  0.553991  0.512156   \n",
       "\n",
       "   Upsampling  All_but_stemming   no_user  count_vec  \n",
       "0    0.507576          0.536379  0.537288   0.537288  \n",
       "1    0.747768          0.707589  0.707589   0.707589  \n",
       "2    0.931488          0.936649  0.936806   0.936806  \n",
       "3    0.604693          0.610202  0.610790   0.610790  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mvb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cca499a840d662a33e8301a94c1b3730e7c5db68b1a61aac955d5a843456daa4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
