{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq646iXZxVbH",
        "outputId": "16e71bf1-6405-4847-a853-3454f9b1ac41"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb#ch0000000?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Wsk40Gx35D",
        "outputId": "3b61d87b-6a88-4ec7-faa3-7035fe043253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DataMining/Data_mining/src/data\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/DataMining/Data_mining/src/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHAr19h1xQgn"
      },
      "source": [
        "# Preproccesing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6trqFrZixQg1"
      },
      "source": [
        "## Importing needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9x1R9W9xQg3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_86307/1507358498.py:13: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
            "  demoji.download_codes()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import demoji\n",
        "\n",
        "\n",
        "demoji.download_codes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDSIpni2xQg9"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tVg3ddLpxQg-"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"../../data/train_tweet.csv\")\n",
        "test_data = pd.read_csv(\"../../data/test_tweets.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3jgrWtqxQhB"
      },
      "source": [
        "Take a first look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "982-_-dQxQhD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation\n",
              "5   6      0  [2/2] huge fan fare and big talking before the...\n",
              "6   7      0   @user camping tomorrow @user @user @user @use...\n",
              "7   8      0  the next school year is the year for exams.ð...\n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fsMipIvRxQhH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYWUXpT1xQh-"
      },
      "source": [
        "## Work on emojis \n",
        "Convert emojis to their corresponding text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_emoji(text:str) -> str:\n",
        "    #convert string to binary representation\n",
        "    binary = ' '.join(format(ord(x), 'b') for x in text)\n",
        "\n",
        "    #convert binary representation to utf8 representation\n",
        "    listRes = list(binary.split(\" \"))\n",
        "    try:\n",
        "        text_with_emoji = bytes([int(x,2) for x in listRes]).decode('utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        return text\n",
        "        \n",
        "    #get all emojis\n",
        "    dictionary = demoji.findall(text_with_emoji)\n",
        "\n",
        "    #replace emojis with text representation\n",
        "    for key in dictionary.keys():\n",
        "        text_with_emoji = text_with_emoji.replace(key, dictionary[key] + \" \")\n",
        "\n",
        "    \n",
        "    return text_with_emoji\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[\"tweet_converted_emojis\"] = train_data[\"tweet\"].apply(lambda x: convert_emoji(x))\n",
        "test_data[\"tweet_converted_emojis\"] = test_data[\"tweet\"].apply(lambda x: convert_emoji(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "      <td>the next school year is the year for exams.hus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
              "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
              "7   8      0  the next school year is the year for exams.ð...   \n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
              "\n",
              "                              tweet_converted_emojis  \n",
              "0   @user when a father is dysfunctional and is s...  \n",
              "1  @user @user thanks for #lyft credit i can't us...  \n",
              "2                                bihday your majesty  \n",
              "3  #model   i love u take with u all the time in ...  \n",
              "4             factsguide: society now    #motivation  \n",
              "5  [2/2] huge fan fare and big talking before the...  \n",
              "6   @user camping tomorrow @user @user @user @use...  \n",
              "7  the next school year is the year for exams.hus...  \n",
              "8  we won!!! love the land!!! #allin #cavs #champ...  \n",
              "9   @user @user welcome here !  i'm   it's so #gr...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3fp1U0AxQhJ"
      },
      "source": [
        "## Deal with user mentions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CSp0NV4txQhM"
      },
      "outputs": [],
      "source": [
        "def count_user_mentions(text:str) ->int:\n",
        "    return text.count(\"@user\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9iUWPC51xQhP"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \n",
              "0   @user when a father is dysfunctional and is s...           1  \n",
              "1  @user @user thanks for #lyft credit i can't us...           2  \n",
              "2                                bihday your majesty           0  \n",
              "3  #model   i love u take with u all the time in ...           0  \n",
              "4             factsguide: society now    #motivation           0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"n_mentions\"] = test_data[\"tweet_converted_emojis\"].apply(lambda x: count_user_mentions(x))\n",
        "train_data[\"n_mentions\"] = train_data[\"tweet_converted_emojis\"].apply(lambda x: count_user_mentions(x))\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0cibTixQhR"
      },
      "source": [
        "## Deal with hashtags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cfD7xYZDxQhT"
      },
      "outputs": [],
      "source": [
        "def identify_hashtags(text:str) -> list:\n",
        "    pattern = re.compile(r\"#(\\w+)\")\n",
        "    return pattern.findall(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Mbu8dHAgxQhV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
              "1  31964   @user #white #supremacists want everyone to s...   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
              "3  31966  is the hp and the cursed child book up for res...   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1   @user #white #supremacists want everyone to s...           1   \n",
              "2  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  is the hp and the cursed child book up for res...           0   \n",
              "4    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1                [white, supremacists, birds, movie]  \n",
              "2            [acne, altwaystoheal, healthy, healing]  \n",
              "3                [harrypotter, pottermore, favorite]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"hashtags\"] = test_data[\"tweet_converted_emojis\"].apply(lambda x: identify_hashtags(x))\n",
        "train_data[\"hashtags\"] = train_data[\"tweet_converted_emojis\"].apply(lambda x: identify_hashtags(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPaOhm2lxQhX"
      },
      "source": [
        "## Punctuation Removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfZQIjwdxQhY"
      },
      "source": [
        "Create helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XFYglYuQxQhZ"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text:str) -> str:\n",
        "    return \"\".join([i for i in text if i not in punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8D3dA36-xQha"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
              "1  31964   @user #white #supremacists want everyone to s...   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
              "3  31966  is the hp and the cursed child book up for res...   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1   @user #white #supremacists want everyone to s...           1   \n",
              "2  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  is the hp and the cursed child book up for res...           0   \n",
              "4    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \n",
              "0  studiolife aislife requires passion dedication...  \n",
              "1   user white supremacists want everyone to see ...  \n",
              "2  safe ways to heal your acne    altwaystoheal h...  \n",
              "3  is the hp and the cursed child book up for res...  \n",
              "4    3rd bihday to my amazing hilarious nephew el...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"without_punctuation\"] = test_data[\"tweet_converted_emojis\"].apply(lambda x: remove_punctuation(x))\n",
        "train_data[\"without_punctuation\"] = train_data[\"tweet_converted_emojis\"].apply(lambda x: remove_punctuation(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AeV3Ir5ExQhc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[run]</td>\n",
              "      <td>user when a father is dysfunctional and is so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>2</td>\n",
              "      <td>[lyft, disapointed, getthanked]</td>\n",
              "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[model]</td>\n",
              "      <td>model   i love u take with u all the time in u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0</td>\n",
              "      <td>[motivation]</td>\n",
              "      <td>factsguide society now    motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>0</td>\n",
              "      <td>[allshowandnogo]</td>\n",
              "      <td>22 huge fan fare and big talking before they l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>8</td>\n",
              "      <td>[]</td>\n",
              "      <td>user camping tomorrow user user user user use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "      <td>the next school year is the year for exams.hus...</td>\n",
              "      <td>0</td>\n",
              "      <td>[school, exams, hate, imagine, actorslife, rev...</td>\n",
              "      <td>the next school year is the year for examshush...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[allin, cavs, champions, cleveland, clevelandc...</td>\n",
              "      <td>we won love the land allin cavs champions clev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>2</td>\n",
              "      <td>[gr8]</td>\n",
              "      <td>user user welcome here   im   its so gr8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
              "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
              "7   8      0  the next school year is the year for exams.ð...   \n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0   @user when a father is dysfunctional and is s...           1   \n",
              "1  @user @user thanks for #lyft credit i can't us...           2   \n",
              "2                                bihday your majesty           0   \n",
              "3  #model   i love u take with u all the time in ...           0   \n",
              "4             factsguide: society now    #motivation           0   \n",
              "5  [2/2] huge fan fare and big talking before the...           0   \n",
              "6   @user camping tomorrow @user @user @user @use...           8   \n",
              "7  the next school year is the year for exams.hus...           0   \n",
              "8  we won!!! love the land!!! #allin #cavs #champ...           0   \n",
              "9   @user @user welcome here !  i'm   it's so #gr...           2   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0                                              [run]   \n",
              "1                    [lyft, disapointed, getthanked]   \n",
              "2                                                 []   \n",
              "3                                            [model]   \n",
              "4                                       [motivation]   \n",
              "5                                   [allshowandnogo]   \n",
              "6                                                 []   \n",
              "7  [school, exams, hate, imagine, actorslife, rev...   \n",
              "8  [allin, cavs, champions, cleveland, clevelandc...   \n",
              "9                                              [gr8]   \n",
              "\n",
              "                                 without_punctuation  \n",
              "0   user when a father is dysfunctional and is so...  \n",
              "1  user user thanks for lyft credit i cant use ca...  \n",
              "2                                bihday your majesty  \n",
              "3  model   i love u take with u all the time in u...  \n",
              "4               factsguide society now    motivation  \n",
              "5  22 huge fan fare and big talking before they l...  \n",
              "6   user camping tomorrow user user user user use...  \n",
              "7  the next school year is the year for examshush...  \n",
              "8  we won love the land allin cavs champions clev...  \n",
              "9         user user welcome here   im   its so gr8    "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgDDGxTCxQhd"
      },
      "source": [
        "## Lowering text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sASiJLEOxQhf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[run]</td>\n",
              "      <td>user when a father is dysfunctional and is so...</td>\n",
              "      <td>user when a father is dysfunctional and is so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>2</td>\n",
              "      <td>[lyft, disapointed, getthanked]</td>\n",
              "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
              "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[model]</td>\n",
              "      <td>model   i love u take with u all the time in u...</td>\n",
              "      <td>model   i love u take with u all the time in u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0</td>\n",
              "      <td>[motivation]</td>\n",
              "      <td>factsguide society now    motivation</td>\n",
              "      <td>factsguide society now    motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0   @user when a father is dysfunctional and is s...           1   \n",
              "1  @user @user thanks for #lyft credit i can't us...           2   \n",
              "2                                bihday your majesty           0   \n",
              "3  #model   i love u take with u all the time in ...           0   \n",
              "4             factsguide: society now    #motivation           0   \n",
              "\n",
              "                          hashtags  \\\n",
              "0                            [run]   \n",
              "1  [lyft, disapointed, getthanked]   \n",
              "2                               []   \n",
              "3                          [model]   \n",
              "4                     [motivation]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0   user when a father is dysfunctional and is so...   \n",
              "1  user user thanks for lyft credit i cant use ca...   \n",
              "2                                bihday your majesty   \n",
              "3  model   i love u take with u all the time in u...   \n",
              "4               factsguide society now    motivation   \n",
              "\n",
              "                                         tweet_lower  \n",
              "0   user when a father is dysfunctional and is so...  \n",
              "1  user user thanks for lyft credit i cant use ca...  \n",
              "2                                bihday your majesty  \n",
              "3  model   i love u take with u all the time in u...  \n",
              "4               factsguide society now    motivation  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"tweet_lower\"] = test_data[\"without_punctuation\"].apply(lambda x: x.lower())\n",
        "train_data[\"tweet_lower\"] = train_data[\"without_punctuation\"].apply(lambda x: x.lower())\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tx4IBjzxQhh"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LVg49DvUzuhY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xu11J8NWxQhh"
      },
      "outputs": [],
      "source": [
        "def tokenization(text:str) -> list:\n",
        "    return nltk.word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "M9ptoOj7xQhj"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
              "1  31964   @user #white #supremacists want everyone to s...   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
              "3  31966  is the hp and the cursed child book up for res...   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1   @user #white #supremacists want everyone to s...           1   \n",
              "2  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  is the hp and the cursed child book up for res...           0   \n",
              "4    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1  [user, white, supremacists, want, everyone, to...  \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...  \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...  \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"tweet_token\"] = test_data[\"tweet_lower\"].apply(lambda x: tokenization(x))\n",
        "train_data[\"tweet_token\"] = train_data[\"tweet_lower\"].apply(lambda x: tokenization(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSC4DCYDxQhk"
      },
      "source": [
        "## Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i91SIAplz9JQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GcRjbmKdxQhl"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens) ->list:\n",
        "    stopwords_list = stopwords.words(\"english\")\n",
        "    return [token for token in tokens if token not in stopwords_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ckw3hwngxQhm"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>clean_token</th>\n",
              "      <th>clean_hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
              "1  31964   @user #white #supremacists want everyone to s...   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
              "3  31966  is the hp and the cursed child book up for res...   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1   @user #white #supremacists want everyone to s...           1   \n",
              "2  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  is the hp and the cursed child book up for res...           0   \n",
              "4    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, to...   \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...   \n",
              "\n",
              "                                         clean_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, se...   \n",
              "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
              "3  [hp, cursed, child, book, reservations, alread...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                      clean_hashtags  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1                [white, supremacists, birds, movie]  \n",
              "2            [acne, altwaystoheal, healthy, healing]  \n",
              "3                [harrypotter, pottermore, favorite]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"clean_token\"] = test_data[\"tweet_token\"].apply(lambda x: remove_stopwords(x))\n",
        "train_data[\"clean_token\"] = train_data[\"tweet_token\"].apply(lambda x: remove_stopwords(x))\n",
        "test_data[\"clean_hashtags\"] = test_data[\"hashtags\"].apply(lambda x: remove_stopwords(x))\n",
        "train_data[\"clean_hashtags\"] = train_data[\"hashtags\"].apply(lambda x: remove_stopwords(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKW9vlXKxQho"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iK6vz_J2xQhp"
      },
      "outputs": [],
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stemming(text:list) -> list:\n",
        "    return [porter_stemmer.stem(word) for word in text]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pdU25XTMxQhq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>clean_token</th>\n",
              "      <th>clean_hashtags</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>stemmed_hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
              "      <td>[white, supremacist, bird, movi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
              "      <td>[acn, altwaystoh, healthi, heal]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>[hp, curs, child, book, reserv, alreadi, ye, s...</td>\n",
              "      <td>[harrypott, pottermor, favorit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
              "1  31964   @user #white #supremacists want everyone to s...   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
              "3  31966  is the hp and the cursed child book up for res...   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1   @user #white #supremacists want everyone to s...           1   \n",
              "2  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  is the hp and the cursed child book up for res...           0   \n",
              "4    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, to...   \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...   \n",
              "\n",
              "                                         clean_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, se...   \n",
              "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
              "3  [hp, cursed, child, book, reservations, alread...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                      clean_hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                      stemmed_tokens  \\\n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
              "1  [user, white, supremacist, want, everyon, see,...   \n",
              "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
              "3  [hp, curs, child, book, reserv, alreadi, ye, s...   \n",
              "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
              "\n",
              "                                    stemmed_hashtags  \n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...  \n",
              "1                   [white, supremacist, bird, movi]  \n",
              "2                   [acn, altwaystoh, healthi, heal]  \n",
              "3                    [harrypott, pottermor, favorit]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"stemmed_tokens\"] = test_data[\"clean_token\"].apply(lambda x: stemming(x))\n",
        "train_data[\"stemmed_tokens\"] = train_data[\"clean_token\"].apply(lambda x: stemming(x))\n",
        "test_data[\"stemmed_hashtags\"] = test_data[\"clean_hashtags\"].apply(lambda x: stemming(x))\n",
        "train_data[\"stemmed_hashtags\"] = train_data[\"clean_hashtags\"].apply(lambda x: stemming(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGOW_qTqxQhs"
      },
      "source": [
        "Result does not look great (e.g. movie -> movi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT29MhFuxQht"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sTj48kNd0Or9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jbYBgb2ExQht"
      },
      "outputs": [],
      "source": [
        "word_lemmatizer = WordNetLemmatizer()\n",
        "def lemmatizer(text: list) -> list:\n",
        "    return [word_lemmatizer.lemmatize(word) for word in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbKAW17l1GXG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "s5caf3YwxQhu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>clean_token</th>\n",
              "      <th>clean_hashtags</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>stemmed_hashtags</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "      <th>lemmatized_hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
              "      <td>[white, supremacists, birds, movie]</td>\n",
              "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
              "      <td>[white, supremacist, bird, movi]</td>\n",
              "      <td>[user, white, supremacist, want, everyone, see...</td>\n",
              "      <td>[white, supremacist, bird, movie]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
              "      <td>[acn, altwaystoh, healthi, heal]</td>\n",
              "      <td>[safe, way, heal, acne, altwaystoheal, healthy...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>[hp, curs, child, book, reserv, alreadi, ye, s...</td>\n",
              "      <td>[harrypott, pottermor, favorit]</td>\n",
              "      <td>[hp, cursed, child, book, reservation, already...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
              "1  31964   @user #white #supremacists want everyone to s...   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
              "3  31966  is the hp and the cursed child book up for res...   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1   @user #white #supremacists want everyone to s...           1   \n",
              "2  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  is the hp and the cursed child book up for res...           0   \n",
              "4    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, to...   \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...   \n",
              "\n",
              "                                         clean_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, se...   \n",
              "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
              "3  [hp, cursed, child, book, reservations, alread...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                      clean_hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1                [white, supremacists, birds, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                      stemmed_tokens  \\\n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
              "1  [user, white, supremacist, want, everyon, see,...   \n",
              "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
              "3  [hp, curs, child, book, reserv, alreadi, ye, s...   \n",
              "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
              "\n",
              "                                    stemmed_hashtags  \\\n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
              "1                   [white, supremacist, bird, movi]   \n",
              "2                   [acn, altwaystoh, healthi, heal]   \n",
              "3                    [harrypott, pottermor, favorit]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                   lemmatized_tokens  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacist, want, everyone, see...   \n",
              "2  [safe, way, heal, acne, altwaystoheal, healthy...   \n",
              "3  [hp, cursed, child, book, reservation, already...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                 lemmatized_hashtags  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1                  [white, supremacist, bird, movie]  \n",
              "2            [acne, altwaystoheal, healthy, healing]  \n",
              "3                [harrypotter, pottermore, favorite]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"lemmatized_tokens\"] = test_data[\"clean_token\"].apply(lambda x: lemmatizer(x))\n",
        "train_data[\"lemmatized_tokens\"] = train_data[\"clean_token\"].apply(lambda x: lemmatizer(x))\n",
        "test_data[\"lemmatized_hashtags\"] = test_data[\"clean_hashtags\"].apply(lambda x: lemmatizer(x))\n",
        "train_data[\"lemmatized_hashtags\"] = train_data[\"clean_hashtags\"].apply(lambda x: lemmatizer(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Temp Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data.to_csv(\"../../data/220510_test_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
        "train_data.to_csv(\"../../data/220510_train_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBHdSxnVxQhy"
      },
      "source": [
        "## Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HQKvjv9V0cpE",
        "outputId": "49682c53-d937-4690-87c2-d57652df607a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "tf = TfidfVectorizer()\n",
        "\n",
        "X_vec = tf.fit(train_data[[\"lemmatized_tokens\", \"lemmatized_hashtags\"]])\n",
        "train_data = X_vec.transform(train_data[[\"lemmatized_tokens\", \"lemmatized_hashtags\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MwAXtKqxQh3"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFkG0AdjxQh4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "X = train_data.loc[:, train_data.columns != \"label\"]\n",
        "Y = train_data.loc[train_data.label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw6vYXgzxQh5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data, Y, test_size=0.2, random_state=55)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNwBcQqoxQh6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PRdzEerxQh8"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "X_test.to_csv(\"../../data/220510_test_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
        "X_train.to_csv(\"../../data/220510_train_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
        "X_val.to_csv(\"../../data/220510_validation_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVSJHA6AxQh9"
      },
      "source": [
        "# Work in progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gANrTs-xxQhz",
        "outputId": "82681452-252f-4b12-daf9-5088d87d79cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "import texthero as hero\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"../../data/220502_train_data_preprocessed.csv\", sep=';')\n",
        "train_data[\"tfidf_stemmed_tokens\"] = (hero.tfidf(train_data[\"stemmed_tokens\"], max_features=8000))\n",
        "train_data[\"tfidf_stemmed_tokens\"] = (hero.pca(train_data[\"tfidf_stemmed_tokens\"], n_components=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BuV0sAAxQh0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "train_data[\"tfidf_stemmed_hashtags\"] = (hero.tfidf(train_data[\"stemmed_hashtags\"], max_features=8000))\n",
        "train_data[\"tfidf_stemmed_hashtags\"] = (hero.pca(train_data[\"tfidf_stemmed_hashtags\"], n_components=200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4OJX1fMxQh0"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "train_data[\"tfidf_lemmatized_tokens\"] = (hero.tfidf(train_data[\"lemmatized_tokens\"], max_features=8000))\n",
        "train_data[\"tfidf_lemmatized_tokens\"] = (hero.pca(train_data[\"tfidf_lemmatized_tokens\"], n_components=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv3CTQNmxQh1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.12 ('env': venv)' requires notebook package.\n",
            "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
            "Command: 'python -m pip install jupyter notebook -U\n",
            "or\n",
            "conda install jupyter notebook -U'\n",
            "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "train_data[\"tfidf_lemmatized_hashtags\"] = (hero.tfidf(train_data[\"lemmatized_hashtags\"], max_features=8000))\n",
        "train_data[\"tfidf_lemmatized_hashtags\"] = (hero.pca(train_data[\"tfidf_lemmatized_hashtags\"], n_components=200))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kgDDGxTCxQhd",
        "9Tx4IBjzxQhh",
        "DSC4DCYDxQhk",
        "JKW9vlXKxQho",
        "tT29MhFuxQht",
        "5n77DbcoxQhw",
        "SBHdSxnVxQhy",
        "-MwAXtKqxQh3",
        "VYWUXpT1xQh-"
      ],
      "machine_shape": "hm",
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "947cd5ef72fa4485f7ecf5a654ef12bcb7ac0faec018370a70389fc4010d0179"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
