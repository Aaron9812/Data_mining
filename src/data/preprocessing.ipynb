{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq646iXZxVbH",
        "outputId": "16e71bf1-6405-4847-a853-3454f9b1ac41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Wsk40Gx35D",
        "outputId": "3b61d87b-6a88-4ec7-faa3-7035fe043253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DataMining/Data_mining/src/data\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/DataMining/Data_mining/src/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHAr19h1xQgn"
      },
      "source": [
        "# Preproccesing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6trqFrZixQg1"
      },
      "source": [
        "## Importing needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "G9x1R9W9xQg3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_2448/1507358498.py:13: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
            "  demoji.download_codes()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import demoji\n",
        "\n",
        "\n",
        "demoji.download_codes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDSIpni2xQg9"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tVg3ddLpxQg-"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"../../data/train_tweet.csv\")\n",
        "test_data = pd.read_csv(\"../../data/test_tweets.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3jgrWtqxQhB"
      },
      "source": [
        "Take a first look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "982-_-dQxQhD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation\n",
              "5   6      0  [2/2] huge fan fare and big talking before the...\n",
              "6   7      0   @user camping tomorrow @user @user @user @use...\n",
              "7   8      0  the next school year is the year for exams.ð...\n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsMipIvRxQhH"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYWUXpT1xQh-"
      },
      "source": [
        "## Work on emojis \n",
        "Convert emojis to their corresponding text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_emoji(text:str) -> str:\n",
        "    #convert string to binary representation\n",
        "    binary = ' '.join(format(ord(x), 'b') for x in text)\n",
        "\n",
        "    #convert binary representation to utf8 representation\n",
        "    listRes = list(binary.split(\" \"))\n",
        "    try:\n",
        "        text_with_emoji = bytes([int(x,2) for x in listRes]).decode('utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        return text\n",
        "        \n",
        "    #get all emojis\n",
        "    dictionary = demoji.findall(text_with_emoji)\n",
        "\n",
        "    #replace emojis with text representation\n",
        "    for key in dictionary.keys():\n",
        "        text_with_emoji = text_with_emoji.replace(key, dictionary[key] + \" \")\n",
        "\n",
        "    \n",
        "    return text_with_emoji\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[\"tweet_converted_emojis\"] = train_data[\"tweet\"].apply(lambda x: convert_emoji(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "      <td>the next school year is the year for exams.hus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
              "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
              "7   8      0  the next school year is the year for exams.ð...   \n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
              "\n",
              "                              tweet_converted_emojis  \n",
              "0   @user when a father is dysfunctional and is s...  \n",
              "1  @user @user thanks for #lyft credit i can't us...  \n",
              "2                                bihday your majesty  \n",
              "3  #model   i love u take with u all the time in ...  \n",
              "4             factsguide: society now    #motivation  \n",
              "5  [2/2] huge fan fare and big talking before the...  \n",
              "6   @user camping tomorrow @user @user @user @use...  \n",
              "7  the next school year is the year for exams.hus...  \n",
              "8  we won!!! love the land!!! #allin #cavs #champ...  \n",
              "9   @user @user welcome here !  i'm   it's so #gr...  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3fp1U0AxQhJ"
      },
      "source": [
        "## Deal with user mentions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "CSp0NV4txQhM"
      },
      "outputs": [],
      "source": [
        "def count_user_mentions(text:str) ->int:\n",
        "    return text.count(\"@user\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9iUWPC51xQhP"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0\n",
              "1  31964   @user #white #supremacists want everyone to s...           1\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0\n",
              "3  31966  is the hp and the cursed child book up for res...           0\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"n_mentions\"] = test_data[\"tweet\"].apply(lambda x: count_user_mentions(x))\n",
        "train_data[\"n_mentions\"] = train_data[\"tweet\"].apply(lambda x: count_user_mentions(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0cibTixQhR"
      },
      "source": [
        "## Deal with hashtags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cfD7xYZDxQhT"
      },
      "outputs": [],
      "source": [
        "def identify_hashtags(text:str) -> list:\n",
        "    pattern = re.compile(r\"#(\\w+)\")\n",
        "    return pattern.findall(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Mbu8dHAgxQhV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1  31964   @user #white #supremacists want everyone to s...           1   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  31966  is the hp and the cursed child book up for res...           0   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1               [white, supremacists, birdsâ, movie]  \n",
              "2            [acne, altwaystoheal, healthy, healing]  \n",
              "3                [harrypotter, pottermore, favorite]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"hashtags\"] = test_data[\"tweet\"].apply(lambda x: identify_hashtags(x))\n",
        "train_data[\"hashtags\"] = train_data[\"tweet\"].apply(lambda x: identify_hashtags(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPaOhm2lxQhX"
      },
      "source": [
        "## Punctuation Removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfZQIjwdxQhY"
      },
      "source": [
        "Create helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "XFYglYuQxQhZ"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text:str) -> str:\n",
        "    return \"\".join([i for i in text if i not in punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8D3dA36-xQha"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1  31964   @user #white #supremacists want everyone to s...           1   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  31966  is the hp and the cursed child book up for res...           0   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \n",
              "0  studiolife aislife requires passion dedication...  \n",
              "1   user white supremacists want everyone to see ...  \n",
              "2  safe ways to heal your acne    altwaystoheal h...  \n",
              "3  is the hp and the cursed child book up for res...  \n",
              "4    3rd bihday to my amazing hilarious nephew el...  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"without_punctuation\"] = test_data[\"tweet\"].apply(lambda x: remove_punctuation(x))\n",
        "train_data[\"without_punctuation\"] = train_data[\"tweet\"].apply(lambda x: remove_punctuation(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AeV3Ir5ExQhc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[run]</td>\n",
              "      <td>user when a father is dysfunctional and is so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>2</td>\n",
              "      <td>[lyft, disapointed, getthanked]</td>\n",
              "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[model]</td>\n",
              "      <td>model   i love u take with u all the time in u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0</td>\n",
              "      <td>[motivation]</td>\n",
              "      <td>factsguide society now    motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "      <td>0</td>\n",
              "      <td>[allshowandnogo]</td>\n",
              "      <td>22 huge fan fare and big talking before they l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "      <td>8</td>\n",
              "      <td>[]</td>\n",
              "      <td>user camping tomorrow user user user user use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "      <td>the next school year is the year for exams.hus...</td>\n",
              "      <td>0</td>\n",
              "      <td>[school, exams, hate, imagine, actorslife, rev...</td>\n",
              "      <td>the next school year is the year for examsð¯...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[allin, cavs, champions, cleveland, clevelandc...</td>\n",
              "      <td>we won love the land allin cavs champions clev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "      <td>2</td>\n",
              "      <td>[gr8]</td>\n",
              "      <td>user user welcome here   im   its so gr8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
              "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
              "7   8      0  the next school year is the year for exams.ð...   \n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0   @user when a father is dysfunctional and is s...           1   \n",
              "1  @user @user thanks for #lyft credit i can't us...           2   \n",
              "2                                bihday your majesty           0   \n",
              "3  #model   i love u take with u all the time in ...           0   \n",
              "4             factsguide: society now    #motivation           0   \n",
              "5  [2/2] huge fan fare and big talking before the...           0   \n",
              "6   @user camping tomorrow @user @user @user @use...           8   \n",
              "7  the next school year is the year for exams.hus...           0   \n",
              "8  we won!!! love the land!!! #allin #cavs #champ...           0   \n",
              "9   @user @user welcome here !  i'm   it's so #gr...           2   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0                                              [run]   \n",
              "1                    [lyft, disapointed, getthanked]   \n",
              "2                                                 []   \n",
              "3                                            [model]   \n",
              "4                                       [motivation]   \n",
              "5                                   [allshowandnogo]   \n",
              "6                                                 []   \n",
              "7  [school, exams, hate, imagine, actorslife, rev...   \n",
              "8  [allin, cavs, champions, cleveland, clevelandc...   \n",
              "9                                              [gr8]   \n",
              "\n",
              "                                 without_punctuation  \n",
              "0   user when a father is dysfunctional and is so...  \n",
              "1  user user thanks for lyft credit i cant use ca...  \n",
              "2                                bihday your majesty  \n",
              "3  model   i love u take with u all the time in u...  \n",
              "4               factsguide society now    motivation  \n",
              "5  22 huge fan fare and big talking before they l...  \n",
              "6   user camping tomorrow user user user user use...  \n",
              "7  the next school year is the year for examsð¯...  \n",
              "8  we won love the land allin cavs champions clev...  \n",
              "9         user user welcome here   im   its so gr8    "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgDDGxTCxQhd"
      },
      "source": [
        "## Lowering text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "sASiJLEOxQhf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_converted_emojis</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[run]</td>\n",
              "      <td>user when a father is dysfunctional and is so...</td>\n",
              "      <td>user when a father is dysfunctional and is so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>2</td>\n",
              "      <td>[lyft, disapointed, getthanked]</td>\n",
              "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
              "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[model]</td>\n",
              "      <td>model   i love u take with u all the time in u...</td>\n",
              "      <td>model   i love u take with u all the time in u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>0</td>\n",
              "      <td>[motivation]</td>\n",
              "      <td>factsguide society now    motivation</td>\n",
              "      <td>factsguide society now    motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1      0   @user when a father is dysfunctional and is s...   \n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3      0                                bihday your majesty   \n",
              "3   4      0  #model   i love u take with u all the time in ...   \n",
              "4   5      0             factsguide: society now    #motivation   \n",
              "\n",
              "                              tweet_converted_emojis  n_mentions  \\\n",
              "0   @user when a father is dysfunctional and is s...           1   \n",
              "1  @user @user thanks for #lyft credit i can't us...           2   \n",
              "2                                bihday your majesty           0   \n",
              "3  #model   i love u take with u all the time in ...           0   \n",
              "4             factsguide: society now    #motivation           0   \n",
              "\n",
              "                          hashtags  \\\n",
              "0                            [run]   \n",
              "1  [lyft, disapointed, getthanked]   \n",
              "2                               []   \n",
              "3                          [model]   \n",
              "4                     [motivation]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0   user when a father is dysfunctional and is so...   \n",
              "1  user user thanks for lyft credit i cant use ca...   \n",
              "2                                bihday your majesty   \n",
              "3  model   i love u take with u all the time in u...   \n",
              "4               factsguide society now    motivation   \n",
              "\n",
              "                                         tweet_lower  \n",
              "0   user when a father is dysfunctional and is so...  \n",
              "1  user user thanks for lyft credit i cant use ca...  \n",
              "2                                bihday your majesty  \n",
              "3  model   i love u take with u all the time in u...  \n",
              "4               factsguide society now    motivation  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"tweet_lower\"] = test_data[\"without_punctuation\"].apply(lambda x: x.lower())\n",
        "train_data[\"tweet_lower\"] = train_data[\"without_punctuation\"].apply(lambda x: x.lower())\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tx4IBjzxQhh"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "LVg49DvUzuhY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "xu11J8NWxQhh"
      },
      "outputs": [],
      "source": [
        "def tokenization(text:str) -> list:\n",
        "    return nltk.word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "M9ptoOj7xQhj"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1  31964   @user #white #supremacists want everyone to s...           1   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  31966  is the hp and the cursed child book up for res...           0   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1  [user, white, supremacists, want, everyone, to...  \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...  \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...  \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"tweet_token\"] = test_data[\"tweet_lower\"].apply(lambda x: tokenization(x))\n",
        "train_data[\"tweet_token\"] = train_data[\"tweet_lower\"].apply(lambda x: tokenization(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSC4DCYDxQhk"
      },
      "source": [
        "## Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "i91SIAplz9JQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "GcRjbmKdxQhl"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens) ->list:\n",
        "    stopwords_list = stopwords.words(\"english\")\n",
        "    return [token for token in tokens if token not in stopwords_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Ckw3hwngxQhm"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>clean_token</th>\n",
              "      <th>clean_hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1  31964   @user #white #supremacists want everyone to s...           1   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  31966  is the hp and the cursed child book up for res...           0   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, to...   \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...   \n",
              "\n",
              "                                         clean_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, se...   \n",
              "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
              "3  [hp, cursed, child, book, reservations, alread...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                      clean_hashtags  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1               [white, supremacists, birdsâ, movie]  \n",
              "2            [acne, altwaystoheal, healthy, healing]  \n",
              "3                [harrypotter, pottermore, favorite]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"clean_token\"] = test_data[\"tweet_token\"].apply(lambda x: remove_stopwords(x))\n",
        "train_data[\"clean_token\"] = train_data[\"tweet_token\"].apply(lambda x: remove_stopwords(x))\n",
        "test_data[\"clean_hashtags\"] = test_data[\"hashtags\"].apply(lambda x: remove_stopwords(x))\n",
        "train_data[\"clean_hashtags\"] = train_data[\"hashtags\"].apply(lambda x: remove_stopwords(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKW9vlXKxQho"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "iK6vz_J2xQhp"
      },
      "outputs": [],
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stemming(text:list) -> list:\n",
        "    return [porter_stemmer.stem(word) for word in text]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "pdU25XTMxQhq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>clean_token</th>\n",
              "      <th>clean_hashtags</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>stemmed_hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
              "      <td>[white, supremacist, birdsâ, movi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
              "      <td>[acn, altwaystoh, healthi, heal]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>[hp, curs, child, book, reserv, alreadi, ye, ð...</td>\n",
              "      <td>[harrypott, pottermor, favorit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1  31964   @user #white #supremacists want everyone to s...           1   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  31966  is the hp and the cursed child book up for res...           0   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, to...   \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...   \n",
              "\n",
              "                                         clean_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, se...   \n",
              "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
              "3  [hp, cursed, child, book, reservations, alread...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                      clean_hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                      stemmed_tokens  \\\n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
              "1  [user, white, supremacist, want, everyon, see,...   \n",
              "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
              "3  [hp, curs, child, book, reserv, alreadi, ye, ð...   \n",
              "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
              "\n",
              "                                    stemmed_hashtags  \n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...  \n",
              "1                 [white, supremacist, birdsâ, movi]  \n",
              "2                   [acn, altwaystoh, healthi, heal]  \n",
              "3                    [harrypott, pottermor, favorit]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"stemmed_tokens\"] = test_data[\"clean_token\"].apply(lambda x: stemming(x))\n",
        "train_data[\"stemmed_tokens\"] = train_data[\"clean_token\"].apply(lambda x: stemming(x))\n",
        "test_data[\"stemmed_hashtags\"] = test_data[\"clean_hashtags\"].apply(lambda x: stemming(x))\n",
        "train_data[\"stemmed_hashtags\"] = train_data[\"clean_hashtags\"].apply(lambda x: stemming(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGOW_qTqxQhs"
      },
      "source": [
        "Result does not look great (e.g. movie -> movi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT29MhFuxQht"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "sTj48kNd0Or9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "jbYBgb2ExQht"
      },
      "outputs": [],
      "source": [
        "word_lemmatizer = WordNetLemmatizer()\n",
        "def lemmatizer(text: list) -> list:\n",
        "    return [word_lemmatizer.lemmatize(word) for word in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "zbKAW17l1GXG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/aaronsteiner/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "s5caf3YwxQhu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>n_mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>without_punctuation</th>\n",
              "      <th>tweet_lower</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>clean_token</th>\n",
              "      <th>clean_hashtags</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>stemmed_hashtags</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "      <th>lemmatized_hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>0</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>1</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>user white supremacists want everyone to see ...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
              "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
              "      <td>[white, supremacists, birdsâ, movie]</td>\n",
              "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
              "      <td>[white, supremacist, birdsâ, movi]</td>\n",
              "      <td>[user, white, supremacist, want, everyone, see...</td>\n",
              "      <td>[white, supremacist, birdsâ, movie]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
              "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
              "      <td>[acn, altwaystoh, healthi, heal]</td>\n",
              "      <td>[safe, way, heal, acne, altwaystoheal, healthy...</td>\n",
              "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
              "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "      <td>[hp, curs, child, book, reserv, alreadi, ye, ð...</td>\n",
              "      <td>[harrypott, pottermor, favorit]</td>\n",
              "      <td>[hp, cursed, child, book, reservation, already...</td>\n",
              "      <td>[harrypotter, pottermore, favorite]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>0</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
              "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
              "      <td>[bihday, nephew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  n_mentions  \\\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
              "1  31964   @user #white #supremacists want everyone to s...           1   \n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
              "3  31966  is the hp and the cursed child book up for res...           0   \n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
              "\n",
              "                                            hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                 without_punctuation  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_lower  \\\n",
              "0  studiolife aislife requires passion dedication...   \n",
              "1   user white supremacists want everyone to see ...   \n",
              "2  safe ways to heal your acne    altwaystoheal h...   \n",
              "3  is the hp and the cursed child book up for res...   \n",
              "4    3rd bihday to my amazing hilarious nephew el...   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, to...   \n",
              "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
              "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
              "4  [3rd, bihday, to, my, amazing, hilarious, neph...   \n",
              "\n",
              "                                         clean_token  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacists, want, everyone, se...   \n",
              "2  [safe, ways, heal, acne, altwaystoheal, health...   \n",
              "3  [hp, cursed, child, book, reservations, alread...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                      clean_hashtags  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1               [white, supremacists, birdsâ, movie]   \n",
              "2            [acne, altwaystoheal, healthy, healing]   \n",
              "3                [harrypotter, pottermore, favorite]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                      stemmed_tokens  \\\n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
              "1  [user, white, supremacist, want, everyon, see,...   \n",
              "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
              "3  [hp, curs, child, book, reserv, alreadi, ye, ð...   \n",
              "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
              "\n",
              "                                    stemmed_hashtags  \\\n",
              "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
              "1                 [white, supremacist, birdsâ, movi]   \n",
              "2                   [acn, altwaystoh, healthi, heal]   \n",
              "3                    [harrypott, pottermor, favorit]   \n",
              "4                                   [bihday, nephew]   \n",
              "\n",
              "                                   lemmatized_tokens  \\\n",
              "0  [studiolife, aislife, requires, passion, dedic...   \n",
              "1  [user, white, supremacist, want, everyone, see...   \n",
              "2  [safe, way, heal, acne, altwaystoheal, healthy...   \n",
              "3  [hp, cursed, child, book, reservation, already...   \n",
              "4  [3rd, bihday, amazing, hilarious, nephew, eli,...   \n",
              "\n",
              "                                 lemmatized_hashtags  \n",
              "0  [studiolife, aislife, requires, passion, dedic...  \n",
              "1                [white, supremacist, birdsâ, movie]  \n",
              "2            [acne, altwaystoheal, healthy, healing]  \n",
              "3                [harrypotter, pottermore, favorite]  \n",
              "4                                   [bihday, nephew]  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"lemmatized_tokens\"] = test_data[\"clean_token\"].apply(lambda x: lemmatizer(x))\n",
        "train_data[\"lemmatized_tokens\"] = train_data[\"clean_token\"].apply(lambda x: lemmatizer(x))\n",
        "test_data[\"lemmatized_hashtags\"] = test_data[\"clean_hashtags\"].apply(lambda x: lemmatizer(x))\n",
        "train_data[\"lemmatized_hashtags\"] = train_data[\"clean_hashtags\"].apply(lambda x: lemmatizer(x))\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBHdSxnVxQhy"
      },
      "source": [
        "## Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HQKvjv9V0cpE",
        "outputId": "49682c53-d937-4690-87c2-d57652df607a"
      },
      "outputs": [],
      "source": [
        "tf = TfidfVectorizer()\n",
        "\n",
        "X_vec = tf.fit(train_data[[\"lemmatized_tokens\", \"lemmatized_hashtags\"]])\n",
        "train_data = X_vec.transform(train_data[[\"lemmatized_tokens\", \"lemmatized_hashtags\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MwAXtKqxQh3"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFkG0AdjxQh4"
      },
      "outputs": [],
      "source": [
        "X = train_data.loc[:, train_data.columns != \"label\"]\n",
        "Y = train_data.loc[train_data.label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw6vYXgzxQh5"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data, Y, test_size=0.2, random_state=55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNwBcQqoxQh6"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PRdzEerxQh8"
      },
      "outputs": [],
      "source": [
        "X_test.to_csv(\"../../data/220505_test_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
        "X_train.to_csv(\"../../data/220505_train_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
        "X_val.to_csv(\"../../data/220505_validation_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVSJHA6AxQh9"
      },
      "source": [
        "# Work in progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gANrTs-xxQhz",
        "outputId": "82681452-252f-4b12-daf9-5088d87d79cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import texthero as hero\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"../../data/220502_train_data_preprocessed.csv\", sep=';')\n",
        "train_data[\"tfidf_stemmed_tokens\"] = (hero.tfidf(train_data[\"stemmed_tokens\"], max_features=8000))\n",
        "train_data[\"tfidf_stemmed_tokens\"] = (hero.pca(train_data[\"tfidf_stemmed_tokens\"], n_components=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BuV0sAAxQh0"
      },
      "outputs": [],
      "source": [
        "train_data[\"tfidf_stemmed_hashtags\"] = (hero.tfidf(train_data[\"stemmed_hashtags\"], max_features=8000))\n",
        "train_data[\"tfidf_stemmed_hashtags\"] = (hero.pca(train_data[\"tfidf_stemmed_hashtags\"], n_components=200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4OJX1fMxQh0"
      },
      "outputs": [],
      "source": [
        "train_data[\"tfidf_lemmatized_tokens\"] = (hero.tfidf(train_data[\"lemmatized_tokens\"], max_features=8000))\n",
        "train_data[\"tfidf_lemmatized_tokens\"] = (hero.pca(train_data[\"tfidf_lemmatized_tokens\"], n_components=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv3CTQNmxQh1"
      },
      "outputs": [],
      "source": [
        "train_data[\"tfidf_lemmatized_hashtags\"] = (hero.tfidf(train_data[\"lemmatized_hashtags\"], max_features=8000))\n",
        "train_data[\"tfidf_lemmatized_hashtags\"] = (hero.pca(train_data[\"tfidf_lemmatized_hashtags\"], n_components=200))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kgDDGxTCxQhd",
        "9Tx4IBjzxQhh",
        "DSC4DCYDxQhk",
        "JKW9vlXKxQho",
        "tT29MhFuxQht",
        "5n77DbcoxQhw",
        "SBHdSxnVxQhy",
        "-MwAXtKqxQh3",
        "VYWUXpT1xQh-"
      ],
      "machine_shape": "hm",
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "947cd5ef72fa4485f7ecf5a654ef12bcb7ac0faec018370a70389fc4010d0179"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
