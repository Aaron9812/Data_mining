{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproccesing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../data/train_tweet.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a first look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with user mentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_mentions(text:str) ->int:\n",
    "    return text.count(\"@user\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0\n",
       "1  31964   @user #white #supremacists want everyone to s...           1\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0\n",
       "3  31966  is the hp and the cursed child book up for res...           0\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"n_mentions\"] = test_data[\"tweet\"].apply(lambda x: count_user_mentions(x))\n",
    "train_data[\"n_mentions\"] = train_data[\"tweet\"].apply(lambda x: count_user_mentions(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_hashtags(text:str) -> list:\n",
    "    pattern = re.compile(r\"#(\\w+)\")\n",
    "    return pattern.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
       "1  31964   @user #white #supremacists want everyone to s...           1   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
       "3  31966  is the hp and the cursed child book up for res...           0   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
       "\n",
       "                                            hashtags  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1               [white, supremacists, birdsâ, movie]  \n",
       "2            [acne, altwaystoheal, healthy, healing]  \n",
       "3                [harrypotter, pottermore, favorite]  \n",
       "4                                   [bihday, nephew]  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"hashtags\"] = test_data[\"tweet\"].apply(lambda x: identify_hashtags(x))\n",
    "train_data[\"hashtags\"] = train_data[\"tweet\"].apply(lambda x: identify_hashtags(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctioation(text:str) -> str:\n",
    "    return \"\".join([i for i in text if i not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
       "1  31964   @user #white #supremacists want everyone to s...           1   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
       "3  31966  is the hp and the cursed child book up for res...           0   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                 without_puctioation  \n",
       "0  studiolife aislife requires passion dedication...  \n",
       "1   user white supremacists want everyone to see ...  \n",
       "2  safe ways to heal your acne    altwaystoheal h...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4    3rd bihday to my amazing hilarious nephew el...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"without_puctioation\"] = test_data[\"tweet\"].apply(lambda x: remove_punctioation(x))\n",
    "train_data[\"without_puctioation\"] = train_data[\"tweet\"].apply(lambda x: remove_punctioation(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[run]</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>2</td>\n",
       "      <td>[lyft, disapointed, getthanked]</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[model]</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>[motivation]</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>0</td>\n",
       "      <td>[allshowandnogo]</td>\n",
       "      <td>22 huge fan fare and big talking before they l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>user camping tomorrow user user user user use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>0</td>\n",
       "      <td>[school, exams, hate, imagine, actorslife, rev...</td>\n",
       "      <td>the next school year is the year for examsð¯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[allin, cavs, champions, cleveland, clevelandc...</td>\n",
       "      <td>we won love the land allin cavs champions clev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>2</td>\n",
       "      <td>[gr8]</td>\n",
       "      <td>user user welcome here   im   its so gr8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  n_mentions  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...           1   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...           2   \n",
       "2   3      0                                bihday your majesty           0   \n",
       "3   4      0  #model   i love u take with u all the time in ...           0   \n",
       "4   5      0             factsguide: society now    #motivation           0   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...           0   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...           8   \n",
       "7   8      0  the next school year is the year for exams.ð...           0   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...           0   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...           2   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                              [run]   \n",
       "1                    [lyft, disapointed, getthanked]   \n",
       "2                                                 []   \n",
       "3                                            [model]   \n",
       "4                                       [motivation]   \n",
       "5                                   [allshowandnogo]   \n",
       "6                                                 []   \n",
       "7  [school, exams, hate, imagine, actorslife, rev...   \n",
       "8  [allin, cavs, champions, cleveland, clevelandc...   \n",
       "9                                              [gr8]   \n",
       "\n",
       "                                 without_puctioation  \n",
       "0   user when a father is dysfunctional and is so...  \n",
       "1  user user thanks for lyft credit i cant use ca...  \n",
       "2                                bihday your majesty  \n",
       "3  model   i love u take with u all the time in u...  \n",
       "4               factsguide society now    motivation  \n",
       "5  22 huge fan fare and big talking before they l...  \n",
       "6   user camping tomorrow user user user user use...  \n",
       "7  the next school year is the year for examsð¯...  \n",
       "8  we won love the land allin cavs champions clev...  \n",
       "9         user user welcome here   im   its so gr8    "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowering text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[run]</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>2</td>\n",
       "      <td>[lyft, disapointed, getthanked]</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[model]</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>[motivation]</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  n_mentions  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...           1   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...           2   \n",
       "2   3      0                                bihday your majesty           0   \n",
       "3   4      0  #model   i love u take with u all the time in ...           0   \n",
       "4   5      0             factsguide: society now    #motivation           0   \n",
       "\n",
       "                          hashtags  \\\n",
       "0                            [run]   \n",
       "1  [lyft, disapointed, getthanked]   \n",
       "2                               []   \n",
       "3                          [model]   \n",
       "4                     [motivation]   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0   user when a father is dysfunctional and is so...   \n",
       "1  user user thanks for lyft credit i cant use ca...   \n",
       "2                                bihday your majesty   \n",
       "3  model   i love u take with u all the time in u...   \n",
       "4               factsguide society now    motivation   \n",
       "\n",
       "                                         tweet_lower  \n",
       "0   user when a father is dysfunctional and is so...  \n",
       "1  user user thanks for lyft credit i cant use ca...  \n",
       "2                                bihday your majesty  \n",
       "3  model   i love u take with u all the time in u...  \n",
       "4               factsguide society now    motivation  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"tweet_lower\"] = test_data[\"without_puctioation\"].apply(lambda x: x.lower())\n",
    "train_data[\"tweet_lower\"] = train_data[\"without_puctioation\"].apply(lambda x: x.lower())\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text:str) -> list:\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>[user, white, supremacists, want, everyone, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>[3rd, bihday, to, my, amazing, hilarious, neph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
       "1  31964   @user #white #supremacists want everyone to s...           1   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
       "3  31966  is the hp and the cursed child book up for res...           0   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_token  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1  [user, white, supremacists, want, everyone, to...  \n",
       "2  [safe, ways, to, heal, your, acne, altwaystohe...  \n",
       "3  [is, the, hp, and, the, cursed, child, book, u...  \n",
       "4  [3rd, bihday, to, my, amazing, hilarious, neph...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"tweet_token\"] = test_data[\"tweet_lower\"].apply(lambda x: tokenization(x))\n",
    "train_data[\"tweet_token\"] = train_data[\"tweet_lower\"].apply(lambda x: tokenization(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens) ->list:\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    return [token for token in tokens if token not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>[white, want, to, the, â, movie, and, why]</td>\n",
       "      <td>[white, want, â, movie]</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>[ways, heal, acne, healthy]</td>\n",
       "      <td>[ways, heal, acne, healthy]</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[and, the, cursed, book, for, already, yes, if...</td>\n",
       "      <td>[cursed, book, already, yes, harrypotter, favo...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>[bihday, my, hilarious, eli, uncle, loves, and]</td>\n",
       "      <td>[bihday, hilarious, eli, uncle, loves]</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
       "1  31964   @user #white #supremacists want everyone to s...           1   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
       "3  31966  is the hp and the cursed child book up for res...           0   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1       [white, want, to, the, â, movie, and, why]   \n",
       "2                        [ways, heal, acne, healthy]   \n",
       "3  [and, the, cursed, book, for, already, yes, if...   \n",
       "4    [bihday, my, hilarious, eli, uncle, loves, and]   \n",
       "\n",
       "                                         clean_token  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1                          [white, want, â, movie]   \n",
       "2                        [ways, heal, acne, healthy]   \n",
       "3  [cursed, book, already, yes, harrypotter, favo...   \n",
       "4             [bihday, hilarious, eli, uncle, loves]   \n",
       "\n",
       "                                      clean_hashtags  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1               [white, supremacists, birdsâ, movie]  \n",
       "2            [acne, altwaystoheal, healthy, healing]  \n",
       "3                [harrypotter, pottermore, favorite]  \n",
       "4                                   [bihday, nephew]  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"clean_token\"] = test_data[\"tweet_token\"].apply(lambda x: remove_stopwords(x))\n",
    "train_data[\"clean_token\"] = train_data[\"tweet_token\"].apply(lambda x: remove_stopwords(x))\n",
    "test_data[\"clean_hashtags\"] = test_data[\"hashtags\"].apply(lambda x: remove_stopwords(x))\n",
    "train_data[\"clean_hashtags\"] = train_data[\"hashtags\"].apply(lambda x: remove_stopwords(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text:list) -> list:\n",
    "    return [porter_stemmer.stem(word) for word in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>stemmed_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>[aislif, passion, willpow, find]</td>\n",
       "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>[white, want, to, the, â, movie, and, why]</td>\n",
       "      <td>[white, want, â, movie]</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>[white, want, â, movi]</td>\n",
       "      <td>[white, supremacist, birdsâ, movi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>[ways, heal, acne, healthy]</td>\n",
       "      <td>[ways, heal, acne, healthy]</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>[way, heal, acn, healthi]</td>\n",
       "      <td>[acn, altwaystoh, healthi, heal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[and, the, cursed, book, for, already, yes, if...</td>\n",
       "      <td>[cursed, book, already, yes, harrypotter, favo...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>[curs, book, alreadi, ye, harrypott, favorit]</td>\n",
       "      <td>[harrypott, pottermor, favorit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>[bihday, my, hilarious, eli, uncle, loves, and]</td>\n",
       "      <td>[bihday, hilarious, eli, uncle, loves]</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>[bihday, hilari, eli, uncl, love]</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
       "1  31964   @user #white #supremacists want everyone to s...           1   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
       "3  31966  is the hp and the cursed child book up for res...           0   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1       [white, want, to, the, â, movie, and, why]   \n",
       "2                        [ways, heal, acne, healthy]   \n",
       "3  [and, the, cursed, book, for, already, yes, if...   \n",
       "4    [bihday, my, hilarious, eli, uncle, loves, and]   \n",
       "\n",
       "                                         clean_token  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1                          [white, want, â, movie]   \n",
       "2                        [ways, heal, acne, healthy]   \n",
       "3  [cursed, book, already, yes, harrypotter, favo...   \n",
       "4             [bihday, hilarious, eli, uncle, loves]   \n",
       "\n",
       "                                      clean_hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                  stemmed_tokens  \\\n",
       "0               [aislif, passion, willpow, find]   \n",
       "1                       [white, want, â, movi]   \n",
       "2                      [way, heal, acn, healthi]   \n",
       "3  [curs, book, alreadi, ye, harrypott, favorit]   \n",
       "4              [bihday, hilari, eli, uncl, love]   \n",
       "\n",
       "                                    stemmed_hashtags  \n",
       "0  [studiolif, aislif, requir, passion, dedic, wi...  \n",
       "1                 [white, supremacist, birdsâ, movi]  \n",
       "2                   [acn, altwaystoh, healthi, heal]  \n",
       "3                    [harrypott, pottermor, favorit]  \n",
       "4                                   [bihday, nephew]  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"stemmed_tokens\"] = test_data[\"clean_token\"].apply(lambda x: stemming(x))\n",
    "train_data[\"stemmed_tokens\"] = train_data[\"clean_token\"].apply(lambda x: stemming(x))\n",
    "test_data[\"stemmed_hashtags\"] = test_data[\"clean_hashtags\"].apply(lambda x: stemming(x))\n",
    "train_data[\"stemmed_hashtags\"] = train_data[\"clean_hashtags\"].apply(lambda x: stemming(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result does not look great (e.g. movie -> movi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizer(text: list) -> list:\n",
    "    return [word_lemmatizer.lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>stemmed_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>[aislif, passion, willpow, find]</td>\n",
       "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
       "      <td>[aislife, passion, willpower, find]</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "      <td>[white, want, to, the, â, movie, and, why]</td>\n",
       "      <td>[white, want, â, movie]</td>\n",
       "      <td>[white, supremacists, birdsâ, movie]</td>\n",
       "      <td>[white, want, â, movi]</td>\n",
       "      <td>[white, supremacist, birdsâ, movi]</td>\n",
       "      <td>[white, want, â, movie]</td>\n",
       "      <td>[white, supremacist, birdsâ, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>[ways, heal, acne, healthy]</td>\n",
       "      <td>[ways, heal, acne, healthy]</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "      <td>[way, heal, acn, healthi]</td>\n",
       "      <td>[acn, altwaystoh, healthi, heal]</td>\n",
       "      <td>[way, heal, acne, healthy]</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[and, the, cursed, book, for, already, yes, if...</td>\n",
       "      <td>[cursed, book, already, yes, harrypotter, favo...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "      <td>[curs, book, alreadi, ye, harrypott, favorit]</td>\n",
       "      <td>[harrypott, pottermor, favorit]</td>\n",
       "      <td>[cursed, book, already, yes, harrypotter, favo...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "      <td>[bihday, my, hilarious, eli, uncle, loves, and]</td>\n",
       "      <td>[bihday, hilarious, eli, uncle, loves]</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>[bihday, hilari, eli, uncl, love]</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "      <td>[bihday, hilarious, eli, uncle, love]</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  n_mentions  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...           0   \n",
       "1  31964   @user #white #supremacists want everyone to s...           1   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...           0   \n",
       "3  31966  is the hp and the cursed child book up for res...           0   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...           0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1   user white supremacists want everyone to see ...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4    3rd bihday to my amazing hilarious nephew el...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1       [white, want, to, the, â, movie, and, why]   \n",
       "2                        [ways, heal, acne, healthy]   \n",
       "3  [and, the, cursed, book, for, already, yes, if...   \n",
       "4    [bihday, my, hilarious, eli, uncle, loves, and]   \n",
       "\n",
       "                                         clean_token  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1                          [white, want, â, movie]   \n",
       "2                        [ways, heal, acne, healthy]   \n",
       "3  [cursed, book, already, yes, harrypotter, favo...   \n",
       "4             [bihday, hilarious, eli, uncle, loves]   \n",
       "\n",
       "                                      clean_hashtags  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1               [white, supremacists, birdsâ, movie]   \n",
       "2            [acne, altwaystoheal, healthy, healing]   \n",
       "3                [harrypotter, pottermore, favorite]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                  stemmed_tokens  \\\n",
       "0               [aislif, passion, willpow, find]   \n",
       "1                       [white, want, â, movi]   \n",
       "2                      [way, heal, acn, healthi]   \n",
       "3  [curs, book, alreadi, ye, harrypott, favorit]   \n",
       "4              [bihday, hilari, eli, uncl, love]   \n",
       "\n",
       "                                    stemmed_hashtags  \\\n",
       "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
       "1                 [white, supremacist, birdsâ, movi]   \n",
       "2                   [acn, altwaystoh, healthi, heal]   \n",
       "3                    [harrypott, pottermor, favorit]   \n",
       "4                                   [bihday, nephew]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0                [aislife, passion, willpower, find]   \n",
       "1                          [white, want, â, movie]   \n",
       "2                         [way, heal, acne, healthy]   \n",
       "3  [cursed, book, already, yes, harrypotter, favo...   \n",
       "4              [bihday, hilarious, eli, uncle, love]   \n",
       "\n",
       "                                 lemmatized_hashtags  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1                [white, supremacist, birdsâ, movie]  \n",
       "2            [acne, altwaystoheal, healthy, healing]  \n",
       "3                [harrypotter, pottermore, favorite]  \n",
       "4                                   [bihday, nephew]  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"lemmatized_tokens\"] = test_data[\"clean_token\"].apply(lambda x: lemmatizer(x))\n",
    "train_data[\"lemmatized_tokens\"] = train_data[\"clean_token\"].apply(lambda x: lemmatizer(x))\n",
    "test_data[\"lemmatized_hashtags\"] = test_data[\"clean_hashtags\"].apply(lambda x: lemmatizer(x))\n",
    "train_data[\"lemmatized_hashtags\"] = train_data[\"clean_hashtags\"].apply(lambda x: lemmatizer(x))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"../../data/220502_test_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "train_data.to_csv(\"../../data/220502_train_data_preprocessed.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work on emojis \n",
    "Convert emojis to their corresponding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronsteiner/Documents/GitHub/Data_mining/env/lib/python3.9/site-packages/IPython/core/inputtransformer2.py:595: UserWarning: `make_tokens_by_line` received a list of lines which do not have lineending markers ('\\n', '\\r', '\\r\\n', '\\x0b', '\\x0c'), behavior will be unspecified\n",
      "  tokens_by_line = make_tokens_by_line(lines)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"#model   i love u take with u all the time in urð±!!! ððððð¦ð¦ð¦  \"\n",
    "test = b'#model   i love u take with u all the time in ur\\xc3\\xb0\\xc2\\x9f\\xc2\\x93\\xc2\\xb1!!! \\xc3\\xb0\\xc2\\x9f\\xc2\\x98\\xc2\\x99\\xc3\\xb0\\xc2\\x9f\\xc2\\x98\\xc2\\x8e\\xc3\\xb0\\xc2\\x9f\\xc2\\x91\\xc2\\x84\\xc3\\xb0\\xc2\\x9f\\xc2\\x91\\xc2\\x85\\xc3\\xb0\\xc2\\x9f\\xc2\\x92\\xc2\\xa6\\xc3\\xb0\\xc2\\x9f\\xc2\\x92\\xc2\\xa6\\xc3\\xb0\\xc2\\x9f\\xc2\\x92\\xc2\\xa6  '\n",
    "\n",
    "test.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronsteiner/Documents/GitHub/Data_mining/env/lib/python3.9/site-packages/IPython/core/inputtransformer2.py:595: UserWarning: `make_tokens_by_line` received a list of lines which do not have lineending markers ('\\n', '\\r', '\\r\\n', '\\x0b', '\\x0c'), behavior will be unspecified\n",
      "  tokens_by_line = make_tokens_by_line(lines)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'emot' has no attribute 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb#ch0000013?line=0'>1</a>\u001b[0m test = \"#model   i love u take with u all the time in urð±!!! ðððð\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb#ch0000013?line=1'>2</a>\u001b[0m ð¦ð¦ð¦  \"\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb#ch0000013?line=2'>3</a>\u001b[0m print(emot.emoji(test))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aaronsteiner/Documents/GitHub/Data_mining/src/data/preprocessing.ipynb#ch0000013?line=3'>4</a>\u001b[0m \n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'emot' has no attribute 'emoji'"
     ]
    }
   ],
   "source": [
    "test = \"#model   i love u take with u all the time in urð±!!! ððððð¦ð¦ð¦  \"\n",
    "print(emot.emoji(test))\n",
    "\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "947cd5ef72fa4485f7ecf5a654ef12bcb7ac0faec018370a70389fc4010d0179"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
