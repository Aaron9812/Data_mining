{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978e6c9a",
   "metadata": {},
   "source": [
    ":# Classifing hate speech in tweets using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27dd58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label', 'tweet', 'n_mentions', 'hashtags', 'without_puctioation',\n",
      "       'tweet_lower', 'tweet_token', 'clean_token', 'clean_hashtags',\n",
      "       'stemmed_tokens', 'stemmed_hashtags', 'lemmatized_tokens',\n",
      "       'lemmatized_hashtags', 'tfidf_stemmed_tokens', 'tfidf_stemmed_hashtags',\n",
      "       'tfidf_lemmatized_tokens', 'tfidf_lemmatized_hashtags'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Downloading the csv file from GitHub\n",
    "url = \"https://raw.githubusercontent.com/Aaron9812/Data_mining/main/data/220505_train_data_preprocessed.csv\"\n",
    "download = requests.get(url).content\n",
    "\n",
    "# Reading the downloaded content and turning it into a pandas dataframe\n",
    "df = pd.read_csv(io.StringIO(download.decode('utf-8')), sep=\";\")\n",
    "\n",
    "# Printing out the first row of the dataframe\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a45a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "\"tweet\",\n",
    "\"hashtags\",\n",
    "\"without_punctuation\",\n",
    "\"tweet_lower\",\n",
    "\"tweet_token\",\n",
    "\"clean_token\",\n",
    "\"clean_hashtags\",\n",
    "\"stemmed_tokens\",\n",
    "\"stemmed_hashtags\",\n",
    "\"lemmatized_tokens\",\n",
    "\"lemmatized_hashtags\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade0cad",
   "metadata": {},
   "source": [
    "### only text features used (so far); no numerical features included!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00376894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>stemmed_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keisha grey and robin sadie exposes her mature...</td>\n",
       "      <td>['robin', 'keisha', 'grey', 'mature']</td>\n",
       "      <td>keisha grey and robin sadie exposes her mature...</td>\n",
       "      <td>keisha grey and robin sadie exposes her mature...</td>\n",
       "      <td>['grey', 'robin', 'exposes', 'and', 'on', 'rob...</td>\n",
       "      <td>['grey', 'robin', 'exposes', 'robin', 'grey', ...</td>\n",
       "      <td>['robin', 'keisha', 'grey', 'mature']</td>\n",
       "      <td>['grey', 'robin', 'expos', 'robin', 'grey', 'm...</td>\n",
       "      <td>['robin', 'keisha', 'grey', 'matur']</td>\n",
       "      <td>['grey', 'robin', 'expose', 'robin', 'grey', '...</td>\n",
       "      <td>['robin', 'keisha', 'grey', 'mature']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ð· themeowood:   puppy</td>\n",
       "      <td>[]</td>\n",
       "      <td>ð· themeowood   puppy</td>\n",
       "      <td>ð· themeowood   puppy</td>\n",
       "      <td>['themeowood']</td>\n",
       "      <td>['themeowood']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['themeowood']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['themeowood']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#angels #archangels from on high here to help ...</td>\n",
       "      <td>['angels', 'archangels', 'spiritual']</td>\n",
       "      <td>angels archangels from on high here to help yo...</td>\n",
       "      <td>angels archangels from on high here to help yo...</td>\n",
       "      <td>['archangels', 'on', 'here', 'help', 'live', '...</td>\n",
       "      <td>['archangels', 'help', 'live', 'lives']</td>\n",
       "      <td>['angels', 'archangels', 'spiritual']</td>\n",
       "      <td>['archangel', 'help', 'live', 'live']</td>\n",
       "      <td>['angel', 'archangel', 'spiritu']</td>\n",
       "      <td>['archangel', 'help', 'live', 'life']</td>\n",
       "      <td>['angel', 'archangel', 'spiritual']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am thankful for being able to remember. #tha...</td>\n",
       "      <td>['thankful', 'positive']</td>\n",
       "      <td>i am thankful for being able to remember thank...</td>\n",
       "      <td>i am thankful for being able to remember thank...</td>\n",
       "      <td>['am', 'for', 'able', 'remember', 'positive']</td>\n",
       "      <td>['able', 'remember', 'positive']</td>\n",
       "      <td>['thankful', 'positive']</td>\n",
       "      <td>['abl', 'rememb', 'posit']</td>\n",
       "      <td>['thank', 'posit']</td>\n",
       "      <td>['able', 'remember', 'positive']</td>\n",
       "      <td>['thankful', 'positive']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rip anton yelchin. a young good actor from the...</td>\n",
       "      <td>['ripantonyelchin', 'actor', 'antonyelchin']</td>\n",
       "      <td>rip anton yelchin a young good actor from the ...</td>\n",
       "      <td>rip anton yelchin a young good actor from the ...</td>\n",
       "      <td>['anton', 'a', 'from', 'star', 'reboots', 'a',...</td>\n",
       "      <td>['anton', 'star', 'reboots', 'good', 'kind', '...</td>\n",
       "      <td>['ripantonyelchin', 'actor', 'antonyelchin']</td>\n",
       "      <td>['anton', 'star', 'reboot', 'good', 'kind', 'r...</td>\n",
       "      <td>['ripantonyelchin', 'actor', 'antonyelchin']</td>\n",
       "      <td>['anton', 'star', 'reboots', 'good', 'kind', '...</td>\n",
       "      <td>['ripantonyelchin', 'actor', 'antonyelchin']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  keisha grey and robin sadie exposes her mature...   \n",
       "1                          ð· themeowood:   puppy    \n",
       "2  #angels #archangels from on high here to help ...   \n",
       "3  i am thankful for being able to remember. #tha...   \n",
       "4  rip anton yelchin. a young good actor from the...   \n",
       "\n",
       "                                       hashtags  \\\n",
       "0         ['robin', 'keisha', 'grey', 'mature']   \n",
       "1                                            []   \n",
       "2         ['angels', 'archangels', 'spiritual']   \n",
       "3                      ['thankful', 'positive']   \n",
       "4  ['ripantonyelchin', 'actor', 'antonyelchin']   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0  keisha grey and robin sadie exposes her mature...   \n",
       "1                           ð· themeowood   puppy    \n",
       "2  angels archangels from on high here to help yo...   \n",
       "3  i am thankful for being able to remember thank...   \n",
       "4  rip anton yelchin a young good actor from the ...   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0  keisha grey and robin sadie exposes her mature...   \n",
       "1                           ð· themeowood   puppy    \n",
       "2  angels archangels from on high here to help yo...   \n",
       "3  i am thankful for being able to remember thank...   \n",
       "4  rip anton yelchin a young good actor from the ...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  ['grey', 'robin', 'exposes', 'and', 'on', 'rob...   \n",
       "1                                     ['themeowood']   \n",
       "2  ['archangels', 'on', 'here', 'help', 'live', '...   \n",
       "3      ['am', 'for', 'able', 'remember', 'positive']   \n",
       "4  ['anton', 'a', 'from', 'star', 'reboots', 'a',...   \n",
       "\n",
       "                                         clean_token  \\\n",
       "0  ['grey', 'robin', 'exposes', 'robin', 'grey', ...   \n",
       "1                                     ['themeowood']   \n",
       "2            ['archangels', 'help', 'live', 'lives']   \n",
       "3                   ['able', 'remember', 'positive']   \n",
       "4  ['anton', 'star', 'reboots', 'good', 'kind', '...   \n",
       "\n",
       "                                 clean_hashtags  \\\n",
       "0         ['robin', 'keisha', 'grey', 'mature']   \n",
       "1                                            []   \n",
       "2         ['angels', 'archangels', 'spiritual']   \n",
       "3                      ['thankful', 'positive']   \n",
       "4  ['ripantonyelchin', 'actor', 'antonyelchin']   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  ['grey', 'robin', 'expos', 'robin', 'grey', 'm...   \n",
       "1                                     ['themeowood']   \n",
       "2              ['archangel', 'help', 'live', 'live']   \n",
       "3                         ['abl', 'rememb', 'posit']   \n",
       "4  ['anton', 'star', 'reboot', 'good', 'kind', 'r...   \n",
       "\n",
       "                               stemmed_hashtags  \\\n",
       "0          ['robin', 'keisha', 'grey', 'matur']   \n",
       "1                                            []   \n",
       "2             ['angel', 'archangel', 'spiritu']   \n",
       "3                            ['thank', 'posit']   \n",
       "4  ['ripantonyelchin', 'actor', 'antonyelchin']   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  ['grey', 'robin', 'expose', 'robin', 'grey', '...   \n",
       "1                                     ['themeowood']   \n",
       "2              ['archangel', 'help', 'live', 'life']   \n",
       "3                   ['able', 'remember', 'positive']   \n",
       "4  ['anton', 'star', 'reboots', 'good', 'kind', '...   \n",
       "\n",
       "                            lemmatized_hashtags  \n",
       "0         ['robin', 'keisha', 'grey', 'mature']  \n",
       "1                                            []  \n",
       "2           ['angel', 'archangel', 'spiritual']  \n",
       "3                      ['thankful', 'positive']  \n",
       "4  ['ripantonyelchin', 'actor', 'antonyelchin']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features]\n",
    "y = df.label\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047a24a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTrain-Test-Split (source vs. code here)\\n\\ntrainData --> X_train\\ntestData --> X_test\\ntrainData['Label'] --> y_train\\ntestData['Label'] --> y_test\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source used:\n",
    "# https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1\n",
    "'''\n",
    "Train-Test-Split (source vs. code here)\n",
    "\n",
    "trainData --> X_train\n",
    "testData --> X_test\n",
    "trainData['Label'] --> y_train\n",
    "testData['Label'] --> y_test\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab5e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f17f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows dataset:  22372\n",
      "X_train: 17897    X_test: 4475    y_train: 17897    y_test: 4475\n",
      "X_train + X_test = 22372\n"
     ]
    }
   ],
   "source": [
    "print(\"# rows dataset: \", len(df))\n",
    "print(\"X_train:\", len(X_train),  \"   X_test:\", len(X_test), \"   y_train:\",  len(y_train), \"   y_test:\", len(y_test))\n",
    "print(\"X_train + X_test =\", (len(X_train) + len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a952dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fd486",
   "metadata": {},
   "source": [
    "# C-Support Vector Classification\n",
    "\n",
    "Using each column indiviudally from our pre-processed data in order to find best kernel for the SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee9d0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d639c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = [\n",
    "\"tweet\",\n",
    "\"tweet_lower\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in kernels:\n",
    "    print(\"f1 scores with \", kernel, \"kernel \\n\")\n",
    "    for feature in feature_selection:\n",
    "        vectors_train = vectorizer.fit_transform(X_train[feature])\n",
    "        vectors_test = vectorizer.transform(X_test[feature])\n",
    "        # Perform classification with SVM\n",
    "        classifier = svm.SVC(kernel= kernel)\n",
    "        classifier.fit(vectors_train, y_train)\n",
    "\n",
    "        prediction = classifier.predict(vectors_test)\n",
    "\n",
    "        # results\n",
    "        \"\"\"\n",
    "        # alternative: print reports\n",
    "        report = classification_report(y_test, prediction, output_dict=True)\n",
    "        # print(feature,\": \", report['1'])\n",
    "        \"\"\"\n",
    "        f1 = f1_score(y_test, prediction)\n",
    "        print(feature,\": \", f1)\n",
    "    print(\"____________________________________________ \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128351b9",
   "metadata": {},
   "source": [
    "### SCV with balanced class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a932e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 scores with  linear kernel \n",
      "\n",
      "tweet :  0.7149606299212599\n",
      "tweet_lower :  0.7169811320754716\n",
      "____________________________________________ \n",
      "\n",
      "f1 scores with  rbf kernel \n",
      "\n",
      "tweet :  0.6653386454183267\n",
      "tweet_lower :  0.6666666666666667\n",
      "____________________________________________ \n",
      "\n",
      "f1 scores with  poly kernel \n",
      "\n",
      "tweet :  0.40909090909090906\n"
     ]
    }
   ],
   "source": [
    "for kernel in kernels:\n",
    "    print(\"f1 scores with \", kernel, \"kernel \\n\")\n",
    "    for feature in feature_selection:\n",
    "        vectors_train = vectorizer.fit_transform(X_train[feature])\n",
    "        vectors_test = vectorizer.transform(X_test[feature])\n",
    "        # Perform classification with SVM\n",
    "        classifier = svm.SVC(kernel= kernel, class_weight='balanced')\n",
    "        classifier.fit(vectors_train, y_train)\n",
    "\n",
    "        prediction = classifier.predict(vectors_test)\n",
    "\n",
    "        # results\n",
    "        \"\"\"\n",
    "        # alternative: print reports\n",
    "        report = classification_report(y_test, prediction, output_dict=True)\n",
    "        # print(feature,\": \", report['1'])\n",
    "        \"\"\"\n",
    "        f1 = f1_score(y_test, prediction)\n",
    "        print(feature,\": \", f1)\n",
    "    print(\"____________________________________________ \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc92cfc",
   "metadata": {},
   "source": [
    "### SCV with scaled vectors & balanced class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94418b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "vectorizer = TfidfVectorizer()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "vec_train = vectorizer.fit_transform(X_train[\"tweet\"])\n",
    "vec_test = vectorizer.transform(X_test[\"tweet\"])\n",
    "vectors_train = scaler.fit(vec_train)\n",
    "vectors_test = scaler.fit(vec_test)\n",
    "\n",
    "vectors_train = scaler.transform(vec_train)\n",
    "vectors_test = scaler.transform(vec_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d270e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in kernels:\n",
    "    print(\"f1 scores with \", kernel, \"kernel \\n\")\n",
    "    for feature in feature_selection:\n",
    "        vectors_train = vectorizer.fit_transform(X_train[feature])\n",
    "        vectors_test = vectorizer.transform(X_test[feature])\n",
    "        # Perform classification with SVM\n",
    "        classifier = svm.SVC(kernel= kernel)\n",
    "        classifier.fit(vectors_train, y_train)\n",
    "\n",
    "        prediction = classifier.predict(vectors_test)\n",
    "\n",
    "        # results\n",
    "        f1 = f1_score(y_test, prediction)\n",
    "        print(feature,\": \", f1)\n",
    "    print(\"____________________________________________ \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf0b3f",
   "metadata": {},
   "source": [
    "## Using Grid Search for \"tweet\" with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491e481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "vec_train = vectorizer.fit_transform(X_train[\"tweet\"])\n",
    "vec_test = vectorizer.transform(X_test[\"tweet\"])\n",
    "vectors_train = scaler.fit(vec_train)\n",
    "vectors_test = scaler.fit(vec_test)\n",
    "\n",
    "X_train_grid = scaler.transform(vec_train)\n",
    "X_test_grid = scaler.transform(vec_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac241282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet :  0.5153664302600472\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM\n",
    "classifier = svm.SVC(kernel= \"linear\", class_weight='balanced')\n",
    "classifier.fit(vectors_train, y_train)\n",
    "\n",
    "prediction = classifier.predict(vectors_test)\n",
    "\n",
    "# results\n",
    "\"\"\"\n",
    "# alternative: print reports\n",
    "report = classification_report(y_test, prediction, output_dict=True)\n",
    "# print(feature,\": \", report['1'])\n",
    "\"\"\"\n",
    "f1 = f1_score(y_test, prediction)\n",
    "print(feature,\": \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_estimator = svm.SVC()\n",
    "\n",
    "model = GridSearchCV(estimator=svm_estimator,\n",
    "             param_grid={'C': [1, 10, ], 'kernel': (\"linear\", \"rbf\", \"poly\", \"sigmoid\"), 'class_weight': (None, \"balanced\")})\n",
    "model.fit(X_train_grid, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, model.predict(X_test_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcd499",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue;\"> to do:</span>\n",
    "\n",
    "- <span style=\"color: blue;\"> Why best result here worse than \"tweet\", with linear kernel?</span>\n",
    "- <span style=\"color: blue;\"> Finding out which parameters were most successful</span>\n",
    "- <span style=\"color: blue;\"> add Confusion Matrix</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd73aa",
   "metadata": {},
   "source": [
    "## keeping track of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b157cd3",
   "metadata": {},
   "source": [
    "- First SVM (linear) with f1 score for the class \"hate-speech\" around 0.3 for \"tweets\" and most pre-preprocessed text. Lemmatization and stemming do not or only slightly improve results. \n",
    "-Testing out different kernels gives worse results for \"rbf\" and \"poly\". \"sigmoid\" produces similar results.\n",
    "- --> !!! vectors not scaled --> bad performance of some of the models?\n",
    "- using weighted classes gives f1 scores up to 0.62\n",
    "- using GridSearch for the least processed column \"tweets\" gives f1 score of 0.59 (parameters C, kernel and class_weight); using more-preprocessing beforehand might improve results\n",
    "- meaning of parameters:\n",
    "    - gamma:tries to fit non-linear data (maybe only useful for some of the \"features\"?\n",
    "    - C:\n",
    "    - weight-class:\n",
    "- scaling parameters: f1 down to 50% (for \"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066d183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}