{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting seaborn\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/10/5b/0479d7d845b5ba410ca702ffcd7f2cd95a14a4dfff1fde2637802b258b9b/seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from seaborn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting datasets\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/ca/8d/560063945adeb394f01217cff629c2d6e5334060452dc7a507bc504f05cd/datasets-2.2.2-py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from datasets) (1.19.2)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/d7/a3/46b059a7d8e382df1c704b04cab5c9f1b8c5dfeda76eb36d9a64b38d8097/pyarrow-8.0.0-cp37-cp37m-win_amd64.whl (17.8 MB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/bd/4c/166d788feff5c739b833342945bbba406581095fb6c4a056113fae646b5c/fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/4b/28/915e6d4943eab538963a4fac7c409aa4a75213f5e6b98d91334e9a284c5c/multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from datasets) (21.3)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/c1/f2/d6542f1e29b803442e058f7a1b52313bea37da46517b1e840ff2f166450c/huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from datasets) (4.11.3)\n",
      "Collecting aiohttp\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/19/22/7a9ea2992cf7adf534eb51f7b6bfd4642bb15894ac36df4edb0838ee1fdb/aiohttp-3.8.1-cp37-cp37m-win_amd64.whl (551 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from datasets) (1.3.5)\n",
      "Collecting responses<0.19\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/7a/95/4272e2b5668a5afbb1c5e9a82a19ad1d07876bf8221de28f5dd4c9af4888/xxhash-3.0.0-cp37-cp37m-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Collecting dill<0.3.5\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting filelock\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/e8/74/48523f5206b0930f7c6b312890c7ab285dba55cea3f0a303999c5425df08/filelock-3.7.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/c3/7c/1232ac7502f1fe7630b91a9a922641b46cb0c3994c64da5030289a0cbc51/frozenlist-1.3.0-cp37-cp37m-win_amd64.whl (33 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/79/f1/4679ba7965fa10fc5583d762fe1eabb68ba0e2344940f5c766c53ed09fcd/yarl-1.7.2-cp37-cp37m-win_amd64.whl (121 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/71/20/5388d06fab6600b61ff2cfc0ed87a7a8a09d25be9b269ff48d413e8ddb87/multidict-6.0.2-cp37-cp37m-win_amd64.whl (27 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from importlib-metadata->datasets) (3.8.0)\n",
      "Collecting multiprocess\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/aa/d8/d7bbcef5c03890f5fe983d8419b0c5236af3657c5aa9bddf1991a6ed813a/multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, filelock, dill, aiohttp, xxhash, responses, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 filelock-3.7.0 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.6.0 multidict-6.0.2 multiprocess-0.70.12.2 pyarrow-8.0.0 responses-0.18.0 xxhash-3.0.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting transformers\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/52/82/b62f139e77c70fab2763d99d83a77a27a179502430851144a1765e37f5ad/transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/39/d2/659aa43b0297fc61881380fbb0f02872d110e6d91729bb452e7e071da473/regex-2022.4.24-cp37-cp37m-win_amd64.whl (261 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/1c/b6/b41856582bc63d9197160d8360a615e6bfb7206e461d0e1c9bf44fa166ce/tokenizers-0.12.1-cp37-cp37m-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2022.5.18.1)\n",
      "Installing collected packages: tokenizers, regex, transformers\n",
      "Successfully installed regex-2022.4.24 tokenizers-0.12.1 transformers-4.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U imbalanced-learn\n",
    "#!pip install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch\n",
    "# Install hugging face library \n",
    "#only colab\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting emoji\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/68/8a/b08dd0b946f0843cba782e3784cd979c33f144e5e7c37fb0162dc47acd43/emoji-1.7.0.tar.gz (175 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=57be5009c861d0f32a3e1a67a09bf70c20704f9b7cc7496a9ca6765cfde60a72\n",
      "  Stored in directory: c:\\users\\d073999\\appdata\\local\\pip\\cache\\wheels\\ba\\47\\17\\0f71949dd87bfe1dc8ed0d8f2306ed99185f64b3f099c5a092\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting ray\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/b4/6d/37ddaf21cb50e93932919dd68dc965c9975bddf78802d156551d6a3db3f1/ray-1.12.1-cp37-cp37m-win_amd64.whl (19.9 MB)\n",
      "Collecting grpcio<=1.43.0,>=1.28.1\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/e3/25/9b04b5af04f81c68d05a770ee3f55e31392d88cbddfa87311f2b282ea73d/grpcio-1.43.0-cp37-cp37m-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (1.19.2)\n",
      "Collecting virtualenv\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/9e/34/e86fc6a8f84329b49321a532b3c1fef103c67765df957fbb3852eea39d00/virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
      "Collecting protobuf>=3.15.3\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/36/16/cfba8fcd817df923827233115df35dc048af12d0afa13df79b303865855a/protobuf-3.20.1-cp37-cp37m-win_amd64.whl (905 kB)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (1.3.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (4.4.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (8.0.4)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/72/d3/2669479923d8e7129bb7029b5a32c19d1bb99153793e24f90e2b48ec5d5f/msgpack-1.0.3-cp37-cp37m-win_amd64.whl (68 kB)\n",
      "Requirement already satisfied: attrs in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (21.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (3.7.0)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from ray) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from click>=7.0->ray) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from click>=7.0->ray) (0.4.4)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from importlib-metadata->click>=7.0->ray) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from importlib-metadata->click>=7.0->ray) (3.8.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from jsonschema->ray) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from jsonschema->ray) (5.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->ray) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->ray) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->ray) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from requests->ray) (2022.5.18.1)\n",
      "Collecting platformdirs<3,>=2\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/ed/22/967181c94c3a4063fe64e15331b4cb366bdd7dfbf46fcb8ad89650026fec/platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/ac/a3/8ee4f54d5f12e16eeeda6b7df3dfdbda24e6cc572c86ff959a4ce110391b/distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "Installing collected packages: platformdirs, distlib, virtualenv, protobuf, msgpack, grpcio, ray\n",
      "Successfully installed distlib-0.3.4 grpcio-1.43.0 msgpack-1.0.3 platformdirs-2.5.2 protobuf-3.20.1 ray-1.12.1 virtualenv-20.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Collecting redis\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/c3/d8/46f3c0dadb5499031282b43d9c280a3c3d70107b6b0217122a92476fb5b0/redis-4.3.1-py3-none-any.whl (241 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.0 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from redis) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from redis) (4.1.1)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from redis) (4.0.2)\n",
      "Requirement already satisfied: packaging>=20.4 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from redis) (21.3)\n",
      "Collecting deprecated>=1.2.3\n",
      "  Using cached https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/51/6a/c3a0408646408f7283b7bc550c30a32cc791181ec4618592eec13e066ce3/Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/e7/a1/a9596c5858c4a58be8cdd5e8b0e5f53f9c1c17f0616b47edde8de1a356fe/wrapt-1.14.1-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from importlib-metadata>=1.0->redis) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages (from packaging>=20.4->redis) (3.0.4)\n",
      "Installing collected packages: wrapt, deprecated, redis\n",
      "Successfully installed deprecated-1.2.13 redis-4.3.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ouON3UCYzbV5"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import list_datasets, load_dataset # hugging face dataset\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "import torch\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ray' has no attribute '_private'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17148\\83804687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#import torchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#import torchvision.transforms as transforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCLIReporter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedulers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mASHAScheduler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\ray\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0m_configure_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;31m# Delete configuration function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0m_configure_system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\ray\\__init__.py\u001b[0m in \u001b[0;36m_configure_system\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_redis_empty_recv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     if (\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'ray' has no attribute '_private'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "30c86a37e1b34b7892f491d0c7838d69",
      "186a0b0e05ab45d0852280684e368037",
      "fc2c69fa052f4e529e70e8f39d992ca6",
      "73f50dcf300943eeb9e64fb22d4ba5f2",
      "7ec65a3b88774ef587d4f6f585ed9996",
      "48aee991747640899d33428d0f50ec5a",
      "97d5f84a7ddd46548df2535b509dc667",
      "d1d02b98452f404f9c2c2e2158d6ae43",
      "f108e8970ea449b0a961c1435d3131f6",
      "c8f2723f25384eea8ec21449aee72735",
      "8163d148c1f9406389ce37bca1136ab4",
      "4645558d3d224648ae1734a22fbbf5b9",
      "19134e72ec634514b5a8e1720d4e846f",
      "28b13f017d294211813836c62085641d",
      "b580e296c16d43ca9122094aafdf66a3",
      "0f04669015554813b6848b017e764d21",
      "75815ec7051c4468aada07066da22887",
      "40250b89d07f46379d2cbf51b6432a99",
      "2bc90466ec6a4e34998fdfd86ffa748c",
      "405f95147fbd49158729402a408b1f4b",
      "2653fe7832bf4192a17161a3b0a6db29",
      "40793fcbbcb042b1804479183a26d818",
      "d34002c4855443b6ab6a4579370d97c9",
      "d8ff69c7f5b041a2811455afcfe7e75e",
      "35f9746dcb474b5d8b984ab8b130ca61",
      "0dda326563f34d22ab738e4580201837",
      "f0f74da5b2194423bf029669d3fb5393",
      "362451df9e6740cfbd0876f8faed0635",
      "0bdeb2bc79d34d8d87ed90cf1018d8f8",
      "f8f0423930bc45f5bf804a460ac8bc17",
      "5d90a6757eb14ea1a63c6a2c0a43fe3e",
      "110cb9c5849f4863a616781d9e44e8bf",
      "cab83eebb90c40c7959ba2b96c62e737",
      "bec7393d65a3473b9751d8edc76b822e",
      "7fd8003481244289aa15330882262072",
      "99566fb78cdc42258b794cd206a0b065",
      "49f3dd43ee4e45f785de805ba42a4b8e",
      "8e76625d244c40fdb4f3f339399fd134",
      "fb25b1bf6d3e4c9b9fe803a040505a4c",
      "e01b3d643788472fac12e0ab2cc41d8b",
      "40491610a50a4467a911493e77a65fab",
      "ef666c7dff8c427fad9e174087ae243d",
      "35b37ef4b75f44e388e9b1ef2ea4422e",
      "1fd7395c9cef444995ae016e03e35ef9",
      "18978f522ffd4ac08807859d47a7d53a",
      "5160b847c2734132b64a4e9ae6624d86",
      "2233b31160ec485692ba718f6696f3bb",
      "00ca26e84295448e8e05b4749684215b",
      "604279b38347409eb81204bcafcad6d1",
      "91ee2e644d3644519be87de5c4e9809c",
      "cad405058b7a4e9f9ab6dfc1ae4b302e",
      "4beb00e888f748bf93f41cda29bec42f",
      "50220ff6ce5741d887af2895553a4322",
      "f1ee6df5ca184a97a1257bd2ac898d46",
      "dbdadcec1063438e908113aa545a6503"
     ]
    },
    "id": "b0W288XidBxA",
    "outputId": "e8de0289-8269-4d8c-a062-681509eaa933"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4d8234117474580f1deca014cbae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e3bbaa8bfa4a78ac406d2386d198c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/881 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\D073999\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5314450a22141d0a740bfc865ce7329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"tweets_hate_speech_detection\")\n",
    "df = pd.DataFrame.from_dict(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ljcQ-3YE-Yz",
    "outputId": "f81e2044-a03c-4385-df77-bfd54c37c82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount= True)\n",
    "except ImportError as e:\n",
    "    print(\"error\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCT2Lsoalom1",
    "outputId": "ca76dda2-f584-4209-cac0-c18258f0f2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/uni-mannheim/web-mining/project_v_2\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/MyDrive/uni-mannheim/web-mining/project_v_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-fTSYxxOymsu",
    "outputId": "301d3914-e2e3-4657-e498-36ec6123d505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FsP6Oi5ay373",
    "outputId": "6826cdc8-24ff-4212-e5f9-69993e6f2a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.19.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache\n",
      "Location: c:\\users\\d073999\\miniconda3\\envs\\torch\\lib\\site-packages\n",
      "Requires: filelock, regex, pyyaml, importlib-metadata, numpy, requests, packaging, tqdm, huggingface-hub, tokenizers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# check the installed version\n",
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKgHJuNdqpX_"
   },
   "source": [
    "# Upload preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "ef99743096b342d38664d1c7b5f81cfc",
      "aa25af278aad4f40a540c3bdc2dc3f3f",
      "04b411b856c34bae8ba4b383be1384dc",
      "15eea04dfbc8465489014b0d6c0c3cc1",
      "f4a8024279fa4622a18c8337bfddedae",
      "f0660e67645e49369a72a5d5fed7939f",
      "653aa77918fb41ce8d1f134593a4418d",
      "b1d2c93ea7414918beb99a8bf14b6d05",
      "74bb34ff58334770ab25d7465bbb6a72",
      "ffc05b8a74384243b43ae1afd904e252",
      "e8f27796c09a4cdb980cbe3b5966d60a"
     ]
    },
    "id": "YXA-Ujl0G0MZ",
    "outputId": "4367099a-8421-43d0-aaf1-fab577501fc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\D073999\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8288997fb30f465bb33cfe2a43991b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_list = list_datasets() \n",
    "hate_speech = load_dataset(\"tweets_hate_speech_detection\")\n",
    "df = hate_speech[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9Pflp2l6yisA"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by='tweet', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4U6OdFjjnWNX",
    "outputId": "abd6c79e-1726-455e-94c8-23041db296e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# removing usernames from tweet\n",
    "df['tweet'] = df.tweet.str.replace('@user', '', regex=True) \n",
    "# rmoveing punktuation\n",
    "df[\"tweet\"] = df[\"tweet\"].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "# removing hashes\n",
    "df[\"tweet\"] = df[\"tweet\"].str.replace(\"#\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0-8e71jkZq87"
   },
   "outputs": [],
   "source": [
    "all_texts = list(df.tweet)\n",
    "all_labels = list(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jP3QiLFgd-iN",
    "outputId": "02a2d0a6-60aa-4081-f2d9-7676c69af951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' duchess roxie sinesh suppo oil gas jobs single mothers fathers ', ' daughter just got graduated imma proud momma jurk throwback tuesday to family ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def transform_text(text):\n",
    "    \n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(text))\n",
    "    # lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "         # remove everything that is not a word \n",
    "    text =  re.sub(\"[^a-z]+\", \" \",text)\n",
    "    \n",
    "   \n",
    "\n",
    "    # remove Links \n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "\n",
    "    # remove emojis\n",
    "    text = emoji.demojize(text.lower(), language='en')\n",
    "    \n",
    "    return text\n",
    "\n",
    "all_texts_preprocessed = []\n",
    "for i in range(len(all_texts)):\n",
    "    all_texts_preprocessed.append(transform_text(all_texts[i]))\n",
    "\n",
    "\n",
    "\n",
    "print(all_texts_preprocessed[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcQmUe-mY-_D",
    "outputId": "01f84285-14d3-40d7-9680-b1249b5085fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " length of train is: 25569, length of validation data is: 3196, length of test data is: 3197\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_texts, all_labels, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED, shuffle=True)\n",
    "print(f' length of train is: {len(X_train)}, length of validation data is: {len(X_val)}, length of test data is: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "NeMe2WQfOIxP",
    "outputId": "9fb2adbd-32ec-4b3f-fad1-b436c3d9f051"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Miniconda3\\envs\\torch\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=sns.countplot(all_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqmCaX13EjRz"
   },
   "source": [
    "Balance positive class for train data by oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "gj4kAqj6blyF",
    "outputId": "8e57459b-a624-463e-e8e0-0f48bb592a97"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have resurrected from the twitter dead  i am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harrods           harrods  love    selfie  smi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when you are wanted to be somewhere today but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>waking up hoping your dream was real    needahug</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to find out about this   rip  bretagne  ripb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  label\n",
       "0  i have resurrected from the twitter dead  i am...      0\n",
       "1  harrods           harrods  love    selfie  smi...      0\n",
       "2  when you are wanted to be somewhere today but ...      0\n",
       "3   waking up hoping your dream was real    needahug      0\n",
       "4    to find out about this   rip  bretagne  ripb...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "sampler = RandomOverSampler()\n",
    "X_train, y_train = sampler.fit_resample(np.array(X_train).reshape(-1,1), list(y_train))\n",
    "data = X_train\n",
    "label = y_train\n",
    "class_dist = pd.Series(label).value_counts()\n",
    "plt.bar(class_dist.index, class_dist)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "data.flatten()\n",
    "data = pd.DataFrame(data, columns = ['reviewText'])\n",
    "data['label'] = label\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCUmBPod2Lx_",
    "outputId": "bee5315d-1e0c-4a68-ce52-bef9ff07ae63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8cdf94f59045179ec63cc3b659c879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce74aee0c2b4dedbc6a68b487fd6cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f85851b626341378fdc5de4bcfc6be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "# Specify the pre-trained model name.\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased' #\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "T8iu447t2RNl"
   },
   "outputs": [],
   "source": [
    "# Print the preprocessed review text.\n",
    "#print('Preprocessed Text: {}'.format(X_train[2]))\n",
    "\n",
    "# Print the text split into tokens.\n",
    "#print('Tokens: {}'.format(tokenizer.tokenize(X_train[2])))\n",
    "\n",
    "# Print the tokens mapped to token ids.\n",
    "#print('Token IDs: {}'.format(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X_train[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hNKfP0rM2hTA"
   },
   "outputs": [],
   "source": [
    "# So to put all the things together,\n",
    "# we can write a class: with the input texts, labels, tokenizer and max_len\n",
    "# we'll have the review_text, input_ids, attention_mask, labels as our output\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    label = self.labels[item]\n",
    "    # `encode_plus` will:\n",
    "      #   (1) Tokenize the text.\n",
    "      #   (2) Prepend the `[CLS]` token to the start.\n",
    "      #   (3) Append the `[SEP]` token to the end.\n",
    "      #   (4) Map tokens to their IDs.\n",
    "      #   (5) Pad or truncate the sentence to `max_length` with [PAD] tokens\n",
    "      #   (6) Create attention masks for [PAD] tokens\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True, # Add '[CLS]' and '[SEP]' and [PAD]\n",
    "      max_length=self.max_len, # Pad & truncate all texts\n",
    "      pad_to_max_length=True,\n",
    "      return_token_type_ids=False,\n",
    "      return_attention_mask=True, # Construct attention masks\n",
    "      return_tensors='pt', # Return pytorch tensors\n",
    "    )\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'labels': torch.tensor(label, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "wYiVdzkh2l7X"
   },
   "outputs": [],
   "source": [
    "# Then we use DataLoader class from pytorch https://pytorch.org/docs/stable/data.html\n",
    "# which help us to customizing data loading order and do automatic batching\n",
    "def create_data_loader(X, Y, tokenizer, max_len, batch_size, num_workers=0, sampler = None):\n",
    "  ds = ReviewDataset(\n",
    "    reviews=np.array(X),\n",
    "    labels=np.array(Y),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  if sampler!=None:\n",
    "    sampler = sampler(ds)\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    sampler = sampler\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "bhLfn9r-2mlh"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order.\n",
    "train_data_loader = create_data_loader(X_train, y_train, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Select batches randomly\n",
    "\n",
    "# For validation & testing samples, the order doesn't matter, so we'll just read them sequentially.\n",
    "val_data_loader = create_data_loader(X_val, y_val, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially.\n",
    "\n",
    "test_data_loader = create_data_loader(X_test, y_test, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qbwDbQ02qp8",
    "outputId": "0c75ce46-0681-4c38-b3d7-00b4e0ccae90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels, in our case it's multi-class tasks with classes=3  \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNngABf02_gt",
    "outputId": "ef346d7b-c967-4b26-a74b-eb24212dfb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (28996, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz_Qf6p_37lH",
    "outputId": "1ee0700c-7417-478b-8b78-eaf85a4467b4"
   },
   "outputs": [],
   "source": [
    "# More optimizers to look up: https://pytorch.org/docs/stable/optim.html\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 1e-3\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-6.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7m_IRHFr4C4a"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4 (depend on the usage, you can also set it larger)\n",
    "# We chose to run for 3\n",
    "EPOCHS = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler, here we use a linear scheduler with no warmup steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Define our loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "KMpWN5x64MIq"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "  model.train()\n",
    "  total_train_accuracy = 0\n",
    "  total_train_loss = 0\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  for step, batch in enumerate(data_loader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "       print('Batch: {}  of  {}'.format(step, len(data_loader)))\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    model.zero_grad()\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      token_type_ids=None,\n",
    "      attention_mask=attention_mask,\n",
    "      labels=labels\n",
    "    )\n",
    "    loss = outputs[0]\n",
    "    total_train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)# avoid exploding gradients\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = outputs[1].detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "    total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "  # Calculate the average loss over all of the batches.\n",
    "  avg_train_accuracy = total_train_accuracy / len(data_loader)\n",
    "  avg_train_loss = total_train_loss / len(data_loader) \n",
    "  return avg_train_accuracy, avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "u1rNQs4g4P1T"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    #print(\"acc shape\", preds.shape)\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def f1Score(preds, labels):\n",
    "    #print(\"f1 score\", np.array(preds).shape)\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    #return f1_score(pred_flat, labels_flat, average='micro')\n",
    "    return pred_flat, labels_flat\n",
    "\n",
    "def flatten_arrays(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return pred_flat, labels_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "2_7eBapl4TIX"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model.eval()\n",
    "  total_eval_accuracy = 0\n",
    "  total_f1_score = 0\n",
    "  total_eval_loss = 0\n",
    "  nb_eval_steps = 0\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  train_metrics_f1 = []\n",
    "  f1_label_ids = []\n",
    "  f1_logits = []\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "      train_f1 = 0.0 # f1\n",
    "      batch_cnt = 0\n",
    "      input_ids = batch[\"input_ids\"].to(device)\n",
    "      attention_mask = batch[\"attention_mask\"].to(device)\n",
    "      labels = batch[\"labels\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        token_type_ids=None,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels\n",
    "      )\n",
    "      total_eval_loss += outputs[0].item()\n",
    "      logits = outputs[1].detach().cpu().numpy()\n",
    "      label_ids = labels.to('cpu').numpy()\n",
    "      total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "      logits_flat,label_ids_flat = f1Score(logits, label_ids)\n",
    "      f1_label_ids.extend(label_ids_flat)\n",
    "      f1_logits.extend(logits_flat)\n",
    "      batch_cnt += 1\n",
    "\n",
    "  print(\"f1-score: \", f1_score(f1_logits, f1_label_ids))\n",
    "  print(classification_report(f1_label_ids, f1_logits, digits=3))\n",
    "\n",
    "  avg_val_accuracy = total_eval_accuracy / len(data_loader)\n",
    "  avg_val_loss = total_eval_loss / len(data_loader)\n",
    "  #print(\"f1-score: \", train_f1/len(data_loader))\n",
    "  #print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "  #print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "  return avg_val_accuracy, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiagChiQ4WpU",
    "outputId": "9bb74d19-7c9e-4439-a1b1-08a66910ead6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40  of  1485\n",
      "Batch: 80  of  1485\n",
      "Batch: 120  of  1485\n",
      "Batch: 160  of  1485\n",
      "Batch: 200  of  1485\n",
      "Batch: 240  of  1485\n",
      "Batch: 280  of  1485\n",
      "Batch: 320  of  1485\n",
      "Batch: 360  of  1485\n",
      "Batch: 400  of  1485\n",
      "Batch: 440  of  1485\n",
      "Batch: 480  of  1485\n",
      "Batch: 520  of  1485\n",
      "Batch: 560  of  1485\n",
      "Batch: 600  of  1485\n",
      "Batch: 640  of  1485\n",
      "Batch: 680  of  1485\n",
      "Batch: 720  of  1485\n",
      "Batch: 760  of  1485\n",
      "Batch: 800  of  1485\n",
      "Batch: 840  of  1485\n",
      "Batch: 880  of  1485\n",
      "Batch: 920  of  1485\n",
      "Batch: 960  of  1485\n",
      "Batch: 1000  of  1485\n",
      "Batch: 1040  of  1485\n",
      "Batch: 1080  of  1485\n",
      "Batch: 1120  of  1485\n",
      "Batch: 1160  of  1485\n",
      "Batch: 1200  of  1485\n",
      "Batch: 1240  of  1485\n",
      "Batch: 1280  of  1485\n",
      "Batch: 1320  of  1485\n",
      "Batch: 1360  of  1485\n",
      "Batch: 1400  of  1485\n",
      "Batch: 1440  of  1485\n",
      "Batch: 1480  of  1485\n",
      "Train loss: 0.1351023903487388, Accuracy: 0.952459114959115\n",
      "f1-score:  0.7047146401985113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.983     0.980      2987\n",
      "           1      0.732     0.679     0.705       209\n",
      "\n",
      "    accuracy                          0.963      3196\n",
      "   macro avg      0.855     0.831     0.842      3196\n",
      "weighted avg      0.962     0.963     0.962      3196\n",
      "\n",
      "Val loss: 0.21574480840678006, Accuracy: 0.9627232142857143\n",
      "\n",
      "Epoch: 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40  of  1485\n",
      "Batch: 80  of  1485\n",
      "Batch: 120  of  1485\n",
      "Batch: 160  of  1485\n",
      "Batch: 200  of  1485\n",
      "Batch: 240  of  1485\n",
      "Batch: 280  of  1485\n",
      "Batch: 320  of  1485\n",
      "Batch: 360  of  1485\n",
      "Batch: 400  of  1485\n",
      "Batch: 440  of  1485\n",
      "Batch: 480  of  1485\n",
      "Batch: 520  of  1485\n",
      "Batch: 560  of  1485\n",
      "Batch: 600  of  1485\n",
      "Batch: 640  of  1485\n",
      "Batch: 680  of  1485\n",
      "Batch: 720  of  1485\n",
      "Batch: 760  of  1485\n",
      "Batch: 800  of  1485\n",
      "Batch: 840  of  1485\n",
      "Batch: 880  of  1485\n",
      "Batch: 920  of  1485\n",
      "Batch: 960  of  1485\n",
      "Batch: 1000  of  1485\n",
      "Batch: 1040  of  1485\n",
      "Batch: 1080  of  1485\n",
      "Batch: 1120  of  1485\n",
      "Batch: 1160  of  1485\n",
      "Batch: 1200  of  1485\n",
      "Batch: 1240  of  1485\n",
      "Batch: 1280  of  1485\n",
      "Batch: 1320  of  1485\n",
      "Batch: 1360  of  1485\n",
      "Batch: 1400  of  1485\n",
      "Batch: 1440  of  1485\n",
      "Batch: 1480  of  1485\n",
      "Train loss: 0.020364300005850523, Accuracy: 0.9955176767676768\n",
      "f1-score:  0.7263427109974424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.987     0.982      2987\n",
      "           1      0.780     0.679     0.726       209\n",
      "\n",
      "    accuracy                          0.967      3196\n",
      "   macro avg      0.879     0.833     0.854      3196\n",
      "weighted avg      0.965     0.967     0.965      3196\n",
      "\n",
      "Val loss: 0.25661594410285943, Accuracy: 0.9665178571428571\n",
      "\n",
      "Epoch: 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40  of  1485\n",
      "Batch: 80  of  1485\n",
      "Batch: 120  of  1485\n",
      "Batch: 160  of  1485\n",
      "Batch: 200  of  1485\n",
      "Batch: 240  of  1485\n",
      "Batch: 280  of  1485\n",
      "Batch: 320  of  1485\n",
      "Batch: 360  of  1485\n",
      "Batch: 400  of  1485\n",
      "Batch: 440  of  1485\n",
      "Batch: 480  of  1485\n",
      "Batch: 520  of  1485\n",
      "Batch: 560  of  1485\n",
      "Batch: 600  of  1485\n",
      "Batch: 640  of  1485\n",
      "Batch: 680  of  1485\n",
      "Batch: 720  of  1485\n",
      "Batch: 760  of  1485\n",
      "Batch: 800  of  1485\n",
      "Batch: 840  of  1485\n",
      "Batch: 880  of  1485\n",
      "Batch: 920  of  1485\n",
      "Batch: 960  of  1485\n",
      "Batch: 1000  of  1485\n",
      "Batch: 1040  of  1485\n",
      "Batch: 1080  of  1485\n",
      "Batch: 1120  of  1485\n",
      "Batch: 1160  of  1485\n",
      "Batch: 1200  of  1485\n",
      "Batch: 1240  of  1485\n",
      "Batch: 1280  of  1485\n",
      "Batch: 1320  of  1485\n",
      "Batch: 1360  of  1485\n",
      "Batch: 1400  of  1485\n",
      "Batch: 1440  of  1485\n",
      "Batch: 1480  of  1485\n",
      "Train loss: 0.006038798130619472, Accuracy: 0.9988636363636364\n",
      "f1-score:  0.731457800511509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.987     0.983      2987\n",
      "           1      0.786     0.684     0.731       209\n",
      "\n",
      "    accuracy                          0.967      3196\n",
      "   macro avg      0.882     0.836     0.857      3196\n",
      "weighted avg      0.966     0.967     0.966      3196\n",
      "\n",
      "Val loss: 0.2806250959848694, Accuracy: 0.9670982142857143\n",
      "\n",
      "Wall time: 39min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(X_train)\n",
    "  )\n",
    "  print('Train loss: {}, Accuracy: {}'.format(train_loss, train_acc))\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(X_val)\n",
    "  )\n",
    "  print('Val loss: {}, Accuracy: {}'.format(val_loss, val_acc))\n",
    "  print()\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc\n",
    "\n",
    "\n",
    "# last output Val loss: 0.1250698012439534, Accuracy: 0.971205357142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dcn546rV4bOJ",
    "outputId": "ef3b3341-95e2-4d97-8591-a85797b4384e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score:  0.7263922518159807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.986     0.981      2975\n",
      "           1      0.785     0.676     0.726       222\n",
      "\n",
      "    accuracy                          0.965      3197\n",
      "   macro avg      0.881     0.831     0.854      3197\n",
      "weighted avg      0.963     0.965     0.963      3197\n",
      "\n",
      "Testing Accuracy: 0.9646875\n"
     ]
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(X_test)\n",
    ")\n",
    "print('Testing Accuracy: {}'.format(test_acc.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh8N0me_BCEN"
   },
   "source": [
    "# **Using uncased BERT**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoqjTee3BM2Z",
    "outputId": "d35bc124-4cb9-47e5-e402-0176572f736a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Specify the pre-trained model name.\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)\n",
    "\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels, in our case it's multi-class tasks with classes=3  \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "WpgVbBXPB0HQ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order.\n",
    "train_data_loader = create_data_loader(X_train, y_train, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Select batches randomly\n",
    "\n",
    "# For validation & testing samples, the order doesn't matter, so we'll just read them sequentially.\n",
    "val_data_loader = create_data_loader(X_val, y_val, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially.\n",
    "\n",
    "test_data_loader = create_data_loader(X_test, y_test, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bvyuqrn6CICo",
    "outputId": "b08673b7-ceb1-4c67-80a3-81dbfd21e817"
   },
   "outputs": [],
   "source": [
    "# More optimizers to look up: https://pytorch.org/docs/stable/optim.html\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 1e-3\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-6.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "WTTRzolfCOKF"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4 (depend on the usage, you can also set it larger)\n",
    "# We chose to run for 3\n",
    "EPOCHS = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler, here we use a linear scheduler with no warmup steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Define our loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pVBo1ZtCX39",
    "outputId": "96a0910b-eb2a-43f3-efaf-7dd512acb20d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Using Bert uncased pretrained Model\n",
      "Epoch: 1/3\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 8.00 GiB total capacity; 6.44 GiB already allocated; 0 bytes free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17148\\2493993459.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m     17\u001b[0m       \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m       \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     )\n\u001b[0;32m     21\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1564\u001b[0m         )\n\u001b[0;32m   1565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1025\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m         )\n\u001b[0;32m   1029\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    611\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m                 )\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         )\n\u001b[0;32m    537\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 8.00 GiB total capacity; 6.44 GiB already allocated; 0 bytes free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "print(\"2. Using Bert uncased pretrained Model\")\n",
    "for epoch in range(EPOCHS):\n",
    "  print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(X_train)\n",
    "  )\n",
    "  print('Train loss: {}, Accuracy: {}'.format(train_loss, train_acc))\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(X_val)\n",
    "  )\n",
    "  print('Val loss: {}, Accuracy: {}'.format(val_loss, val_acc))\n",
    "  print()\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc\n",
    "\n",
    "\n",
    "# last output Val loss: 0.1250698012439534, Accuracy: 0.971205357142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9Hgmo9G8LMns",
    "outputId": "edc57874-9748-44df-cb60-df88cf98c5d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score:  0.7707317073170732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.990     0.984      2975\n",
      "           1      0.840     0.712     0.771       222\n",
      "\n",
      "    accuracy                          0.971      3197\n",
      "   macro avg      0.910     0.851     0.878      3197\n",
      "weighted avg      0.969     0.971     0.969      3197\n",
      "\n",
      "Testing Accuracy: 0.9705926724137932\n"
     ]
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(X_test)\n",
    ")\n",
    "print('Testing Accuracy: {}'.format(test_acc.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tfDomgSK4wm"
   },
   "source": [
    "### RoBerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "361f84f26ce24ed1bf73bc9a5d70c8bc",
      "6bc05b517af94808bcae88bee3222765",
      "65e74b1e387c44a381d41f55d0125f84",
      "edede2c721e64864b6c95ff7e8cb5364",
      "2ee0bc4ba32549f4b03464c3c09295d1",
      "20243ce309c0422597b47dcfaf62c898",
      "95dce82673624c609fc0a76aabde8b66",
      "73c2e7422ef44d0eb76040317e0d539e",
      "49765ef497934781b180d27a2e56e633",
      "cf2a59247e7248b680246b7f0b3ace62",
      "267e577c5d004eecb473f06ea93a7980",
      "f1eb9254710b4dd5b1646c8aebf6eea3",
      "6c39694a28eb4472bf3c3f08f371ff05",
      "de849959cc1c48978f818806c246630b",
      "1b5b947c9485499e8f7655d47c4a61fd",
      "9ec796fcd2434bc7903a7ecd2a708282",
      "a70e5ab8eae147b98e47bd1a9592134b",
      "a9b4d18d398f4acaa163f0081def5ab7",
      "6d5f212001e54c338137b921ec028dfe",
      "cf48084e8b9d4540b2c23eeb0e2da262",
      "94f6c2a1dbcb44928984a61be600b8ff",
      "d2db308ab95d492ca28e07f17aedbfbc",
      "980b5446fb934d6cbc71f710f616dc7f",
      "af5edc633b7a42cab48bd650e4190546",
      "a3426b48639f4d16b849467174293cde",
      "8276bb209ca24b27b92673410d56b7ae",
      "5c2379295cc3465ebaf85798476a07e6",
      "59472bf2571542c19b3780ff3e9a9f9d",
      "7327aafaa1224b5d8debfe5cd04b0276",
      "61a6e759e53a4f98a8d7041c7353d706",
      "19833cfc6dc14c5a90fc78fb3b73c505",
      "a7c62ba2c20845019dbee5c7ff819e02",
      "0e816028472b46129dfc040a4c843224",
      "ae774fbe80504a589ef46df6ddb22287",
      "58f206984c694f7a82b3fe77e081e50d",
      "a7778257233147e7bece9ebf796e301f",
      "a74c2d4086934bcb80ba2654845b9fef",
      "3726ed517c5c4b1ebe55d3670067a51d",
      "43e5eabfb9bf4ad782a064d6b7d5d62b",
      "e68a0b535903401ab638e983711e7eed",
      "cca731ef81fd448b89da2b4df3b82cdf",
      "f093a8c575cf46e9b673b2902792f4a0",
      "39aa76e922c5466cbe401f22450d7618",
      "0ed1ec47524b476fb02c8d540f0510e3",
      "f711eedcb5324cc18a152b3ae7a5695f",
      "761c8bccbb4c4ceb920916827e1745fe",
      "0d4211eaddff414490d8fbf99755389a",
      "794365564589477ba209bff2a225032f",
      "ae86609b1a264b30acec87d0e07a180c",
      "4ce1142139394c6e8cfc9436aa24cf4d",
      "f6eb5eea7c194542a374d734b28a7374",
      "4e1b1260e2d148bdb9b38c7a54e6c9b9",
      "695578a3cec1426bb8fcce8d413eb9a6",
      "f9e9a59ec6f240a18753096837ca89e1",
      "632280a9c59a46f091dc686ab616d4dc"
     ]
    },
    "id": "E84sjTSlKkEC",
    "outputId": "65997a40-bc1d-4ae4-df77-cb4571b6f84a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading roBERTa tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Specify the pre-trained model name.\n",
    "PRE_TRAINED_MODEL_NAME = 'distilroberta-base'\n",
    "\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading roBERTa tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels, in our case it's multi-class tasks with classes=3  \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "69lz0NXAPx_P"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order.\n",
    "train_data_loader = create_data_loader(X_train, y_train, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Select batches randomly\n",
    "\n",
    "# For validation & testing samples, the order doesn't matter, so we'll just read them sequentially.\n",
    "val_data_loader = create_data_loader(X_val, y_val, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially.\n",
    "\n",
    "test_data_loader = create_data_loader(X_test, y_test, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3KiAAQJQKkM",
    "outputId": "7de8d6ba-ebe7-449a-b5d4-f5a659d05ff0"
   },
   "outputs": [],
   "source": [
    "# More optimizers to look up: https://pytorch.org/docs/stable/optim.html\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 1e-3\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-6.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qSX6btBKQQxy"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4 (depend on the usage, you can also set it larger)\n",
    "# We chose to run for 3\n",
    "EPOCHS = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler, here we use a linear scheduler with no warmup steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Define our loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6U8II3NOQW1w",
    "outputId": "dfb30c09-37b6-4511-f167-705dfc7f7684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Using Bert uncased pretrained Model\n",
      "Epoch: 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40  of  1485\n",
      "Batch: 80  of  1485\n",
      "Batch: 120  of  1485\n",
      "Batch: 160  of  1485\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "print(\"2. Using Bert uncased pretrained Model\")\n",
    "for epoch in range(EPOCHS):\n",
    "  print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(X_train)\n",
    "  )\n",
    "  print('Train loss: {}, Accuracy: {}'.format(train_loss, train_acc))\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(X_val)\n",
    "  )\n",
    "  print('Val loss: {}, Accuracy: {}'.format(val_loss, val_acc))\n",
    "  print()\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc\n",
    "\n",
    "\n",
    "# last output Val loss: 0.1250698012439534, Accuracy: 0.971205357142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxzvmwp8LPMt"
   },
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(X_test)\n",
    ")\n",
    "print('Testing Accuracy: {}'.format(test_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17148\\3583037558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;31m#test_best_model(best_trial)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17148\\3583037558.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     config = {\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloguniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tune' is not defined"
     ]
    }
   ],
   "source": [
    "def train_roberta(config, checkpoint_dir=None):\n",
    "\n",
    "    MAX_LEN = 128\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    # Create the DataLoaders for our training and validation sets.\n",
    "    # We'll take training samples in random order.\n",
    "    train_data_loader = create_data_loader(X_train, y_train, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Select batches randomly\n",
    "\n",
    "    # For validation & testing samples, the order doesn't matter, so we'll just read them sequentially.\n",
    "    val_data_loader = create_data_loader(X_val, y_val, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially.\n",
    "\n",
    "    test_data_loader = create_data_loader(X_test, y_test, tokenizer, MAX_LEN, BATCH_SIZE, sampler = SequentialSampler) # Pull out batches sequentially.\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(model)\n",
    "    net.to(device)\n",
    "\n",
    "    # Define our loss function\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr=config[\"lr\"], # args.learning_rate - default is 1e-3\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-6.\n",
    "                )\n",
    "\n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    model.train()\n",
    "    total_train_accuracy = 0\n",
    "    total_train_loss = 0\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for step, batch in enumerate(train_data_loader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            print('Batch: {}  of  {}'.format(step, len(train_data_loader)))\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        token_type_ids=None,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)# avoid exploding gradients\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_accuracy = total_train_accuracy / len(train_data_loader)\n",
    "    avg_train_loss = total_train_loss / len(train_data_loader) \n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_f1_score = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    train_metrics_f1 = []\n",
    "    f1_label_ids = []\n",
    "    f1_logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_data_loader:\n",
    "            train_f1 = 0.0 # f1\n",
    "            batch_cnt = 0\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            total_eval_loss += outputs[0].item()\n",
    "            logits = outputs[1].detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            logits_flat,label_ids_flat = f1Score(logits, label_ids)\n",
    "            f1_label_ids.extend(label_ids_flat)\n",
    "            f1_logits.extend(logits_flat)\n",
    "            batch_cnt += 1\n",
    "\n",
    "    print(\"f1-score: \", f1_score(f1_logits, f1_label_ids))\n",
    "    print(classification_report(f1_label_ids, f1_logits, digits=3))\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_data_loader)\n",
    "    avg_val_loss = total_eval_loss / len(val_data_loader)\n",
    "\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# main loop\n",
    "def main(num_samples=10, max_num_epochs=5, gpus_per_trial=2):\n",
    "    config = {\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([8, 16, 64])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    result = tune.run(\n",
    "        tune.with_parameters(train_roberta),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    #if ray.util.client.ray.is_connected():\n",
    "        # If using Ray Client, we want to make sure checkpoint access\n",
    "        # happens on the server. So we wrap `test_best_model` in a Ray task.\n",
    "        # We have to make sure it gets executed on the same node that\n",
    "        # ``tune.run`` is called on.\n",
    "        #from ray.util.ml_utils.node import force_on_current_node\n",
    "        #remote_fn = force_on_current_node(ray.remote(test_best_model))\n",
    "        #ray.get(remote_fn.remote(best_trial))\n",
    "    #else:\n",
    "        #test_best_model(best_trial)\n",
    "\n",
    "main(num_samples=2, max_num_epochs=2, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF6bphfv4Dsm"
   },
   "outputs": [],
   "source": [
    "\n",
    "# To prevent from retraining models, you can save them to disk and load them\n",
    "# later on\n",
    "import os\n",
    "MODEL_PATH = \"/content/drive/MyDrive/uni-mannheim/DM/project\"\n",
    "def save(model, filename):\n",
    "    torch.save(model.state_dict(), os.path.join(MODEL_PATH, filename))\n",
    "\n",
    "\n",
    "def load(model, filename):\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_PATH, filename)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8DzhmPsE2Nm",
    "outputId": "bc0419c7-33ea-4f35-9582-fdad74529b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount= True)\n",
    "except ImportError as e:\n",
    "    print(\"error\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kL8WTNAGAy3",
    "outputId": "f67b4c5b-1ca0-45e6-95fc-f1df6bf1ec2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/uni-mannheim/DM/project\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/MyDrive/uni-mannheim/DM/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNoxNJANEh-6"
   },
   "outputs": [],
   "source": [
    "save(model, \"fine-_tunned_bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "pxbXu9PsFIP1",
    "outputId": "e5fd5d30-15e0-4856-d113-b2ec142577f1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-63e5925a1bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fine-_tunned_bert.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "load(model, \"fine-_tunned_bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "ZRArpXNpFo1N",
    "outputId": "2788fe57-500a-498a-a13c-c71f449e6512"
   },
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b1fb7ceacde9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/uni-mannheim/DM/project'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/MyDrive/uni-mannheim/DM/project'"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/MyDrive/uni-mannheim/DM/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7TvoxeSFuFM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_and_ROBERTA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ca26e84295448e8e05b4749684215b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1ee6df5ca184a97a1257bd2ac898d46",
      "placeholder": "",
      "style": "IPY_MODEL_dbdadcec1063438e908113aa545a6503",
      "value": " 1/1 [00:00&lt;00:00, 24.14it/s]"
     }
    },
    "04b411b856c34bae8ba4b383be1384dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1d2c93ea7414918beb99a8bf14b6d05",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74bb34ff58334770ab25d7465bbb6a72",
      "value": 1
     }
    },
    "0bdeb2bc79d34d8d87ed90cf1018d8f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d4211eaddff414490d8fbf99755389a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1b1260e2d148bdb9b38c7a54e6c9b9",
      "max": 331070498,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_695578a3cec1426bb8fcce8d413eb9a6",
      "value": 331070498
     }
    },
    "0dda326563f34d22ab738e4580201837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_110cb9c5849f4863a616781d9e44e8bf",
      "placeholder": "",
      "style": "IPY_MODEL_cab83eebb90c40c7959ba2b96c62e737",
      "value": " 3.10M/? [00:00&lt;00:00, 25.8MB/s]"
     }
    },
    "0e816028472b46129dfc040a4c843224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ed1ec47524b476fb02c8d540f0510e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f04669015554813b6848b017e764d21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "110cb9c5849f4863a616781d9e44e8bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15eea04dfbc8465489014b0d6c0c3cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffc05b8a74384243b43ae1afd904e252",
      "placeholder": "",
      "style": "IPY_MODEL_e8f27796c09a4cdb980cbe3b5966d60a",
      "value": " 1/1 [00:00&lt;00:00, 12.36it/s]"
     }
    },
    "186a0b0e05ab45d0852280684e368037": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48aee991747640899d33428d0f50ec5a",
      "placeholder": "",
      "style": "IPY_MODEL_97d5f84a7ddd46548df2535b509dc667",
      "value": "Downloading builder script: "
     }
    },
    "18978f522ffd4ac08807859d47a7d53a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5160b847c2734132b64a4e9ae6624d86",
       "IPY_MODEL_2233b31160ec485692ba718f6696f3bb",
       "IPY_MODEL_00ca26e84295448e8e05b4749684215b"
      ],
      "layout": "IPY_MODEL_604279b38347409eb81204bcafcad6d1"
     }
    },
    "19134e72ec634514b5a8e1720d4e846f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75815ec7051c4468aada07066da22887",
      "placeholder": "",
      "style": "IPY_MODEL_40250b89d07f46379d2cbf51b6432a99",
      "value": "Downloading metadata: "
     }
    },
    "19833cfc6dc14c5a90fc78fb3b73c505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b5b947c9485499e8f7655d47c4a61fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94f6c2a1dbcb44928984a61be600b8ff",
      "placeholder": "",
      "style": "IPY_MODEL_d2db308ab95d492ca28e07f17aedbfbc",
      "value": " 878k/878k [00:00&lt;00:00, 2.83MB/s]"
     }
    },
    "1fd7395c9cef444995ae016e03e35ef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20243ce309c0422597b47dcfaf62c898": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2233b31160ec485692ba718f6696f3bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4beb00e888f748bf93f41cda29bec42f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50220ff6ce5741d887af2895553a4322",
      "value": 1
     }
    },
    "2653fe7832bf4192a17161a3b0a6db29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "267e577c5d004eecb473f06ea93a7980": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28b13f017d294211813836c62085641d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bc90466ec6a4e34998fdfd86ffa748c",
      "max": 881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_405f95147fbd49158729402a408b1f4b",
      "value": 881
     }
    },
    "2bc90466ec6a4e34998fdfd86ffa748c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee0bc4ba32549f4b03464c3c09295d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30c86a37e1b34b7892f491d0c7838d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_186a0b0e05ab45d0852280684e368037",
       "IPY_MODEL_fc2c69fa052f4e529e70e8f39d992ca6",
       "IPY_MODEL_73f50dcf300943eeb9e64fb22d4ba5f2"
      ],
      "layout": "IPY_MODEL_7ec65a3b88774ef587d4f6f585ed9996"
     }
    },
    "35b37ef4b75f44e388e9b1ef2ea4422e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35f9746dcb474b5d8b984ab8b130ca61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8f0423930bc45f5bf804a460ac8bc17",
      "max": 1276746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d90a6757eb14ea1a63c6a2c0a43fe3e",
      "value": 1276746
     }
    },
    "361f84f26ce24ed1bf73bc9a5d70c8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bc05b517af94808bcae88bee3222765",
       "IPY_MODEL_65e74b1e387c44a381d41f55d0125f84",
       "IPY_MODEL_edede2c721e64864b6c95ff7e8cb5364"
      ],
      "layout": "IPY_MODEL_2ee0bc4ba32549f4b03464c3c09295d1"
     }
    },
    "362451df9e6740cfbd0876f8faed0635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3726ed517c5c4b1ebe55d3670067a51d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39aa76e922c5466cbe401f22450d7618": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40250b89d07f46379d2cbf51b6432a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40491610a50a4467a911493e77a65fab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "405f95147fbd49158729402a408b1f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40793fcbbcb042b1804479183a26d818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43e5eabfb9bf4ad782a064d6b7d5d62b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4645558d3d224648ae1734a22fbbf5b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19134e72ec634514b5a8e1720d4e846f",
       "IPY_MODEL_28b13f017d294211813836c62085641d",
       "IPY_MODEL_b580e296c16d43ca9122094aafdf66a3"
      ],
      "layout": "IPY_MODEL_0f04669015554813b6848b017e764d21"
     }
    },
    "48aee991747640899d33428d0f50ec5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49765ef497934781b180d27a2e56e633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "49f3dd43ee4e45f785de805ba42a4b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35b37ef4b75f44e388e9b1ef2ea4422e",
      "placeholder": "",
      "style": "IPY_MODEL_1fd7395c9cef444995ae016e03e35ef9",
      "value": " 31004/31962 [00:01&lt;00:00, 30008.22 examples/s]"
     }
    },
    "4beb00e888f748bf93f41cda29bec42f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ce1142139394c6e8cfc9436aa24cf4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e1b1260e2d148bdb9b38c7a54e6c9b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50220ff6ce5741d887af2895553a4322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5160b847c2734132b64a4e9ae6624d86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91ee2e644d3644519be87de5c4e9809c",
      "placeholder": "",
      "style": "IPY_MODEL_cad405058b7a4e9f9ab6dfc1ae4b302e",
      "value": "100%"
     }
    },
    "58f206984c694f7a82b3fe77e081e50d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43e5eabfb9bf4ad782a064d6b7d5d62b",
      "placeholder": "",
      "style": "IPY_MODEL_e68a0b535903401ab638e983711e7eed",
      "value": "Downloading: 100%"
     }
    },
    "59472bf2571542c19b3780ff3e9a9f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c2379295cc3465ebaf85798476a07e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d90a6757eb14ea1a63c6a2c0a43fe3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "604279b38347409eb81204bcafcad6d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a6e759e53a4f98a8d7041c7353d706": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "632280a9c59a46f091dc686ab616d4dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "653aa77918fb41ce8d1f134593a4418d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65e74b1e387c44a381d41f55d0125f84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c2e7422ef44d0eb76040317e0d539e",
      "max": 480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49765ef497934781b180d27a2e56e633",
      "value": 480
     }
    },
    "695578a3cec1426bb8fcce8d413eb9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bc05b517af94808bcae88bee3222765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20243ce309c0422597b47dcfaf62c898",
      "placeholder": "",
      "style": "IPY_MODEL_95dce82673624c609fc0a76aabde8b66",
      "value": "Downloading: 100%"
     }
    },
    "6c39694a28eb4472bf3c3f08f371ff05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a70e5ab8eae147b98e47bd1a9592134b",
      "placeholder": "",
      "style": "IPY_MODEL_a9b4d18d398f4acaa163f0081def5ab7",
      "value": "Downloading: 100%"
     }
    },
    "6d5f212001e54c338137b921ec028dfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7327aafaa1224b5d8debfe5cd04b0276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73c2e7422ef44d0eb76040317e0d539e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f50dcf300943eeb9e64fb22d4ba5f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8f2723f25384eea8ec21449aee72735",
      "placeholder": "",
      "style": "IPY_MODEL_8163d148c1f9406389ce37bca1136ab4",
      "value": " 3.14k/? [00:00&lt;00:00, 113kB/s]"
     }
    },
    "74bb34ff58334770ab25d7465bbb6a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75815ec7051c4468aada07066da22887": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "761c8bccbb4c4ceb920916827e1745fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ce1142139394c6e8cfc9436aa24cf4d",
      "placeholder": "",
      "style": "IPY_MODEL_f6eb5eea7c194542a374d734b28a7374",
      "value": "Downloading: 100%"
     }
    },
    "794365564589477ba209bff2a225032f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9e9a59ec6f240a18753096837ca89e1",
      "placeholder": "",
      "style": "IPY_MODEL_632280a9c59a46f091dc686ab616d4dc",
      "value": " 316M/316M [00:15&lt;00:00, 58.0MB/s]"
     }
    },
    "7ec65a3b88774ef587d4f6f585ed9996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fd8003481244289aa15330882262072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb25b1bf6d3e4c9b9fe803a040505a4c",
      "placeholder": "",
      "style": "IPY_MODEL_e01b3d643788472fac12e0ab2cc41d8b",
      "value": "Generating train split:  97%"
     }
    },
    "8163d148c1f9406389ce37bca1136ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8276bb209ca24b27b92673410d56b7ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7c62ba2c20845019dbee5c7ff819e02",
      "placeholder": "",
      "style": "IPY_MODEL_0e816028472b46129dfc040a4c843224",
      "value": " 446k/446k [00:00&lt;00:00, 821kB/s]"
     }
    },
    "8e76625d244c40fdb4f3f339399fd134": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91ee2e644d3644519be87de5c4e9809c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94f6c2a1dbcb44928984a61be600b8ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95dce82673624c609fc0a76aabde8b66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97d5f84a7ddd46548df2535b509dc667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "980b5446fb934d6cbc71f710f616dc7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af5edc633b7a42cab48bd650e4190546",
       "IPY_MODEL_a3426b48639f4d16b849467174293cde",
       "IPY_MODEL_8276bb209ca24b27b92673410d56b7ae"
      ],
      "layout": "IPY_MODEL_5c2379295cc3465ebaf85798476a07e6"
     }
    },
    "99566fb78cdc42258b794cd206a0b065": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40491610a50a4467a911493e77a65fab",
      "max": 31962,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef666c7dff8c427fad9e174087ae243d",
      "value": 31962
     }
    },
    "9ec796fcd2434bc7903a7ecd2a708282": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3426b48639f4d16b849467174293cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61a6e759e53a4f98a8d7041c7353d706",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_19833cfc6dc14c5a90fc78fb3b73c505",
      "value": 456318
     }
    },
    "a70e5ab8eae147b98e47bd1a9592134b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a74c2d4086934bcb80ba2654845b9fef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39aa76e922c5466cbe401f22450d7618",
      "placeholder": "",
      "style": "IPY_MODEL_0ed1ec47524b476fb02c8d540f0510e3",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 2.82MB/s]"
     }
    },
    "a7778257233147e7bece9ebf796e301f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cca731ef81fd448b89da2b4df3b82cdf",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f093a8c575cf46e9b673b2902792f4a0",
      "value": 1355863
     }
    },
    "a7c62ba2c20845019dbee5c7ff819e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9b4d18d398f4acaa163f0081def5ab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa25af278aad4f40a540c3bdc2dc3f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0660e67645e49369a72a5d5fed7939f",
      "placeholder": "",
      "style": "IPY_MODEL_653aa77918fb41ce8d1f134593a4418d",
      "value": "100%"
     }
    },
    "ae774fbe80504a589ef46df6ddb22287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58f206984c694f7a82b3fe77e081e50d",
       "IPY_MODEL_a7778257233147e7bece9ebf796e301f",
       "IPY_MODEL_a74c2d4086934bcb80ba2654845b9fef"
      ],
      "layout": "IPY_MODEL_3726ed517c5c4b1ebe55d3670067a51d"
     }
    },
    "ae86609b1a264b30acec87d0e07a180c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af5edc633b7a42cab48bd650e4190546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59472bf2571542c19b3780ff3e9a9f9d",
      "placeholder": "",
      "style": "IPY_MODEL_7327aafaa1224b5d8debfe5cd04b0276",
      "value": "Downloading: 100%"
     }
    },
    "b1d2c93ea7414918beb99a8bf14b6d05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b580e296c16d43ca9122094aafdf66a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2653fe7832bf4192a17161a3b0a6db29",
      "placeholder": "",
      "style": "IPY_MODEL_40793fcbbcb042b1804479183a26d818",
      "value": " 1.84k/? [00:00&lt;00:00, 56.7kB/s]"
     }
    },
    "bec7393d65a3473b9751d8edc76b822e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7fd8003481244289aa15330882262072",
       "IPY_MODEL_99566fb78cdc42258b794cd206a0b065",
       "IPY_MODEL_49f3dd43ee4e45f785de805ba42a4b8e"
      ],
      "layout": "IPY_MODEL_8e76625d244c40fdb4f3f339399fd134"
     }
    },
    "c8f2723f25384eea8ec21449aee72735": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab83eebb90c40c7959ba2b96c62e737": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cad405058b7a4e9f9ab6dfc1ae4b302e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cca731ef81fd448b89da2b4df3b82cdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf2a59247e7248b680246b7f0b3ace62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf48084e8b9d4540b2c23eeb0e2da262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1d02b98452f404f9c2c2e2158d6ae43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2db308ab95d492ca28e07f17aedbfbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d34002c4855443b6ab6a4579370d97c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8ff69c7f5b041a2811455afcfe7e75e",
       "IPY_MODEL_35f9746dcb474b5d8b984ab8b130ca61",
       "IPY_MODEL_0dda326563f34d22ab738e4580201837"
      ],
      "layout": "IPY_MODEL_f0f74da5b2194423bf029669d3fb5393"
     }
    },
    "d8ff69c7f5b041a2811455afcfe7e75e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_362451df9e6740cfbd0876f8faed0635",
      "placeholder": "",
      "style": "IPY_MODEL_0bdeb2bc79d34d8d87ed90cf1018d8f8",
      "value": "Downloading data: "
     }
    },
    "dbdadcec1063438e908113aa545a6503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de849959cc1c48978f818806c246630b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d5f212001e54c338137b921ec028dfe",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf48084e8b9d4540b2c23eeb0e2da262",
      "value": 898823
     }
    },
    "e01b3d643788472fac12e0ab2cc41d8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e68a0b535903401ab638e983711e7eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8f27796c09a4cdb980cbe3b5966d60a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edede2c721e64864b6c95ff7e8cb5364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf2a59247e7248b680246b7f0b3ace62",
      "placeholder": "",
      "style": "IPY_MODEL_267e577c5d004eecb473f06ea93a7980",
      "value": " 480/480 [00:00&lt;00:00, 16.6kB/s]"
     }
    },
    "ef666c7dff8c427fad9e174087ae243d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef99743096b342d38664d1c7b5f81cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa25af278aad4f40a540c3bdc2dc3f3f",
       "IPY_MODEL_04b411b856c34bae8ba4b383be1384dc",
       "IPY_MODEL_15eea04dfbc8465489014b0d6c0c3cc1"
      ],
      "layout": "IPY_MODEL_f4a8024279fa4622a18c8337bfddedae"
     }
    },
    "f0660e67645e49369a72a5d5fed7939f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f093a8c575cf46e9b673b2902792f4a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0f74da5b2194423bf029669d3fb5393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f108e8970ea449b0a961c1435d3131f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1eb9254710b4dd5b1646c8aebf6eea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c39694a28eb4472bf3c3f08f371ff05",
       "IPY_MODEL_de849959cc1c48978f818806c246630b",
       "IPY_MODEL_1b5b947c9485499e8f7655d47c4a61fd"
      ],
      "layout": "IPY_MODEL_9ec796fcd2434bc7903a7ecd2a708282"
     }
    },
    "f1ee6df5ca184a97a1257bd2ac898d46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4a8024279fa4622a18c8337bfddedae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6eb5eea7c194542a374d734b28a7374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f711eedcb5324cc18a152b3ae7a5695f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_761c8bccbb4c4ceb920916827e1745fe",
       "IPY_MODEL_0d4211eaddff414490d8fbf99755389a",
       "IPY_MODEL_794365564589477ba209bff2a225032f"
      ],
      "layout": "IPY_MODEL_ae86609b1a264b30acec87d0e07a180c"
     }
    },
    "f8f0423930bc45f5bf804a460ac8bc17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9e9a59ec6f240a18753096837ca89e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb25b1bf6d3e4c9b9fe803a040505a4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc2c69fa052f4e529e70e8f39d992ca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1d02b98452f404f9c2c2e2158d6ae43",
      "max": 1448,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f108e8970ea449b0a961c1435d3131f6",
      "value": 1448
     }
    },
    "ffc05b8a74384243b43ae1afd904e252": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
