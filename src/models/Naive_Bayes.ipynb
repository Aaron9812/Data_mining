{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifing hate speech tweets\n",
    "## Using Multi-variate Bernoulli Naive Bayes and Multinominal Naive Bayes in combination with count vectorizer and TF-IDF vectorizer\n",
    "\n",
    "### To Do's\n",
    "- Modify Preprocessing (currently default count and TF-IDF vectroizer preprocessing used)\n",
    "    - Implement Emoji transformation\n",
    "    - Implement Morphological Normalization (e.g. Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tweets_hate_speech_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently not in use\n",
    "def remove_punctioation(text:str) -> str:\n",
    "    return \"\".join([i for i in text if i not in punctuation])\n",
    "\n",
    "def tokenization(text:str) -> list:\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(tokens) ->list:\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    return [token for token in tokens if token not in stopwords_list]\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text:list) -> list:\n",
    "    return [porter_stemmer.stem(word) for word in text]\n",
    "\n",
    "def preProcess(list):\n",
    "    return list.apply(lambda x: stemming(remove_stopwords(tokenization(remove_punctioation(x.lower())))))\n",
    "\n",
    "def preProcess2(list):\n",
    "    return list.apply(lambda x: remove_stopwords(tokenization(remove_punctioation(x.lower()))))\n",
    "\n",
    "def dummy(text):\n",
    "    return text\n",
    "\n",
    "def validate(y_test,y_pred):\n",
    "    print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "    print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently not in use\n",
    "df[\"preprocessed\"] = preProcess(df[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_user']= df['tweet'].str.replace(\"user\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Label-Vektors\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Using allready preprocessed tweets\n",
    "tf = text.TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    "    token_pattern=None)\n",
    "\n",
    "\n",
    "X_vec = tf.fit(df['preprocessed'])\n",
    "X = X_vec.transform(df['preprocessed'])\n",
    "\n",
    "print(X.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using unpreprocessed tweets\n",
    "tf = text.TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_vec = tf.fit(df['tweet'])\n",
    "X = X_vec.transform(df['tweet'])\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# No User string\n",
    "# Definition der Feature-Matrix\n",
    "tf = text.TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_vec = tf.fit(df['no_user'])\n",
    "X = X_vec.transform(df['no_user'])\n",
    "\n",
    "print(X.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting of data into training and test data\n",
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Stratification\n",
    "print('There is {} training data, of which {}% is hate speech '.format(y_train.count(), round(y_train.sum()/y_train.count()*100,2)))\n",
    "print('There is {} test data, of which {}% is hate speech '.format(y_test.count(), round(y_test.sum()/y_test.count()*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models\n",
    "The method GridSearchCV is used for hyperparameter optimization. In the following cases the smoothing parameter alpha is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-variate Bernoulli Naive Bayes\n",
    "bnb = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnb.fit(X_train, y_train);\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "mnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "mnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance based on TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, bnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores with the Multinominal Bernoulli Naive Bayes:')\n",
    "validate(y_test, mnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(y_test, mnb.predict(X_test))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# No user string\n",
    "co = text.CountVectorizer(stop_words='english')\n",
    "\n",
    "Xc_vec = co.fit(df['no_user'])\n",
    "Xc = Xc_vec.transform(df['no_user'])\n",
    "\n",
    "print(Xc.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = text.CountVectorizer(stop_words='english')\n",
    "\n",
    "Xc_vec = co.fit(df['tweet'])\n",
    "Xc = Xc_vec.transform(df['tweet'])\n",
    "\n",
    "print(Xc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting of data into training and test data\n",
    "(Xc_train, Xc_test, yc_train, yc_test) = ms.train_test_split(Xc, y, test_size=.2, random_state = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-variate Bernoulli Naive Bayes\n",
    "bnbc = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnbc.fit(Xc_train, yc_train);\n",
    "\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "mnbc = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "mnbc.fit(Xc_train, yc_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance based on Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(yc_test, bnbc.predict(Xc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(yc_test, mnbc.predict(Xc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(yc_test, mnbc.predict(Xc_test))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Get most frequent words including stop words\n",
    "word_freq_df = pd.DataFrame(Xc.toarray(), columns=co.get_feature_names_out())\n",
    "top_words_df = pd.DataFrame(word_freq_df.sum()).sort_values(0, ascending=False)\n",
    "top_words_df.head(10)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get words with biggest impact on each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc = nb.MultinomialNB()\n",
    "mnbc.fit(Xc_train, yc_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words with biggest impact on each category\n",
    "\n",
    "mnbc.feature_log_prob_\n",
    "mnbc.coef_\n",
    "\n",
    "feature_names = co.get_feature_names_out()\n",
    "for i, class_label in enumerate(['no_hate', 'hate']):\n",
    "    top10 = np.argsort(mnbc.feature_log_prob_[i])[-10:]\n",
    "    print(\"%s: %s\" % (class_label,\n",
    "          \" \".join(feature_names[j] for j in top10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vectorizer BEFORE upsampling\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "X_tf_vec = tf.fit(df['tweet'])\n",
    "#X_tf_vec = tf.fit(df['no_user'])\n",
    "\n",
    "co = CountVectorizer(stop_words='english')\n",
    "X_co_vec = co.fit(df['tweet'])\n",
    "#X_co_vec = co.fit(df['no_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Split data\n",
    "y = df['label']\n",
    "X = df['tweet']\n",
    "#X = df['no_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data BEFORE upsampling\n",
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)\n",
    "\n",
    "df_train = pd.concat([y_train,X_train], axis=1)\n",
    "df_test = pd.concat([y_test,X_test], axis = 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minority = df_train[df_train.label == 1]\n",
    "data_majority = df_train[df_train.label == 0]\n",
    "\n",
    "print(\"length majority\", len(data_majority))\n",
    "print(\"length minority\", len(data_minority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "data_minority = resample(data_minority, replace = True, n_samples=23775, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_up = pd.concat([data_majority, data_minority])\n",
    "df_train_up.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# create embeddings\n",
    "\n",
    "# tfifd\n",
    "Xt_train = X_tf_vec.transform(df_train_up['no_user'])\n",
    "Xt_test = X_tf_vec.transform(df_test['no_user'])\n",
    "\n",
    "# count vectorizer\n",
    "Xc_train = X_co_vec.transform(df_train_up['no_user'])\n",
    "Xc_test = X_co_vec.transform(df_test['no_user'])\n",
    "\n",
    "# labels\n",
    "y_train = df_train_up['label']\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(Xt_train.shape) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "\n",
    "# tfifd\n",
    "Xt_train = X_tf_vec.transform(df_train_up['tweet'])\n",
    "Xt_test = X_tf_vec.transform(df_test['tweet'])\n",
    "\n",
    "# count vectorizer\n",
    "Xc_train = X_co_vec.transform(df_train_up['tweet'])\n",
    "Xc_test = X_co_vec.transform(df_test['tweet'])\n",
    "\n",
    "# labels\n",
    "y_train = df_train_up['label']\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(Xt_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Stratification\n",
    "print('There is {} training data, of which {}% is hate speech '.format(df_train_up['label'].count(), round(df_train_up['label'].sum()/df_train_up['label'].count()*100,2)))\n",
    "print('There is {} test data, of which {}% is hate speech '.format(df_test['label'].count(), round(df_test['label'].sum()/df_test['label'].count()*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "# Multi-variate Bernoulli Naive Bayes\n",
    "bnb = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnb.fit(Xt_train, y_train);\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "mnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "mnb.fit(Xt_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF-IDF Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, bnb.predict(Xt_test))\n",
    "print('TF-IDF Scores with the Multinominal Bernoulli Naive Bayes:')\n",
    "validate(y_test, mnb.predict(Xt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "# Multi-variate Bernoulli Naive Bayes\n",
    "cbnb = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "cbnb.fit(Xc_train, y_train);\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "cmnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "cmnb.fit(Xc_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count Vectorizer Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, cbnb.predict(Xc_test))\n",
    "print('Count Vectorizer Scores with the Multinominal Bernoulli Naive Bayes:')\n",
    "validate(y_test, cmnb.predict(Xc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(y_test, cmnb.predict(Xc_test))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b03aa4afe8e1e93efa7641c6ec3d6ea13fef12134f79b85e9488b2fa31c226cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
