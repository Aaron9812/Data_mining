{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifing hate speech tweets\n",
    "## Using Multi-variate Bernoulli Naive Bayes and Multinominal Naive Bayes in combination with count vectorizer and TF-IDF vectorizer\n",
    "\n",
    "### To Do's\n",
    "- Modify Preprocessing (currently default count and TF-IDF vectroizer preprocessing used)\n",
    "    - Implement Emoji transformation\n",
    "    - Implement Morphological Normalization (e.g. Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programme\\Miniconda\\envs\\DataMining\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (C:\\Users\\jonas\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tweets_hate_speech_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  @user when a father is dysfunctional and is so...\n",
       "1      0  @user @user thanks for #lyft credit i can't us...\n",
       "2      0                                bihday your majesty\n",
       "3      0  #model   i love u take with u all the time in ...\n",
       "4      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently not in use\n",
    "def remove_punctioation(text:str) -> str:\n",
    "    return \"\".join([i for i in text if i not in punctuation])\n",
    "\n",
    "def tokenization(text:str) -> list:\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(tokens) ->list:\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    return [token for token in tokens if token not in stopwords_list]\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text:list) -> list:\n",
    "    return [porter_stemmer.stem(word) for word in text]\n",
    "\n",
    "def preProcess(list):\n",
    "    return list.apply(lambda x: stemming(remove_stopwords(tokenization(remove_punctioation(x.lower())))))\n",
    "\n",
    "def preProcess2(list):\n",
    "    return list.apply(lambda x: remove_stopwords(tokenization(remove_punctioation(x.lower()))))\n",
    "\n",
    "def dummy(text):\n",
    "    return text\n",
    "\n",
    "def validate(y_test,y_pred):\n",
    "    print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "    print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently not in use\n",
    "df[\"preprocessed\"] = preProcess(df[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_user']= df['tweet'].str.replace(\"user\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des Label-Vektors\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Using allready preprocessed tweets\n",
    "tf = text.TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    "    token_pattern=None)\n",
    "\n",
    "\n",
    "X_vec = tf.fit(df['preprocessed'])\n",
    "X = X_vec.transform(df['preprocessed'])\n",
    "\n",
    "print(X.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 41104)\n"
     ]
    }
   ],
   "source": [
    "# Using unpreprocessed tweets\n",
    "tf = text.TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_vec = tf.fit(df['tweet'])\n",
    "X = X_vec.transform(df['tweet'])\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 38161,\n",
       " 'father': 12981,\n",
       " 'dysfunctional': 11373,\n",
       " 'selfish': 32080,\n",
       " 'drags': 11051,\n",
       " 'kids': 20140,\n",
       " 'dysfunction': 11372,\n",
       " 'run': 31207,\n",
       " 'thanks': 35980,\n",
       " 'lyft': 22203,\n",
       " 'credit': 8964,\n",
       " 'use': 38152,\n",
       " 'cause': 6850,\n",
       " 'don': 10839,\n",
       " 'offer': 26115,\n",
       " 'wheelchair': 39521,\n",
       " 'vans': 38306,\n",
       " 'pdx': 27319,\n",
       " 'disapointed': 10458,\n",
       " 'getthanked': 14989,\n",
       " 'bihday': 4699,\n",
       " 'majesty': 22413,\n",
       " 'model': 23785,\n",
       " 'love': 21856,\n",
       " 'time': 36564,\n",
       " 'urð': 38135,\n",
       " 'factsguide': 12742,\n",
       " 'society': 33470,\n",
       " 'motivation': 24090,\n",
       " 'huge': 17592,\n",
       " 'fan': 12859,\n",
       " 'fare': 12893,\n",
       " 'big': 4637,\n",
       " 'talking': 35449,\n",
       " 'leave': 20907,\n",
       " 'chaos': 7107,\n",
       " 'pay': 27260,\n",
       " 'disputes': 10579,\n",
       " 'allshowandnogo': 2089,\n",
       " 'camping': 6463,\n",
       " 'tomorrow': 36788,\n",
       " 'dannyâ': 9526,\n",
       " 'school': 31755,\n",
       " 'year': 40502,\n",
       " 'exams': 12432,\n",
       " 'think': 36335,\n",
       " 'hate': 16540,\n",
       " 'imagine': 18115,\n",
       " 'actorslife': 1434,\n",
       " 'revolutionschool': 30617,\n",
       " 'girl': 15111,\n",
       " 'won': 40020,\n",
       " 'land': 20633,\n",
       " 'allin': 2057,\n",
       " 'cavs': 6863,\n",
       " 'champions': 7065,\n",
       " 'cleveland': 7734,\n",
       " 'clevelandcavaliers': 7735,\n",
       " 'welcome': 39329,\n",
       " 'gr8': 15659,\n",
       " 'ireland': 18938,\n",
       " 'consumer': 8464,\n",
       " 'price': 28788,\n",
       " 'index': 18327,\n",
       " 'mom': 23842,\n",
       " 'climbed': 7767,\n",
       " 'previous': 28781,\n",
       " 'blog': 5088,\n",
       " 'silver': 32818,\n",
       " 'gold': 15389,\n",
       " 'forex': 13981,\n",
       " 'orlando': 26579,\n",
       " 'standwithorlando': 34145,\n",
       " 'pulseshooting': 29206,\n",
       " 'orlandoshooting': 26591,\n",
       " 'biggerproblems': 4662,\n",
       " 'heabreaking': 16656,\n",
       " 'values': 38273,\n",
       " 'daddy': 9366,\n",
       " 'today': 36711,\n",
       " '80days': 1044,\n",
       " 'gettingfed': 14997,\n",
       " 'cnn': 7872,\n",
       " 'calls': 6397,\n",
       " 'michigan': 23366,\n",
       " 'middle': 23390,\n",
       " 'build': 6066,\n",
       " 'wall': 38891,\n",
       " 'chant': 7104,\n",
       " 'tcot': 35607,\n",
       " 'comment': 8143,\n",
       " 'australia': 3255,\n",
       " 'opkillingbay': 26465,\n",
       " 'seashepherd': 31925,\n",
       " 'helpcovedolphins': 16843,\n",
       " 'thecove': 36080,\n",
       " 'ouch': 26655,\n",
       " 'junior': 19754,\n",
       " 'angryð': 2447,\n",
       " 'got7': 15599,\n",
       " 'yugyoem': 40773,\n",
       " 'omg': 26271,\n",
       " 'thankful': 35970,\n",
       " 'having': 16597,\n",
       " 'paner': 27023,\n",
       " 'positive': 28431,\n",
       " 'retweet': 30567,\n",
       " 'agree': 1737,\n",
       " 'friday': 14232,\n",
       " 'smiles': 33269,\n",
       " 'ig': 17920,\n",
       " 'cookies': 8567,\n",
       " 'make': 22425,\n",
       " 'people': 27440,\n",
       " 'know': 20327,\n",
       " 'essential': 12242,\n",
       " 'oils': 26178,\n",
       " 'chemicals': 7249,\n",
       " 'euro2016': 12309,\n",
       " 'blaming': 4989,\n",
       " 'ha': 16158,\n",
       " 'conceded': 8288,\n",
       " 'goal': 15299,\n",
       " 'fat': 12970,\n",
       " 'rooney': 31037,\n",
       " 'gave': 14760,\n",
       " 'away': 3351,\n",
       " 'free': 14150,\n",
       " 'kick': 20115,\n",
       " 'knowing': 20328,\n",
       " 'bale': 3655,\n",
       " 'hit': 17100,\n",
       " 'sad': 31342,\n",
       " 'little': 21449,\n",
       " 'dude': 11246,\n",
       " 'badday': 3560,\n",
       " 'coneofshame': 8338,\n",
       " 'cats': 6831,\n",
       " 'pissed': 27923,\n",
       " 'funny': 14491,\n",
       " 'laughs': 20775,\n",
       " 'product': 28903,\n",
       " 'day': 9630,\n",
       " 'happy': 16407,\n",
       " 'man': 22547,\n",
       " 'wine': 39810,\n",
       " 'tool': 36837,\n",
       " 'weekend': 39259,\n",
       " 'open': 26428,\n",
       " 'amp': 2328,\n",
       " 'drink': 11138,\n",
       " 'lumpy': 22157,\n",
       " 'says': 31676,\n",
       " 'prove': 29066,\n",
       " 'tgif': 35943,\n",
       " 'ff': 13279,\n",
       " 'gamedev': 14650,\n",
       " 'indiedev': 18349,\n",
       " 'indiegamedev': 18352,\n",
       " 'squad': 34028,\n",
       " 'beautiful': 4095,\n",
       " 'sign': 32781,\n",
       " 'vendor': 38386,\n",
       " '80': 1038,\n",
       " '45': 777,\n",
       " '00': 0,\n",
       " 'upsideofflorida': 38102,\n",
       " 'shopalyssas': 32617,\n",
       " 'media': 23059,\n",
       " 'pressconference': 28734,\n",
       " 'antalya': 2575,\n",
       " 'turkey': 37490,\n",
       " 'sunday': 34889,\n",
       " 'throwback': 36468,\n",
       " 'great': 15781,\n",
       " 'panel': 27021,\n",
       " 'mediatization': 23063,\n",
       " 'public': 29153,\n",
       " 'service': 32213,\n",
       " 'ica16': 17816,\n",
       " '50': 834,\n",
       " 'went': 39387,\n",
       " 'nightclub': 25364,\n",
       " 'good': 15442,\n",
       " 'night': 25362,\n",
       " 'actions': 1417,\n",
       " 'means': 23032,\n",
       " 'lost': 21809,\n",
       " 'families': 12827,\n",
       " 'forever': 13970,\n",
       " 'rip': 30773,\n",
       " 'chance': 7072,\n",
       " 'vote': 38730,\n",
       " 'presidential': 28726,\n",
       " 'candidate': 6509,\n",
       " 'excited': 12457,\n",
       " 'cycle': 9317,\n",
       " 'looks': 21751,\n",
       " 'different': 10353,\n",
       " 'alohafriday': 2129,\n",
       " 'does': 10737,\n",
       " 'exist': 12508,\n",
       " 'positivevibes': 28445,\n",
       " 'hawaiian': 16604,\n",
       " 'fellow': 13210,\n",
       " 'nohern': 25545,\n",
       " 'sadley': 31355,\n",
       " 'passed': 27157,\n",
       " 'tonight': 36805,\n",
       " 'gawa': 14761,\n",
       " 'singing': 32886,\n",
       " 'cheering': 7206,\n",
       " 'hard': 16444,\n",
       " 'monday': 23884,\n",
       " 'cloudy': 7829,\n",
       " 'weather': 39170,\n",
       " 'disabling': 10449,\n",
       " 'oxygen': 26816,\n",
       " 'production': 28905,\n",
       " 'goodnight': 15501,\n",
       " 'badmonday': 3576,\n",
       " 'unbelievable': 37814,\n",
       " '21st': 463,\n",
       " 'century': 7000,\n",
       " 'need': 24887,\n",
       " 'like': 21274,\n",
       " 'neverump': 25051,\n",
       " 'xenophobia': 40373,\n",
       " 'taylorswift1989': 35583,\n",
       " 'bull': 6087,\n",
       " 'dominate': 10826,\n",
       " 'direct': 10434,\n",
       " 'want': 38940,\n",
       " 'morning': 24030,\n",
       " 'travelingram': 37109,\n",
       " 'dalat': 9437,\n",
       " 'ripinkylife': 30798,\n",
       " 'word': 40087,\n",
       " 'tells': 35801,\n",
       " 'photoshop': 27736,\n",
       " 'enoughisenough': 12056,\n",
       " 'dontphotoshopeverything': 10894,\n",
       " 'wheresallthenaturalphotos': 39553,\n",
       " 'oh': 26152,\n",
       " 'cedarpoint': 6926,\n",
       " 'waited': 38835,\n",
       " 'hours': 17486,\n",
       " 'valravn': 38267,\n",
       " 'line': 21364,\n",
       " 'stopped': 34426,\n",
       " 'working': 40118,\n",
       " 'close': 7794,\n",
       " 'sunshine': 34951,\n",
       " 'finally': 13407,\n",
       " 'finish': 13455,\n",
       " 'book': 5370,\n",
       " 've': 38341,\n",
       " 'awhile': 3375,\n",
       " 'bookworm': 5397,\n",
       " 'ontothenextnovel': 26382,\n",
       " 'yup': 40800,\n",
       " 'knicks': 20311,\n",
       " 'easier': 11438,\n",
       " 'just': 19766,\n",
       " 'nba': 24827,\n",
       " 'playoffs': 28068,\n",
       " 'roll': 30979,\n",
       " 'life': 21188,\n",
       " 'social': 33448,\n",
       " 'networking': 25015,\n",
       " 'embrace': 11812,\n",
       " 'shares': 32403,\n",
       " 'snake': 33338,\n",
       " 'lovely': 21943,\n",
       " 'echeveria': 11504,\n",
       " 'blooms': 5130,\n",
       " 'flowers': 13764,\n",
       " 'grow': 15959,\n",
       " 'gardening': 14702,\n",
       " 'iphonesia': 18910,\n",
       " 'bliss': 5070,\n",
       " 'basilicabotanica': 3862,\n",
       " 'amazing': 2225,\n",
       " 'i_am': 17763,\n",
       " 'affirmation': 1627,\n",
       " 'im': 18099,\n",
       " 'goes': 15360,\n",
       " 'wrong': 40273,\n",
       " 'feeling': 13135,\n",
       " 'blue': 5145,\n",
       " 'illustration': 18030,\n",
       " 'best': 4426,\n",
       " 'pa': 26841,\n",
       " '¼ð': 41019,\n",
       " 'abc2020': 1228,\n",
       " 'getting': 14994,\n",
       " 'ready': 29838,\n",
       " 'remove': 30313,\n",
       " 'victums': 38519,\n",
       " 'frm': 14315,\n",
       " 'pulseclub': 29200,\n",
       " 'prayfororlando': 28623,\n",
       " 'got': 15598,\n",
       " 'nose': 25684,\n",
       " 'job': 19517,\n",
       " 'petunia': 27613,\n",
       " 'concelebrate': 8290,\n",
       " 'albanpilgrimage': 1914,\n",
       " 'let': 21044,\n",
       " 'scum': 31880,\n",
       " 'baggery': 3599,\n",
       " 'begin': 4218,\n",
       " 'thank': 35967,\n",
       " 'super': 34964,\n",
       " 'zpamdelacruz': 40936,\n",
       " 'wedding': 39200,\n",
       " 'dolores': 10817,\n",
       " 'capas': 6590,\n",
       " 'tarlac': 35515,\n",
       " 'scourge': 31819,\n",
       " 'playing': 28058,\n",
       " 'baroque': 3818,\n",
       " 'pieces': 27809,\n",
       " 'piano': 27754,\n",
       " 'belief': 4286,\n",
       " 'lets': 21060,\n",
       " 'fight': 13330,\n",
       " 'peace': 27324,\n",
       " 'fatherâ': 13007,\n",
       " 'mr': 24200,\n",
       " 'rayos': 29778,\n",
       " 'video': 38522,\n",
       " 'fathers': 12988,\n",
       " 'world': 40153,\n",
       " 'hotvideo': 17474,\n",
       " 'videos': 38530,\n",
       " 'ascot': 2948,\n",
       " 'times': 36580,\n",
       " 'babe': 3454,\n",
       " 'fashion': 12932,\n",
       " 'monochrome': 23924,\n",
       " 'style': 34669,\n",
       " 'instahappyday': 18641,\n",
       " 'selfie': 32071,\n",
       " 'yolo': 40644,\n",
       " 'xoxo': 40391,\n",
       " 'like4like': 21277,\n",
       " 'work': 40097,\n",
       " 'conference': 8345,\n",
       " 'right': 30726,\n",
       " 'mindset': 23517,\n",
       " 'leads': 20864,\n",
       " 'culture': 9187,\n",
       " 'development': 10222,\n",
       " 'organizations': 26551,\n",
       " 'christina': 7492,\n",
       " 'grimmie': 15912,\n",
       " 'performance': 27500,\n",
       " 'shot': 32643,\n",
       " 'christinarip': 7495,\n",
       " 'voice': 38700,\n",
       " 'christinagrimmie': 7494,\n",
       " 'dance': 9475,\n",
       " 'roar': 30889,\n",
       " 'preschoolers': 28708,\n",
       " 'students': 34630,\n",
       " 'proudâ': 29063,\n",
       " 'really': 29884,\n",
       " 'hu': 17570,\n",
       " 'feelings': 13159,\n",
       " 'wife': 39721,\n",
       " 'adore': 1540,\n",
       " 'miss': 23616,\n",
       " 'poland': 28231,\n",
       " 'surgery': 35082,\n",
       " 'bridget': 5750,\n",
       " 'jealous': 19355,\n",
       " 'chatiado': 7163,\n",
       " 'celebrate': 6939,\n",
       " 'played': 28052,\n",
       " 'fatherly': 12987,\n",
       " 'role': 30973,\n",
       " 'sure': 35064,\n",
       " '½ð': 41028,\n",
       " 'hour': 17482,\n",
       " 'white': 39590,\n",
       " 'establishment': 12252,\n",
       " 'blk': 5076,\n",
       " 'folx': 13873,\n",
       " 'running': 31224,\n",
       " 'loving': 22045,\n",
       " 'promoting': 28974,\n",
       " 'greatness': 15808,\n",
       " 'journey': 19620,\n",
       " 'begins': 4222,\n",
       " 'travel': 37101,\n",
       " 'yeah': 40495,\n",
       " 'thejourneybegins': 36151,\n",
       " 'helloâ': 16832,\n",
       " 'luv': 22182,\n",
       " 'hottweets': 17472,\n",
       " 'venusexchangeâ': 38406,\n",
       " 'new': 25060,\n",
       " 'brochures': 5853,\n",
       " 'arrived': 2917,\n",
       " 'exciting': 12466,\n",
       " 'aworks': 3384,\n",
       " 'solutions': 33558,\n",
       " 'stuff': 34646,\n",
       " 'happening': 16374,\n",
       " 'florida': 13735,\n",
       " 'shooting': 32612,\n",
       " 'disneygatorattack': 10553,\n",
       " 'old': 26215,\n",
       " 'kidð': 20153,\n",
       " 'ferrari': 13246,\n",
       " 'itð': 19149,\n",
       " 'ªð': 40961,\n",
       " 'sake': 31410,\n",
       " 'championship': 7066,\n",
       " 'gp': 15650,\n",
       " 'clearly': 7720,\n",
       " 'turning': 37501,\n",
       " 'point': 28206,\n",
       " 'rb': 29786,\n",
       " 'mercs': 23234,\n",
       " 'aced': 1367,\n",
       " 'test': 35898,\n",
       " 'proud': 29043,\n",
       " 'seeks': 32006,\n",
       " 'probe': 28875,\n",
       " 'udtapunjab': 37697,\n",
       " 'leak': 20872,\n",
       " 'points': 28214,\n",
       " 'finger': 13448,\n",
       " 'amarinder': 2214,\n",
       " 'aap': 1199,\n",
       " 'wrapping': 40229,\n",
       " 'senseaboutmaths': 32150,\n",
       " '6th': 964,\n",
       " 'hey': 16934,\n",
       " 'race': 29499,\n",
       " 'identity': 17869,\n",
       " 'medâ': 23081,\n",
       " 'shown': 32679,\n",
       " 'regurgitated': 30178,\n",
       " 'calling': 6394,\n",
       " 'raise': 29627,\n",
       " 'brows': 5919,\n",
       " 'bar': 3760,\n",
       " 'golfstrengthandconditioning': 15411,\n",
       " 'strong': 34595,\n",
       " 'felixfoisgolf': 13191,\n",
       " 'greathonour': 15800,\n",
       " 'careerconvos': 6656,\n",
       " 'designing': 10138,\n",
       " 'innovative': 18514,\n",
       " 'learning': 20893,\n",
       " 'space': 33764,\n",
       " 'include': 18284,\n",
       " 'wateringhole': 39069,\n",
       " 'cave': 6861,\n",
       " 'mountaintop': 24130,\n",
       " 'campfire': 6460,\n",
       " 'hâ': 17760,\n",
       " 'altright': 2171,\n",
       " 'uses': 38166,\n",
       " 'insecurity': 18535,\n",
       " 'lure': 22172,\n",
       " 'men': 23171,\n",
       " 'whitesupremacy': 39634,\n",
       " 'carrying': 6731,\n",
       " 'gun': 16072,\n",
       " 'wouldn': 40205,\n",
       " 'helped': 16844,\n",
       " 'control': 8527,\n",
       " 'stop': 34417,\n",
       " 'black': 4906,\n",
       " 'market': 22726,\n",
       " 'terrorism': 35888,\n",
       " 'worse': 40190,\n",
       " 'power': 28534,\n",
       " 'mind': 23501,\n",
       " 'heal': 16691,\n",
       " 'body': 5257,\n",
       " 'altwaystoheal': 2174,\n",
       " 'healthy': 16714,\n",
       " 'woohoo': 40065,\n",
       " 'weeks': 39285,\n",
       " 'far': 12887,\n",
       " 'place': 27979,\n",
       " 'family': 12830,\n",
       " 'members': 23144,\n",
       " 'hus': 17693,\n",
       " 'rehearse': 30184,\n",
       " 'music': 24389,\n",
       " 'look': 21730,\n",
       " 'announcement': 2529,\n",
       " 'midweek': 23403,\n",
       " 'newmusic': 25161,\n",
       " 'watchthisspace': 39047,\n",
       " 'guitar': 16058,\n",
       " 'nights': 25383,\n",
       " '8pm': 1085,\n",
       " 'channel': 7099,\n",
       " 'fuss': 14539,\n",
       " 'watching': 39040,\n",
       " 'episodes': 12137,\n",
       " 'offline': 26140,\n",
       " 'nice': 25302,\n",
       " 'long': 21691,\n",
       " 'snapchat': 33341,\n",
       " 'redhead': 30044,\n",
       " 'vermillionred': 38424,\n",
       " '15': 227,\n",
       " 'things': 36330,\n",
       " 'incredibly': 18311,\n",
       " 'yes': 40560,\n",
       " 'received': 29951,\n",
       " 'acceptance': 1321,\n",
       " 'letter': 21083,\n",
       " 'masters': 22841,\n",
       " 'october': 26078,\n",
       " 'goodtimes': 15519,\n",
       " 'history': 17095,\n",
       " 'daughter': 9597,\n",
       " 'riding': 30709,\n",
       " 'bike': 4761,\n",
       " 'driveway': 11157,\n",
       " 'son': 33602,\n",
       " 'enjoy': 12029,\n",
       " 'summeime': 34813,\n",
       " 'memories': 23159,\n",
       " 'station': 34210,\n",
       " 'way': 39100,\n",
       " 'jam': 19260,\n",
       " 'course': 8783,\n",
       " 'll': 21559,\n",
       " 'hope': 17354,\n",
       " 'hug': 17591,\n",
       " 'gonna': 15432,\n",
       " 'happen': 16371,\n",
       " 'anytime': 2634,\n",
       " 'soon': 33637,\n",
       " 'couple': 8771,\n",
       " 'sex': 32265,\n",
       " 'naked': 24659,\n",
       " 'japanese': 19298,\n",
       " 'girls': 15127,\n",
       " 'hump': 17649,\n",
       " 'humpersð': 17653,\n",
       " 'edwardsville': 11611,\n",
       " 'pennsylvania': 27425,\n",
       " 'personalised': 27556,\n",
       " 'gbp': 14808,\n",
       " '99': 1128,\n",
       " 'shop': 32615,\n",
       " 'cool': 8572,\n",
       " 'home': 17226,\n",
       " 'fun': 14446,\n",
       " 'truly': 37320,\n",
       " 'sick': 32743,\n",
       " 'ppl': 28555,\n",
       " 'trump': 37324,\n",
       " 'obama': 26002,\n",
       " 'resign': 30448,\n",
       " 'shootings': 32613,\n",
       " 'boy': 5545,\n",
       " 'years': 40507,\n",
       " 'did': 10316,\n",
       " 'talk': 35444,\n",
       " 'change': 7082,\n",
       " 'nashvilletour2016': 24724,\n",
       " 'nashvilleforever': 24722,\n",
       " 'eur': 12304,\n",
       " 'usd': 38150,\n",
       " 'clears': 7722,\n",
       " '1400': 183,\n",
       " 'barrier': 3830,\n",
       " 'jumps': 19714,\n",
       " 'fresh': 14215,\n",
       " 'week': 39252,\n",
       " 'high': 16968,\n",
       " 'going': 15376,\n",
       " 'la': 20500,\n",
       " 'friends': 14271,\n",
       " 'wrap': 40227,\n",
       " 'head': 16662,\n",
       " 'fact': 12735,\n",
       " 'gone': 15425,\n",
       " 'destroyed': 10182,\n",
       " 'dis': 10445,\n",
       " 'wait': 38833,\n",
       " 'sta': 34073,\n",
       " 'baking': 3632,\n",
       " 'eyelids': 12652,\n",
       " 'vigilfororlando': 38553,\n",
       " 'harp': 16492,\n",
       " 'clonakilty': 7790,\n",
       " 'ihavenofriends': 17959,\n",
       " 'someonecomewithme': 33571,\n",
       " 'relax': 30228,\n",
       " 'icon': 17844,\n",
       " 'woman': 39979,\n",
       " 'sundaymorning': 34898,\n",
       " 'marilynmonroe': 22708,\n",
       " 'interested': 18766,\n",
       " 'linguistics': 21377,\n",
       " 'doesn': 10738,\n",
       " 'address': 1476,\n",
       " 'racism': 29527,\n",
       " 'raciolinguistics': 29526,\n",
       " 'bringsâ': 5794,\n",
       " 'beloved': 4333,\n",
       " 'cds': 6911,\n",
       " 'recovered': 30001,\n",
       " 'apple': 2712,\n",
       " 'marvel': 22774,\n",
       " 'song': 33609,\n",
       " 'musica': 24390,\n",
       " 'weed': 39244,\n",
       " 'ripchristina': 30785,\n",
       " 'adele': 1486,\n",
       " 'vine': 38576,\n",
       " 'mocked': 23777,\n",
       " 'brexit': 5721,\n",
       " 'spell': 33845,\n",
       " 'referendum': 30094,\n",
       " 'commerzbank': 8153,\n",
       " '100': 55,\n",
       " 'health': 16699,\n",
       " 'benefits': 4352,\n",
       " 'cucumbers': 9164,\n",
       " 'ofw': 26146,\n",
       " 'pinoy': 27888,\n",
       " 'followme': 13862,\n",
       " 'igers': 17927,\n",
       " 'instagood': 18629,\n",
       " 'smile': 33258,\n",
       " 'toradora': 36882,\n",
       " 'anime': 2477,\n",
       " 'animeedit': 2481,\n",
       " 'breakups': 5676,\n",
       " 'lonely': 21683,\n",
       " 'laps': 20680,\n",
       " 'pool': 28327,\n",
       " '10k': 98,\n",
       " 'ride': 30698,\n",
       " 'picked': 27768,\n",
       " 'gym': 16137,\n",
       " 'membership': 23145,\n",
       " 'form': 14001,\n",
       " 'cotd': 8710,\n",
       " 'polar': 28233,\n",
       " 'bear': 4045,\n",
       " 'climb': 7766,\n",
       " 'racing': 29525,\n",
       " 'angry': 2442,\n",
       " 'living': 21538,\n",
       " 'cold': 7967,\n",
       " 'places': 27986,\n",
       " 'looking': 21741,\n",
       " 'gets': 14986,\n",
       " 'muslim': 24422,\n",
       " 'assassinating': 3027,\n",
       " 'snappy': 33352,\n",
       " 'waiting': 38842,\n",
       " 'football': 13927,\n",
       " 'fringes': 14306,\n",
       " 'qcbags': 29343,\n",
       " 'summer': 34817,\n",
       " 'ó¾': 41101,\n",
       " 'nochebuena': 25488,\n",
       " 'lasvegas': 20720,\n",
       " 'usa': 38137,\n",
       " 'las': 20693,\n",
       " 'vegas': 38361,\n",
       " 'strip': 34573,\n",
       " 'ma': 22233,\n",
       " 'fleurette': 13676,\n",
       " 'instaboy': 18593,\n",
       " 'instaman': 18658,\n",
       " 'sefie': 32024,\n",
       " 'septum': 32183,\n",
       " 'friend': 14264,\n",
       " 'blackandwhite': 4908,\n",
       " 'branches': 5616,\n",
       " 'itâ': 19148,\n",
       " 'rainy': 29620,\n",
       " 'writing': 40269,\n",
       " 'tears': 35723,\n",
       " 'flying': 13792,\n",
       " 'birds': 4841,\n",
       " 'haiku': 16204,\n",
       " '3lines': 727,\n",
       " 'micropoetry': 23379,\n",
       " 'buttons': 6241,\n",
       " 'mail': 22382,\n",
       " 'pretty': 28762,\n",
       " 'jewelrymaking': 19454,\n",
       " 'driver': 11152,\n",
       " 'female': 13218,\n",
       " 'moose': 23990,\n",
       " 'river': 30843,\n",
       " 'rd': 29804,\n",
       " 'weston': 39435,\n",
       " 'killed': 20172,\n",
       " 'ok': 26198,\n",
       " 'crews': 8994,\n",
       " 'removing': 30317,\n",
       " 'animal': 2457,\n",
       " 'afterpas': 1678,\n",
       " 'japan': 19296,\n",
       " 'ï¼': 41077,\n",
       " 'madeinjapan': 22286,\n",
       " 'eos': 12116,\n",
       " 'cute': 9272,\n",
       " 'cawaii': 6869,\n",
       " 'strawberry': 34499,\n",
       " 'tomato': 36772,\n",
       " 'aren': 2816,\n",
       " 'protesting': 29036,\n",
       " 'republican': 30405,\n",
       " 'fuhered': 14417,\n",
       " 'spend': 33853,\n",
       " 'guy': 16118,\n",
       " '1466047260': 204,\n",
       " 'update': 38064,\n",
       " 'analytics': 2364,\n",
       " 'photooftheday': 27725,\n",
       " 'likes': 21303,\n",
       " 'date': 9583,\n",
       " 'doj': 10805,\n",
       " 'fbi': 13060,\n",
       " 'corrupted': 8675,\n",
       " 'emailgate': 11799,\n",
       " 'hillary2016': 17029,\n",
       " 'shameful': 32372,\n",
       " 'disgraceful': 10520,\n",
       " 'ridiculous': 30705,\n",
       " 'stupidity': 34658,\n",
       " 'makes': 22451,\n",
       " 'negligence': 24940,\n",
       " 'sachintendulkar': 31329,\n",
       " 'installation': 18651,\n",
       " 'bihdayð': 4753,\n",
       " '21thbihday': 464,\n",
       " 'bestfriend': 4454,\n",
       " 'loveð': 22043,\n",
       " 'impoant': 18210,\n",
       " 'thing': 36327,\n",
       " 'matters': 22888,\n",
       " 'sho': 32573,\n",
       " 'pooh4u': 28323,\n",
       " 'chris': 7477,\n",
       " 'evansð': 12340,\n",
       " 'actor': 1431,\n",
       " 'human': 17621,\n",
       " '³ð': 40979,\n",
       " 'chrisevans': 7479,\n",
       " 'bihdayâ': 4751,\n",
       " 'heas': 16742,\n",
       " 'thoughts': 36423,\n",
       " 'prayers': 28604,\n",
       " 'murdered': 24363,\n",
       " 'gay': 14762,\n",
       " 'demoing': 9996,\n",
       " 'guitars': 16061,\n",
       " 'album': 1926,\n",
       " 'newalbum': 25067,\n",
       " 'indie': 18347,\n",
       " 'echobelly': 11506,\n",
       " 'retweeted': 30568,\n",
       " 'lion': 21394,\n",
       " 'pro': 28868,\n",
       " 'webmareting': 39183,\n",
       " 'seo': 32171,\n",
       " 'community': 8183,\n",
       " 'management': 22553,\n",
       " 'nzd': 25986,\n",
       " 'targets': 35512,\n",
       " 'sma': 33204,\n",
       " '7190': 993,\n",
       " 'bad': 3555,\n",
       " 'worst': 40194,\n",
       " 'bihdayweeksucks': 4747,\n",
       " 'bithday27': 4879,\n",
       " 'tâ': 37664,\n",
       " 'blessed': 5029,\n",
       " 'worked': 40103,\n",
       " 'sa': 31301,\n",
       " 'leading': 20863,\n",
       " 'ladiesð': 20550,\n",
       " 'happiest': 16381,\n",
       " 'eah': 11403,\n",
       " 'disneysmagickingdom': 10560,\n",
       " 'disney': 10549,\n",
       " 'magickingdom': 22342,\n",
       " 'disneyland': 10554,\n",
       " 'orlandoâ': 26600,\n",
       " 'kinda': 20207,\n",
       " 'humans': 17630,\n",
       " 'exclaiming': 12472,\n",
       " 'blain': 4983,\n",
       " 'hair': 16208,\n",
       " 'nite': 25435,\n",
       " 'lt': 22097,\n",
       " 'listen': 21422,\n",
       " '17': 269,\n",
       " 'freedom': 14157,\n",
       " 'effo': 11639,\n",
       " 'present': 28711,\n",
       " 'merely': 23238,\n",
       " 'stored': 34444,\n",
       " 'past': 27175,\n",
       " 'theodore': 36196,\n",
       " 'rooseveltâ': 31040,\n",
       " 'yall': 40447,\n",
       " 'aint': 1804,\n",
       " 'commitment': 8158,\n",
       " 'trust': 37365,\n",
       " 'faithful': 12780,\n",
       " 'michelleobama': 23364,\n",
       " 'gorilla': 15584,\n",
       " 'racists': 29530,\n",
       " 'thought': 36416,\n",
       " 'betâ': 4543,\n",
       " 'newarkfestival': 25069,\n",
       " '3rd': 733,\n",
       " 'internet': 18790,\n",
       " 'broken': 5861,\n",
       " 'watch': 39032,\n",
       " 'netflix': 25008,\n",
       " 'mochithepug': 23775,\n",
       " 'puglife': 29180,\n",
       " 'business': 6185,\n",
       " 'usual': 38187,\n",
       " 'hbd': 16625,\n",
       " 'dick': 10301,\n",
       " 'suckin': 34739,\n",
       " 'tequila': 35848,\n",
       " 'lovin': 22044,\n",
       " 'slut': 33199,\n",
       " 'wouldnt': 40206,\n",
       " 'justalillate': 19769,\n",
       " 'butstillontime': 6227,\n",
       " 'smaller': 33219,\n",
       " 'hands': 16330,\n",
       " 'barry': 3833,\n",
       " 'probably': 28871,\n",
       " 'lied': 21183,\n",
       " 'game': 14643,\n",
       " 'sucked': 34736,\n",
       " 'golfâ': 15412,\n",
       " 'doing': 10795,\n",
       " 'goodmorning': 15493,\n",
       " 'challenges': 7050,\n",
       " 'claim': 7632,\n",
       " '70': 976,\n",
       " 'punjabis': 29230,\n",
       " 'drugaddicts': 11186,\n",
       " 'dares': 9540,\n",
       " 'tracerequest': 36989,\n",
       " 'sending': 32139,\n",
       " 'deepest': 9835,\n",
       " 'condolences': 8328,\n",
       " 'zimbabwe': 40887,\n",
       " 'hea': 16651,\n",
       " 'touched': 36926,\n",
       " 'mato': 22879,\n",
       " 'chapones': 7113,\n",
       " 'saturday': 31607,\n",
       " 'afternoon': 1675,\n",
       " 'chi': 7287,\n",
       " 'meet': 23088,\n",
       " 'soed': 33496,\n",
       " 'nut': 25939,\n",
       " 'bolts': 5315,\n",
       " 'bloke': 5107,\n",
       " 'aww': 3389,\n",
       " 'bing': 4811,\n",
       " 'bong': 5341,\n",
       " 'dawned': 9626,\n",
       " 'months': 23950,\n",
       " 'seeing': 32000,\n",
       " 'live': 21484,\n",
       " 'vfest': 38474,\n",
       " '35th': 680,\n",
       " 'shane': 32382,\n",
       " 'robe': 30900,\n",
       " 'watson': 39085,\n",
       " 'cricker': 8998,\n",
       " 'millions': 23479,\n",
       " 'pointed': 28208,\n",
       " 'jewishsupremacist': 19460,\n",
       " 'hear': 16736,\n",
       " 'announcers': 2532,\n",
       " 'say': 31663,\n",
       " 'moved': 24148,\n",
       " 'player': 28053,\n",
       " 'lead': 20857,\n",
       " 'whoknows': 39652,\n",
       " 'radio1': 29549,\n",
       " 'coldplay': 7973,\n",
       " 'god': 15322,\n",
       " 'coming': 8130,\n",
       " 'keeping': 19998,\n",
       " 'terrorist': 35890,\n",
       " 'constitutional': 8451,\n",
       " 'rights': 30735,\n",
       " 'excuse': 12479,\n",
       " 'republicans': 30406,\n",
       " 'appease': 2702,\n",
       " 'nra': 25871,\n",
       " 'measures': 23037,\n",
       " 'gloucesterrugby': 15256,\n",
       " 'happened': 16373,\n",
       " 'fine': 13437,\n",
       " 'dandy': 9502,\n",
       " 'exuberant': 12637,\n",
       " 'depressed': 10071,\n",
       " 'halffull': 16247,\n",
       " 'halfempty': 16246,\n",
       " 'mikeashley': 23430,\n",
       " 'sposdirectshame': 33966,\n",
       " 'perhapse': 27509,\n",
       " 'example': 12430,\n",
       " 'protect': 29022,\n",
       " 'workersrights': 40107,\n",
       " 'europe': 12317,\n",
       " 'euref': 12305,\n",
       " 'remain': 30268,\n",
       " 'stella': 34284,\n",
       " 'princess': 28819,\n",
       " 'birdsstellabadprincess': 4845,\n",
       " 'post': 28463,\n",
       " 'wedâ': 39242,\n",
       " 'check': 7184,\n",
       " 'saw': 31661,\n",
       " 'shi': 32503,\n",
       " 'said': 31389,\n",
       " 'cared': 6652,\n",
       " 'hilarious': 17024,\n",
       " 'blocked': 5083,\n",
       " 'asking': 2996,\n",
       " 'paicularly': 26914,\n",
       " 'difficult': 10357,\n",
       " 'question': 29427,\n",
       " 'devastating': 10214,\n",
       " 'news': 25178,\n",
       " 'victims': 38506,\n",
       " 'happiness': 16388,\n",
       " 'state': 34199,\n",
       " 'arrive': 2916,\n",
       " 'manner': 22616,\n",
       " 'traveling': 37108,\n",
       " 'margaret': 22683,\n",
       " 'lee': 20932,\n",
       " 'runbeck': 31209,\n",
       " 'quotes': 29470,\n",
       " 'inspirational': 18561,\n",
       " 'safe': 31362,\n",
       " 'ways': 39103,\n",
       " 'acne': 1392,\n",
       " 'healing': 16697,\n",
       " 'creating': 8949,\n",
       " 'beats': 4083,\n",
       " 'makingbeats': 22475,\n",
       " 'thursday': 36496,\n",
       " 'istandard': 19073,\n",
       " 'akaiproâ': 1870,\n",
       " 'number': 25917,\n",
       " '10': 54,\n",
       " '¾ð': 41037,\n",
       " 'weddingpay': 39212,\n",
       " 'weddingdressâ': 39208,\n",
       " 'forward': 14018,\n",
       " 'attending': 3161,\n",
       " 'cipd': 7574,\n",
       " 'workshop': 40143,\n",
       " 'cpd': 8846,\n",
       " 'onemoreday': 26309,\n",
       " 'reached': 29811,\n",
       " '200': 393,\n",
       " 'followers': 13855,\n",
       " 'twitch': 37598,\n",
       " 'follower': 13854,\n",
       " 'hypu': 17752,\n",
       " 'stream': 34513,\n",
       " 'words': 40092,\n",
       " 'em': 11794,\n",
       " 'cost': 8695,\n",
       " 'verbal': 38412,\n",
       " 'abuse': 1302,\n",
       " 'adult': 1549,\n",
       " 'teen': 35764,\n",
       " 'country': 8755,\n",
       " 'bring': 5781,\n",
       " 'bomb': 5317,\n",
       " 'stadium': 34086,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# No User string\n",
    "# Definition der Feature-Matrix\n",
    "tf = text.TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_vec = tf.fit(df['no_user'])\n",
    "X = X_vec.transform(df['no_user'])\n",
    "\n",
    "print(X.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting of data into training and test data\n",
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 25569 training data, of which 7.02% is hate speech \n",
      "There is 6393 test data, of which 7.01% is hate speech \n"
     ]
    }
   ],
   "source": [
    "# Testing Stratification\n",
    "print('There is {} training data, of which {}% is hate speech '.format(y_train.count(), round(y_train.sum()/y_train.count()*100,2)))\n",
    "print('There is {} test data, of which {}% is hate speech '.format(y_test.count(), round(y_test.sum()/y_test.count()*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models\n",
    "The method GridSearchCV is used for hyperparameter optimization. In the following cases the smoothing parameter alpha is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.935080</td>\n",
       "      <td>0.940357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.937622</td>\n",
       "      <td>0.940064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.937427</td>\n",
       "      <td>0.940161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.938600</td>\n",
       "      <td>0.940161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.938588</td>\n",
       "      <td>0.940360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.009974    0.000997    0.935080     0.940357\n",
       "1  0.009973    0.001994    0.937622     0.940064\n",
       "2  0.006981    0.002992    0.937427     0.940161\n",
       "3  0.008976    0.000998    0.938600     0.940161\n",
       "4  0.011968    0.001996    0.938588     0.940360"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(nb.MultinomialNB(), X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-2, num=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = ms.GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "gnb.fit(X_train.toarray(), y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with the Gaussian Naive Bayes:\n",
      "Precision: 0.279\n",
      "Recall: 0.618\n",
      "Accuracy: 0.861\n",
      "F1 Score: 0.384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train.toarray(), y_train);\n",
    "print('Scores with the Gaussian Naive Bayes:')\n",
    "validate(y_test, gnb.predict(X_test.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with the Complement Naive Bayes:\n",
      "Precision: 0.583\n",
      "Recall: 0.299\n",
      "Accuracy: 0.936\n",
      "F1 Score: 0.395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB \n",
    "cnb = ms.GridSearchCV(nb.ComplementNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "cnb.fit(X_train, y_train);\n",
    "print('Scores with the Complement Naive Bayes:')\n",
    "validate(y_test, cnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-variate Bernoulli Naive Bayes\n",
    "bnb = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnb.fit(X_train, y_train);\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "mnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "mnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.19306977288832497}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance based on TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with the Multi-variate Bernoulli Naive Bayes:\n",
      "Precision: 0.524\n",
      "Recall: 0.692\n",
      "Accuracy: 0.934\n",
      "F1 Score: 0.596\n",
      "Scores with the Multinominal Naive Bayes:\n",
      "Precision: 0.579\n",
      "Recall: 0.623\n",
      "Accuracy: 0.942\n",
      "F1 Score: 0.600\n"
     ]
    }
   ],
   "source": [
    "print('Scores with the Multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, bnb.predict(X_test))\n",
    "print('Scores with the Multinominal Naive Bayes:')\n",
    "validate(y_test, mnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with the Multi-variate Bernoulli Naive Bayes:\n",
      "Precision: 0.648\n",
      "Recall: 0.551\n",
      "Accuracy: 0.948\n",
      "F1 Score: 0.596\n"
     ]
    }
   ],
   "source": [
    "print('Scores with the Multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, bnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with the Multinominal Naive Bayes:\n",
      "Precision: 0.715\n",
      "Recall: 0.542\n",
      "Accuracy: 0.953\n",
      "F1 Score: 0.617\n"
     ]
    }
   ],
   "source": [
    "print('Scores with the Multinominal Naive Bayes:')\n",
    "validate(y_test, mnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(y_test, mnb.predict(X_test))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# No user string\n",
    "co = text.CountVectorizer(stop_words='english')\n",
    "\n",
    "Xc_vec = co.fit(df['no_user'])\n",
    "Xc = Xc_vec.transform(df['no_user'])\n",
    "\n",
    "print(Xc.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = text.CountVectorizer(stop_words='english')\n",
    "\n",
    "Xc_vec = co.fit(df['tweet'])\n",
    "Xc = Xc_vec.transform(df['tweet'])\n",
    "\n",
    "print(Xc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting of data into training and test data\n",
    "(Xc_train, Xc_test, yc_train, yc_test) = ms.train_test_split(Xc, y, test_size=.2, random_state = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-variate Bernoulli Naive Bayes\n",
    "bnbc = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnbc.fit(Xc_train, yc_train);\n",
    "\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "mnbc = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "mnbc.fit(Xc_train, yc_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance based on Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(yc_test, bnbc.predict(Xc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(yc_test, mnbc.predict(Xc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(yc_test, mnbc.predict(Xc_test))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Get most frequent words including stop words\n",
    "word_freq_df = pd.DataFrame(Xc.toarray(), columns=co.get_feature_names_out())\n",
    "top_words_df = pd.DataFrame(word_freq_df.sum()).sort_values(0, ascending=False)\n",
    "top_words_df.head(10)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get words with biggest impact on each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc = nb.MultinomialNB()\n",
    "mnbc.fit(Xc_train, yc_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words with biggest impact on each category\n",
    "\n",
    "mnbc.feature_log_prob_\n",
    "mnbc.coef_\n",
    "\n",
    "feature_names = co.get_feature_names_out()\n",
    "for i, class_label in enumerate(['no_hate', 'hate']):\n",
    "    top10 = np.argsort(mnbc.feature_log_prob_[i])[-10:]\n",
    "    print(\"%s: %s\" % (class_label,\n",
    "          \" \".join(feature_names[j] for j in top10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vectorizer BEFORE upsampling\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "X_tf_vec = tf.fit(df['tweet'])\n",
    "#X_tf_vec = tf.fit(df['no_user'])\n",
    "\n",
    "co = CountVectorizer(stop_words='english')\n",
    "X_co_vec = co.fit(df['tweet'])\n",
    "#X_co_vec = co.fit(df['no_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Split data\n",
    "y = df['label']\n",
    "X = df['tweet']\n",
    "#X = df['no_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data BEFORE upsampling\n",
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)\n",
    "\n",
    "df_train = pd.concat([y_train,X_train], axis=1)\n",
    "df_test = pd.concat([y_test,X_test], axis = 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minority = df_train[df_train.label == 1]\n",
    "data_majority = df_train[df_train.label == 0]\n",
    "\n",
    "print(\"length majority\", len(data_majority))\n",
    "print(\"length minority\", len(data_minority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "data_minority = resample(data_minority, replace = True, n_samples=23775, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_up = pd.concat([data_majority, data_minority])\n",
    "df_train_up.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# create embeddings\n",
    "\n",
    "# tfifd\n",
    "Xt_train = X_tf_vec.transform(df_train_up['no_user'])\n",
    "Xt_test = X_tf_vec.transform(df_test['no_user'])\n",
    "\n",
    "# count vectorizer\n",
    "Xc_train = X_co_vec.transform(df_train_up['no_user'])\n",
    "Xc_test = X_co_vec.transform(df_test['no_user'])\n",
    "\n",
    "# labels\n",
    "y_train = df_train_up['label']\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(Xt_train.shape) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "\n",
    "# tfifd\n",
    "Xt_train = X_tf_vec.transform(df_train_up['tweet'])\n",
    "Xt_test = X_tf_vec.transform(df_test['tweet'])\n",
    "\n",
    "# count vectorizer\n",
    "Xc_train = X_co_vec.transform(df_train_up['tweet'])\n",
    "Xc_test = X_co_vec.transform(df_test['tweet'])\n",
    "\n",
    "# labels\n",
    "y_train = df_train_up['label']\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(Xt_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Stratification\n",
    "print('There is {} training data, of which {}% is hate speech '.format(df_train_up['label'].count(), round(df_train_up['label'].sum()/df_train_up['label'].count()*100,2)))\n",
    "print('There is {} test data, of which {}% is hate speech '.format(df_test['label'].count(), round(df_test['label'].sum()/df_test['label'].count()*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "# Multi-variate Bernoulli Naive Bayes\n",
    "bnb = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "bnb.fit(Xt_train, y_train);\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "mnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "mnb.fit(Xt_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF-IDF Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, bnb.predict(Xt_test))\n",
    "print('TF-IDF Scores with the Multinominal Bernoulli Naive Bayes:')\n",
    "validate(y_test, mnb.predict(Xt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "# Multi-variate Bernoulli Naive Bayes\n",
    "cbnb = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "cbnb.fit(Xc_train, y_train);\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "cmnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)})\n",
    "cmnb.fit(Xc_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count Vectorizer Scores with the multi-variate Bernoulli Naive Bayes:')\n",
    "validate(y_test, cbnb.predict(Xc_test))\n",
    "print('Count Vectorizer Scores with the Multinominal Bernoulli Naive Bayes:')\n",
    "validate(y_test, cmnb.predict(Xc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(y_test, cmnb.predict(Xc_test))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cca499a840d662a33e8301a94c1b3730e7c5db68b1a61aac955d5a843456daa4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
