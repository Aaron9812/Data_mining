{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>stemmed_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "      <td>['when', 'father', 'dysfunctional', 'is', 'sel...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drags'...</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunct', 'selfish', 'drag', 'kid...</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>['run']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "      <td>['user', 'for', 'credit', 'cant', 'cause', 'do...</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'caus', 'dont', 'wh...</td>\n",
       "      <td>['lyft', 'disapoint', 'getthank']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>['your']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>['i', 'with', 'u', 'all', 'time', 'urð\\x9f\\x93...</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>['model']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['societi', 'motiv']</td>\n",
       "      <td>['motiv']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>['motivation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  n_mentions  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...           1   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...           2   \n",
       "2   3      0                                bihday your majesty           0   \n",
       "3   4      0  #model   i love u take with u all the time in ...           0   \n",
       "4   5      0             factsguide: society now    #motivation           0   \n",
       "\n",
       "                                hashtags  \\\n",
       "0                                ['run']   \n",
       "1  ['lyft', 'disapointed', 'getthanked']   \n",
       "2                                     []   \n",
       "3                              ['model']   \n",
       "4                         ['motivation']   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0   user when a father is dysfunctional and is so...   \n",
       "1  user user thanks for lyft credit i cant use ca...   \n",
       "2                                bihday your majesty   \n",
       "3  model   i love u take with u all the time in u...   \n",
       "4               factsguide society now    motivation   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0   user when a father is dysfunctional and is so...   \n",
       "1  user user thanks for lyft credit i cant use ca...   \n",
       "2                                bihday your majesty   \n",
       "3  model   i love u take with u all the time in u...   \n",
       "4               factsguide society now    motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  ['when', 'father', 'dysfunctional', 'is', 'sel...   \n",
       "1  ['user', 'for', 'credit', 'cant', 'cause', 'do...   \n",
       "2                                           ['your']   \n",
       "3  ['i', 'with', 'u', 'all', 'time', 'urð\\x9f\\x93...   \n",
       "4                          ['society', 'motivation']   \n",
       "\n",
       "                                         clean_token  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drags'...   \n",
       "1  ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                 []   \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                          ['society', 'motivation']   \n",
       "\n",
       "                          clean_hashtags  \\\n",
       "0                                ['run']   \n",
       "1  ['lyft', 'disapointed', 'getthanked']   \n",
       "2                                     []   \n",
       "3                              ['model']   \n",
       "4                         ['motivation']   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  ['father', 'dysfunct', 'selfish', 'drag', 'kid...   \n",
       "1  ['user', 'credit', 'cant', 'caus', 'dont', 'wh...   \n",
       "2                                                 []   \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                               ['societi', 'motiv']   \n",
       "\n",
       "                    stemmed_hashtags  \\\n",
       "0                            ['run']   \n",
       "1  ['lyft', 'disapoint', 'getthank']   \n",
       "2                                 []   \n",
       "3                          ['model']   \n",
       "4                          ['motiv']   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1  ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                 []   \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                          ['society', 'motivation']   \n",
       "\n",
       "                     lemmatized_hashtags  \n",
       "0                                ['run']  \n",
       "1  ['lyft', 'disapointed', 'getthanked']  \n",
       "2                                     []  \n",
       "3                              ['model']  \n",
       "4                         ['motivation']  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/220502_train_data_preprocessed.csv\", sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Up-sample Minority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate Minortity Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length majority 29720\n",
      "length minority 2242\n"
     ]
    }
   ],
   "source": [
    "data_minority = data[data.label == 1]\n",
    "data_majority = data[data.label == 0]\n",
    "print(\"length majority\", len(data_majority))\n",
    "print(\"length minority\", len(data_minority))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minority = resample(data_minority, replace = True, n_samples=29720, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1    29720\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsampled = pd.concat([data_majority, data_minority])\n",
    "data_upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_mentions                    lemmatized_hashtags  \\\n",
       "0           1                                ['run']   \n",
       "1           2  ['lyft', 'disapointed', 'getthanked']   \n",
       "2           0                                     []   \n",
       "3           0                              ['model']   \n",
       "4           0                         ['motivation']   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...  \n",
       "1  ['user', 'credit', 'cant', 'cause', 'dont', 'w...  \n",
       "2                                                 []  \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...  \n",
       "4                          ['society', 'motivation']  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"n_mentions\", \"lemmatized_hashtags\", \"lemmatized_tokens\"]\n",
    "X = data[features]\n",
    "y = data.label\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bag of words from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/3688221143.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_tokens\"] = (hero.tfidf(X[\"lemmatized_tokens\"], max_features=5000))\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/3688221143.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_hashtags\"] = (hero.tfidf(X[\"lemmatized_hashtags\"], max_features=5000))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>bow_tokens</th>\n",
       "      <th>bow_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['user']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>['shame', 'imwithher']</td>\n",
       "      <td>['see', 'turner', 'trying', 'wrap', 'mantle', ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song', 'morning']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>['sikh', 'temple', 'calgary', 'wso']</td>\n",
       "      <td>['sikh', 'vandalised', 'wso', 'act']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['follow']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions                    lemmatized_hashtags  \\\n",
       "0               1                                ['run']   \n",
       "1               2  ['lyft', 'disapointed', 'getthanked']   \n",
       "2               0                                     []   \n",
       "3               0                              ['model']   \n",
       "4               0                         ['motivation']   \n",
       "...           ...                                    ...   \n",
       "31957           1                                     []   \n",
       "31958           0                 ['shame', 'imwithher']   \n",
       "31959           0                                     []   \n",
       "31960           1   ['sikh', 'temple', 'calgary', 'wso']   \n",
       "31961           1                                     []   \n",
       "\n",
       "                                       lemmatized_tokens  \\\n",
       "0      ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1      ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                     []   \n",
       "3      ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                              ['society', 'motivation']   \n",
       "...                                                  ...   \n",
       "31957                                           ['user']   \n",
       "31958  ['see', 'turner', 'trying', 'wrap', 'mantle', ...   \n",
       "31959                                ['song', 'morning']   \n",
       "31960               ['sikh', 'vandalised', 'wso', 'act']   \n",
       "31961                                         ['follow']   \n",
       "\n",
       "                                              bow_tokens  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "31957  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "31958  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "31959  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "31960  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "31961  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            bow_hashtags  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "31957  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "31958  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "31959  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "31960  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "31961  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[31962 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import texthero as hero\n",
    "from texthero import preprocessing\n",
    "X[\"bow_tokens\"] = (hero.tfidf(X[\"lemmatized_tokens\"], max_features=5000))\n",
    "X[\"bow_hashtags\"] = (hero.tfidf(X[\"lemmatized_hashtags\"], max_features=5000))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimension of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2594054688.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_tokens\"] = (hero.tsne(X[\"bow_tokens\"]))\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2594054688.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_hashtags\"] = (hero.tsne(X[\"bow_hashtags\"]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>bow_tokens</th>\n",
       "      <th>bow_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>[4.522366523742676, -12.791789054870605]</td>\n",
       "      <td>[3.0793397426605225, 12.407670974731445]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>[-16.068601608276367, -44.1268196105957]</td>\n",
       "      <td>[0.5125786662101746, 1.6410552263259888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-58.391571044921875, 23.286211013793945]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>[58.901100158691406, 30.188573837280273]</td>\n",
       "      <td>[18.094478607177734, -19.416061401367188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>[-41.57936477661133, 31.845523834228516]</td>\n",
       "      <td>[7.747095108032227, -33.71648406982422]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['user']</td>\n",
       "      <td>[-20.37633514404297, 61.130393981933594]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>['shame', 'imwithher']</td>\n",
       "      <td>['see', 'turner', 'trying', 'wrap', 'mantle', ...</td>\n",
       "      <td>[3.5070629119873047, 20.457685470581055]</td>\n",
       "      <td>[10.712545394897461, 4.604351043701172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song', 'morning']</td>\n",
       "      <td>[-16.49297332763672, 33.97321319580078]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>['sikh', 'temple', 'calgary', 'wso']</td>\n",
       "      <td>['sikh', 'vandalised', 'wso', 'act']</td>\n",
       "      <td>[5.2635626792907715, 43.18000030517578]</td>\n",
       "      <td>[22.43916130065918, -8.663960456848145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['follow']</td>\n",
       "      <td>[-2.740935802459717, 2.17716121673584]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions                    lemmatized_hashtags  \\\n",
       "0               1                                ['run']   \n",
       "1               2  ['lyft', 'disapointed', 'getthanked']   \n",
       "2               0                                     []   \n",
       "3               0                              ['model']   \n",
       "4               0                         ['motivation']   \n",
       "...           ...                                    ...   \n",
       "31957           1                                     []   \n",
       "31958           0                 ['shame', 'imwithher']   \n",
       "31959           0                                     []   \n",
       "31960           1   ['sikh', 'temple', 'calgary', 'wso']   \n",
       "31961           1                                     []   \n",
       "\n",
       "                                       lemmatized_tokens  \\\n",
       "0      ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1      ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                     []   \n",
       "3      ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                              ['society', 'motivation']   \n",
       "...                                                  ...   \n",
       "31957                                           ['user']   \n",
       "31958  ['see', 'turner', 'trying', 'wrap', 'mantle', ...   \n",
       "31959                                ['song', 'morning']   \n",
       "31960               ['sikh', 'vandalised', 'wso', 'act']   \n",
       "31961                                         ['follow']   \n",
       "\n",
       "                                      bow_tokens  \\\n",
       "0       [4.522366523742676, -12.791789054870605]   \n",
       "1       [-16.068601608276367, -44.1268196105957]   \n",
       "2      [-58.391571044921875, 23.286211013793945]   \n",
       "3       [58.901100158691406, 30.188573837280273]   \n",
       "4       [-41.57936477661133, 31.845523834228516]   \n",
       "...                                          ...   \n",
       "31957   [-20.37633514404297, 61.130393981933594]   \n",
       "31958   [3.5070629119873047, 20.457685470581055]   \n",
       "31959    [-16.49297332763672, 33.97321319580078]   \n",
       "31960    [5.2635626792907715, 43.18000030517578]   \n",
       "31961     [-2.740935802459717, 2.17716121673584]   \n",
       "\n",
       "                                     bow_hashtags  \n",
       "0        [3.0793397426605225, 12.407670974731445]  \n",
       "1        [0.5125786662101746, 1.6410552263259888]  \n",
       "2      [-0.5365710854530334, -12.591863632202148]  \n",
       "3       [18.094478607177734, -19.416061401367188]  \n",
       "4         [7.747095108032227, -33.71648406982422]  \n",
       "...                                           ...  \n",
       "31957  [-0.5365710854530334, -12.591863632202148]  \n",
       "31958     [10.712545394897461, 4.604351043701172]  \n",
       "31959  [-0.5365710854530334, -12.591863632202148]  \n",
       "31960     [22.43916130065918, -8.663960456848145]  \n",
       "31961  [-0.5365710854530334, -12.591863632202148]  \n",
       "\n",
       "[31962 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"bow_tokens\"] = (hero.tsne(X[\"bow_tokens\"]))\n",
    "X[\"bow_hashtags\"] = (hero.tsne(X[\"bow_hashtags\"]))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split vector into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_tokens_1\", \"bow_tokens_\"]] = pd.DataFrame(X.bow_tokens.tolist(), index= X.index)\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_tokens_1\", \"bow_tokens_\"]] = pd.DataFrame(X.bow_tokens.tolist(), index= X.index)\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_hashtags_1\", \"bow_hashtags_2\"]] = pd.DataFrame(X.bow_hashtags.tolist(), index= X.index)\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_hashtags_1\", \"bow_hashtags_2\"]] = pd.DataFrame(X.bow_hashtags.tolist(), index= X.index)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>bow_tokens</th>\n",
       "      <th>bow_hashtags</th>\n",
       "      <th>bow_tokens_1</th>\n",
       "      <th>bow_tokens_</th>\n",
       "      <th>bow_hashtags_1</th>\n",
       "      <th>bow_hashtags_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>[4.522366523742676, -12.791789054870605]</td>\n",
       "      <td>[3.0793397426605225, 12.407670974731445]</td>\n",
       "      <td>4.522367</td>\n",
       "      <td>-12.791789</td>\n",
       "      <td>3.079340</td>\n",
       "      <td>12.407671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>[-16.068601608276367, -44.1268196105957]</td>\n",
       "      <td>[0.5125786662101746, 1.6410552263259888]</td>\n",
       "      <td>-16.068602</td>\n",
       "      <td>-44.126820</td>\n",
       "      <td>0.512579</td>\n",
       "      <td>1.641055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-58.391571044921875, 23.286211013793945]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "      <td>-58.391571</td>\n",
       "      <td>23.286211</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>[58.901100158691406, 30.188573837280273]</td>\n",
       "      <td>[18.094478607177734, -19.416061401367188]</td>\n",
       "      <td>58.901100</td>\n",
       "      <td>30.188574</td>\n",
       "      <td>18.094479</td>\n",
       "      <td>-19.416061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>[-41.57936477661133, 31.845523834228516]</td>\n",
       "      <td>[7.747095108032227, -33.71648406982422]</td>\n",
       "      <td>-41.579365</td>\n",
       "      <td>31.845524</td>\n",
       "      <td>7.747095</td>\n",
       "      <td>-33.716484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['user']</td>\n",
       "      <td>[-20.37633514404297, 61.130393981933594]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "      <td>-20.376335</td>\n",
       "      <td>61.130394</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>['shame', 'imwithher']</td>\n",
       "      <td>['see', 'turner', 'trying', 'wrap', 'mantle', ...</td>\n",
       "      <td>[3.5070629119873047, 20.457685470581055]</td>\n",
       "      <td>[10.712545394897461, 4.604351043701172]</td>\n",
       "      <td>3.507063</td>\n",
       "      <td>20.457685</td>\n",
       "      <td>10.712545</td>\n",
       "      <td>4.604351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song', 'morning']</td>\n",
       "      <td>[-16.49297332763672, 33.97321319580078]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "      <td>-16.492973</td>\n",
       "      <td>33.973213</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>['sikh', 'temple', 'calgary', 'wso']</td>\n",
       "      <td>['sikh', 'vandalised', 'wso', 'act']</td>\n",
       "      <td>[5.2635626792907715, 43.18000030517578]</td>\n",
       "      <td>[22.43916130065918, -8.663960456848145]</td>\n",
       "      <td>5.263563</td>\n",
       "      <td>43.180000</td>\n",
       "      <td>22.439161</td>\n",
       "      <td>-8.663960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['follow']</td>\n",
       "      <td>[-2.740935802459717, 2.17716121673584]</td>\n",
       "      <td>[-0.5365710854530334, -12.591863632202148]</td>\n",
       "      <td>-2.740936</td>\n",
       "      <td>2.177161</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions                    lemmatized_hashtags  \\\n",
       "0               1                                ['run']   \n",
       "1               2  ['lyft', 'disapointed', 'getthanked']   \n",
       "2               0                                     []   \n",
       "3               0                              ['model']   \n",
       "4               0                         ['motivation']   \n",
       "...           ...                                    ...   \n",
       "31957           1                                     []   \n",
       "31958           0                 ['shame', 'imwithher']   \n",
       "31959           0                                     []   \n",
       "31960           1   ['sikh', 'temple', 'calgary', 'wso']   \n",
       "31961           1                                     []   \n",
       "\n",
       "                                       lemmatized_tokens  \\\n",
       "0      ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1      ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                     []   \n",
       "3      ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                              ['society', 'motivation']   \n",
       "...                                                  ...   \n",
       "31957                                           ['user']   \n",
       "31958  ['see', 'turner', 'trying', 'wrap', 'mantle', ...   \n",
       "31959                                ['song', 'morning']   \n",
       "31960               ['sikh', 'vandalised', 'wso', 'act']   \n",
       "31961                                         ['follow']   \n",
       "\n",
       "                                      bow_tokens  \\\n",
       "0       [4.522366523742676, -12.791789054870605]   \n",
       "1       [-16.068601608276367, -44.1268196105957]   \n",
       "2      [-58.391571044921875, 23.286211013793945]   \n",
       "3       [58.901100158691406, 30.188573837280273]   \n",
       "4       [-41.57936477661133, 31.845523834228516]   \n",
       "...                                          ...   \n",
       "31957   [-20.37633514404297, 61.130393981933594]   \n",
       "31958   [3.5070629119873047, 20.457685470581055]   \n",
       "31959    [-16.49297332763672, 33.97321319580078]   \n",
       "31960    [5.2635626792907715, 43.18000030517578]   \n",
       "31961     [-2.740935802459717, 2.17716121673584]   \n",
       "\n",
       "                                     bow_hashtags  bow_tokens_1  bow_tokens_  \\\n",
       "0        [3.0793397426605225, 12.407670974731445]      4.522367   -12.791789   \n",
       "1        [0.5125786662101746, 1.6410552263259888]    -16.068602   -44.126820   \n",
       "2      [-0.5365710854530334, -12.591863632202148]    -58.391571    23.286211   \n",
       "3       [18.094478607177734, -19.416061401367188]     58.901100    30.188574   \n",
       "4         [7.747095108032227, -33.71648406982422]    -41.579365    31.845524   \n",
       "...                                           ...           ...          ...   \n",
       "31957  [-0.5365710854530334, -12.591863632202148]    -20.376335    61.130394   \n",
       "31958     [10.712545394897461, 4.604351043701172]      3.507063    20.457685   \n",
       "31959  [-0.5365710854530334, -12.591863632202148]    -16.492973    33.973213   \n",
       "31960     [22.43916130065918, -8.663960456848145]      5.263563    43.180000   \n",
       "31961  [-0.5365710854530334, -12.591863632202148]     -2.740936     2.177161   \n",
       "\n",
       "       bow_hashtags_1  bow_hashtags_2  \n",
       "0            3.079340       12.407671  \n",
       "1            0.512579        1.641055  \n",
       "2           -0.536571      -12.591864  \n",
       "3           18.094479      -19.416061  \n",
       "4            7.747095      -33.716484  \n",
       "...               ...             ...  \n",
       "31957       -0.536571      -12.591864  \n",
       "31958       10.712545        4.604351  \n",
       "31959       -0.536571      -12.591864  \n",
       "31960       22.439161       -8.663960  \n",
       "31961       -0.536571      -12.591864  \n",
       "\n",
       "[31962 rows x 9 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[\"bow_tokens_1\", \"bow_tokens_\"]] = pd.DataFrame(X.bow_tokens.tolist(), index= X.index)\n",
    "X[[\"bow_hashtags_1\", \"bow_hashtags_2\"]] = pd.DataFrame(X.bow_hashtags.tolist(), index= X.index)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>bow_tokens_1</th>\n",
       "      <th>bow_tokens_</th>\n",
       "      <th>bow_hashtags_1</th>\n",
       "      <th>bow_hashtags_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.522367</td>\n",
       "      <td>-12.791789</td>\n",
       "      <td>3.079340</td>\n",
       "      <td>12.407671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-16.068602</td>\n",
       "      <td>-44.126820</td>\n",
       "      <td>0.512579</td>\n",
       "      <td>1.641055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-58.391571</td>\n",
       "      <td>23.286211</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>58.901100</td>\n",
       "      <td>30.188574</td>\n",
       "      <td>18.094479</td>\n",
       "      <td>-19.416061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-41.579365</td>\n",
       "      <td>31.845524</td>\n",
       "      <td>7.747095</td>\n",
       "      <td>-33.716484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>1</td>\n",
       "      <td>-20.376335</td>\n",
       "      <td>61.130394</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>3.507063</td>\n",
       "      <td>20.457685</td>\n",
       "      <td>10.712545</td>\n",
       "      <td>4.604351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>-16.492973</td>\n",
       "      <td>33.973213</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>5.263563</td>\n",
       "      <td>43.180000</td>\n",
       "      <td>22.439161</td>\n",
       "      <td>-8.663960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.740936</td>\n",
       "      <td>2.177161</td>\n",
       "      <td>-0.536571</td>\n",
       "      <td>-12.591864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions  bow_tokens_1  bow_tokens_  bow_hashtags_1  bow_hashtags_2\n",
       "0               1      4.522367   -12.791789        3.079340       12.407671\n",
       "1               2    -16.068602   -44.126820        0.512579        1.641055\n",
       "2               0    -58.391571    23.286211       -0.536571      -12.591864\n",
       "3               0     58.901100    30.188574       18.094479      -19.416061\n",
       "4               0    -41.579365    31.845524        7.747095      -33.716484\n",
       "...           ...           ...          ...             ...             ...\n",
       "31957           1    -20.376335    61.130394       -0.536571      -12.591864\n",
       "31958           0      3.507063    20.457685       10.712545        4.604351\n",
       "31959           0    -16.492973    33.973213       -0.536571      -12.591864\n",
       "31960           1      5.263563    43.180000       22.439161       -8.663960\n",
       "31961           1     -2.740936     2.177161       -0.536571      -12.591864\n",
       "\n",
       "[31962 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = X[[\"n_mentions\", \"bow_tokens_1\", \"bow_tokens_\", \"bow_hashtags_1\", \"bow_hashtags_2\"]]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22373"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Data, y, test_size=0.3, random_state=55)\n",
    "\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.9278339764313276, 0.0], [2, 0.9278339764313276, 0.0], [3, 0.92950255501095, 0.08152173913043478], [4, 0.9306497027844405, 0.13298565840938725], [5, 0.9319011367191574, 0.12113055181695827], [6, 0.932839712170195, 0.1503957783641161], [7, 0.9335697152987799, 0.18437900128040974], [8, 0.9334654291375535, 0.18622448979591835], [9, 0.9337782876212327, 0.22085889570552147], [10, 0.9339868599436855, 0.2233128834355828], [11, 0.9334654291375535, 0.23132530120481926], [12, 0.9319011367191574, 0.24856156501726126], [13, 0.932318281364063, 0.26166097838452784], [14, 0.9314839920742517, 0.2708102108768035], [15, 0.9296068411721764, 0.2749731471535983], [16, 0.9286682657211388, 0.2860125260960334], [17, 0.9266868286578371, 0.2819203268641471], [18, 0.9249139639169882, 0.2828685258964143], [19, 0.9252268224006674, 0.2949852507374631], [20, 0.9231410991761393, 0.28792270531400965], [21, 0.9230368130149129, 0.29714285714285715], [22, 0.9182396495984982, 0.2885662431941924], [23, 0.9161539263739702, 0.2972027972027972], [24, 0.9145896339555741, 0.2982005141388175], [25, 0.91354677234331, 0.30042194092827], [26, 0.9109396183126499, 0.3], [27, 0.9065595995411408, 0.29448818897637796], [28, 0.9052038794451976, 0.2937062937062937], [29, 0.9040567316717072, 0.29770992366412213], [30, 0.9030138700594431, 0.2986425339366516], [31, 0.9021795807696319, 0.29685157421289354], [32, 0.9007195745124622, 0.29896907216494845], [33, 0.8995724267389718, 0.29963636363636365], [34, 0.8971738450307645, 0.2957142857142857], [35, 0.8969652727083116, 0.29327610872675247], [36, 0.8959224110960475, 0.29320113314447593], [37, 0.8941495463551986, 0.2877192982456141], [38, 0.8956095526123683, 0.29556650246305416], [39, 0.8950881218062363, 0.29453015427769985], [40, 0.8950881218062363, 0.2955182072829131], [41, 0.8920638231306706, 0.2857142857142857], [42, 0.8955052664511419, 0.3031988873435327], [43, 0.8945666910001043, 0.2915206727400141], [44, 0.8923766816143498, 0.2970027247956403], [45, 0.8919595369694442, 0.2933151432469304], [46, 0.893732401710293, 0.29088378566457895], [47, 0.8939409740327459, 0.2952182952182953], [48, 0.893732401710293, 0.2948096885813149], [49, 0.8946709771613307, 0.29469273743016755]]\n",
      "0.9278339764313276\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(1, 50):\n",
    "    classifier = DecisionTreeClassifier(random_state=55, max_depth=i)\n",
    "\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    #print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results.append([i,accuracy_score(y_test, y_pred), f1_score(y_test, y_pred)])\n",
    "\n",
    "print(results)\n",
    "print(y_test.value_counts()[0]/len(y_test))\n",
    "\n",
    "#plot_tree(classifier, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[1, 0.9278339764313276], [2, 0.9278339764313276], [3, 0.9296068411721764], [4, 0.9297111273334029], [5, 0.9311711335905726], [6, 0.9316925643967046], [7, 0.9320054228803838], [8, 0.9322139952028365], [9, 0.931275419751799], [10, 0.9327354260089686], [11, 0.932318281364063], [12, 0.9316925643967046], [13, 0.9298154134946293], [14, 0.9300239858170821], [15, 0.9292939826884973], [16, 0.9285639795599124], [17, 0.9292939826884973], [18, 0.9271039733027427], [19, 0.9248096777557618], [20, 0.9244968192720826], [21, 0.9206382313067056], [22, 0.9203253728230264], [23, 0.9161539263739702], [24, 0.9144853477943476], [25, 0.9147982062780269], [26, 0.911982479924914], [27, 0.9087496089268954], [28, 0.9072896026697257], [29, 0.9055167379288769], [30, 0.9042653039941599], [31, 0.9036395870268016], [32, 0.9040567316717072], [33, 0.9028052977369903], [34, 0.9028052977369903], [35, 0.903222442381896], [36, 0.9017624361247263], [37, 0.900928146834915], [38, 0.900928146834915], [39, 0.9011367191573678], [40, 0.9008238606736886], [41, 0.8987381374491605], [42, 0.8992595682552925], [43, 0.8989467097716133], [44, 0.8973824173532172], [45, 0.8958181249348212], [46, 0.8966524142246324], [47, 0.8961309834185004], [48, 0.8964438419021796], [49, 0.8957138387735948]]\n",
    "\n",
    "Dataset split: 0.9278339764313276"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "616c97465a6025a66a6be12e69d645bc9085c717f842c390f2a0b7dba71434fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
