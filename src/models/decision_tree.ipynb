{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>without_puctioation</th>\n",
       "      <th>tweet_lower</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>stemmed_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "      <td>user when a father is dysfunctional and is so...</td>\n",
       "      <td>['when', 'father', 'dysfunctional', 'is', 'sel...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drags'...</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunct', 'selfish', 'drag', 'kid...</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>['run']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "      <td>user user thanks for lyft credit i cant use ca...</td>\n",
       "      <td>['user', 'for', 'credit', 'cant', 'cause', 'do...</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'caus', 'dont', 'wh...</td>\n",
       "      <td>['lyft', 'disapoint', 'getthank']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>['your']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>['i', 'with', 'u', 'all', 'time', 'urð\\x9f\\x93...</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>['model']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['societi', 'motiv']</td>\n",
       "      <td>['motiv']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>['motivation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  n_mentions  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...           1   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...           2   \n",
       "2   3      0                                bihday your majesty           0   \n",
       "3   4      0  #model   i love u take with u all the time in ...           0   \n",
       "4   5      0             factsguide: society now    #motivation           0   \n",
       "\n",
       "                                hashtags  \\\n",
       "0                                ['run']   \n",
       "1  ['lyft', 'disapointed', 'getthanked']   \n",
       "2                                     []   \n",
       "3                              ['model']   \n",
       "4                         ['motivation']   \n",
       "\n",
       "                                 without_puctioation  \\\n",
       "0   user when a father is dysfunctional and is so...   \n",
       "1  user user thanks for lyft credit i cant use ca...   \n",
       "2                                bihday your majesty   \n",
       "3  model   i love u take with u all the time in u...   \n",
       "4               factsguide society now    motivation   \n",
       "\n",
       "                                         tweet_lower  \\\n",
       "0   user when a father is dysfunctional and is so...   \n",
       "1  user user thanks for lyft credit i cant use ca...   \n",
       "2                                bihday your majesty   \n",
       "3  model   i love u take with u all the time in u...   \n",
       "4               factsguide society now    motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  ['when', 'father', 'dysfunctional', 'is', 'sel...   \n",
       "1  ['user', 'for', 'credit', 'cant', 'cause', 'do...   \n",
       "2                                           ['your']   \n",
       "3  ['i', 'with', 'u', 'all', 'time', 'urð\\x9f\\x93...   \n",
       "4                          ['society', 'motivation']   \n",
       "\n",
       "                                         clean_token  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drags'...   \n",
       "1  ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                 []   \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                          ['society', 'motivation']   \n",
       "\n",
       "                          clean_hashtags  \\\n",
       "0                                ['run']   \n",
       "1  ['lyft', 'disapointed', 'getthanked']   \n",
       "2                                     []   \n",
       "3                              ['model']   \n",
       "4                         ['motivation']   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  ['father', 'dysfunct', 'selfish', 'drag', 'kid...   \n",
       "1  ['user', 'credit', 'cant', 'caus', 'dont', 'wh...   \n",
       "2                                                 []   \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                               ['societi', 'motiv']   \n",
       "\n",
       "                    stemmed_hashtags  \\\n",
       "0                            ['run']   \n",
       "1  ['lyft', 'disapoint', 'getthank']   \n",
       "2                                 []   \n",
       "3                          ['model']   \n",
       "4                          ['motiv']   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1  ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                 []   \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                          ['society', 'motivation']   \n",
       "\n",
       "                     lemmatized_hashtags  \n",
       "0                                ['run']  \n",
       "1  ['lyft', 'disapointed', 'getthanked']  \n",
       "2                                     []  \n",
       "3                              ['model']  \n",
       "4                         ['motivation']  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/220502_train_data_preprocessed.csv\", sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Up-sample Minority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate Minortity Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length majority 29720\n",
      "length minority 2242\n"
     ]
    }
   ],
   "source": [
    "data_minority = data[data.label == 1]\n",
    "data_majority = data[data.label == 0]\n",
    "print(\"length majority\", len(data_majority))\n",
    "print(\"length minority\", len(data_minority))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minority = resample(data_minority, replace = True, n_samples=29720, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1    29720\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_upsampled = pd.concat([data_majority, data_minority])\n",
    "data_upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_mentions                    lemmatized_hashtags  \\\n",
       "0           1                                ['run']   \n",
       "1           2  ['lyft', 'disapointed', 'getthanked']   \n",
       "2           0                                     []   \n",
       "3           0                              ['model']   \n",
       "4           0                         ['motivation']   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...  \n",
       "1  ['user', 'credit', 'cant', 'cause', 'dont', 'w...  \n",
       "2                                                 []  \n",
       "3  ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...  \n",
       "4                          ['society', 'motivation']  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"n_mentions\", \"lemmatized_hashtags\", \"lemmatized_tokens\"]\n",
    "X = data[features]\n",
    "y = data.label\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bag of words from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/3688221143.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_tokens\"] = (hero.tfidf(X[\"lemmatized_tokens\"], max_features=5000))\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/3688221143.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_hashtags\"] = (hero.tfidf(X[\"lemmatized_hashtags\"], max_features=5000))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>bow_tokens</th>\n",
       "      <th>bow_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051</th>\n",
       "      <td>1</td>\n",
       "      <td>['libtard', 'sjw', 'liberal', 'politics']</td>\n",
       "      <td>['libtard', 'libtard', 'liberal']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>3</td>\n",
       "      <td>['sandniggers']</td>\n",
       "      <td>['user', 'user', 'use', 'like', '2', 'hm', 'is...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>0</td>\n",
       "      <td>['brexit', 'hatecrime', 'nationalism']</td>\n",
       "      <td>['postbrexit', 'history', 'brexit', 'nationali...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>['knicks', 'golfâ']</td>\n",
       "      <td>['hand', 'barry', 'lied', 'game']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24175</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reply', 'dead', 'ð\\x9f\\x99\\x84']</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions                        lemmatized_hashtags  \\\n",
       "0               1                                    ['run']   \n",
       "1               2      ['lyft', 'disapointed', 'getthanked']   \n",
       "2               0                                         []   \n",
       "3               0                                  ['model']   \n",
       "4               0                             ['motivation']   \n",
       "...           ...                                        ...   \n",
       "17051           1  ['libtard', 'sjw', 'liberal', 'politics']   \n",
       "6518            3                            ['sandniggers']   \n",
       "9183            0     ['brexit', 'hatecrime', 'nationalism']   \n",
       "156             0                        ['knicks', 'golfâ']   \n",
       "24175           0                                         []   \n",
       "\n",
       "                                       lemmatized_tokens  \\\n",
       "0      ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1      ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                     []   \n",
       "3      ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                              ['society', 'motivation']   \n",
       "...                                                  ...   \n",
       "17051                  ['libtard', 'libtard', 'liberal']   \n",
       "6518   ['user', 'user', 'use', 'like', '2', 'hm', 'is...   \n",
       "9183   ['postbrexit', 'history', 'brexit', 'nationali...   \n",
       "156                    ['hand', 'barry', 'lied', 'game']   \n",
       "24175                 ['reply', 'dead', 'ð\\x9f\\x99\\x84']   \n",
       "\n",
       "                                              bow_tokens  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "17051  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6518   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9183   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "156    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24175  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            bow_hashtags  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "17051  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6518   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9183   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "156    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "24175  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[59440 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import texthero as hero\n",
    "from texthero import preprocessing\n",
    "X[\"bow_tokens\"] = (hero.tfidf(X[\"lemmatized_tokens\"], max_features=5000))\n",
    "X[\"bow_hashtags\"] = (hero.tfidf(X[\"lemmatized_hashtags\"], max_features=5000))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimension of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2594054688.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_tokens\"] = (hero.tsne(X[\"bow_tokens\"]))\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2594054688.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"bow_hashtags\"] = (hero.tsne(X[\"bow_hashtags\"]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>bow_tokens</th>\n",
       "      <th>bow_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>[-44.27634048461914, 25.174989700317383]</td>\n",
       "      <td>[-7.433860778808594, -15.336506843566895]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>[-17.095165252685547, 16.130037307739258]</td>\n",
       "      <td>[-34.860477447509766, -32.4604606628418]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-61.81212615966797, -0.12865515053272247]</td>\n",
       "      <td>[-3.994373321533203, 20.591201782226562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>[-19.474811553955078, -60.077354431152344]</td>\n",
       "      <td>[-18.86371421813965, 39.71250915527344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>[-30.36427879333496, 6.235439777374268]</td>\n",
       "      <td>[20.11435890197754, 57.742855072021484]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051</th>\n",
       "      <td>1</td>\n",
       "      <td>['libtard', 'sjw', 'liberal', 'politics']</td>\n",
       "      <td>['libtard', 'libtard', 'liberal']</td>\n",
       "      <td>[25.654123306274414, -55.03548812866211]</td>\n",
       "      <td>[41.280391693115234, 18.038806915283203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>3</td>\n",
       "      <td>['sandniggers']</td>\n",
       "      <td>['user', 'user', 'use', 'like', '2', 'hm', 'is...</td>\n",
       "      <td>[48.54783630371094, -30.92182159423828]</td>\n",
       "      <td>[30.957664489746094, -48.639408111572266]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>0</td>\n",
       "      <td>['brexit', 'hatecrime', 'nationalism']</td>\n",
       "      <td>['postbrexit', 'history', 'brexit', 'nationali...</td>\n",
       "      <td>[-8.348377227783203, -23.413721084594727]</td>\n",
       "      <td>[35.726680755615234, -9.232100486755371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>['knicks', 'golfâ']</td>\n",
       "      <td>['hand', 'barry', 'lied', 'game']</td>\n",
       "      <td>[45.90692901611328, -0.9228905439376831]</td>\n",
       "      <td>[-23.783769607543945, -47.45092010498047]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24175</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reply', 'dead', 'ð\\x9f\\x99\\x84']</td>\n",
       "      <td>[20.953445434570312, -7.560249328613281]</td>\n",
       "      <td>[7.337237358093262, 14.808087348937988]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions                        lemmatized_hashtags  \\\n",
       "0               1                                    ['run']   \n",
       "1               2      ['lyft', 'disapointed', 'getthanked']   \n",
       "2               0                                         []   \n",
       "3               0                                  ['model']   \n",
       "4               0                             ['motivation']   \n",
       "...           ...                                        ...   \n",
       "17051           1  ['libtard', 'sjw', 'liberal', 'politics']   \n",
       "6518            3                            ['sandniggers']   \n",
       "9183            0     ['brexit', 'hatecrime', 'nationalism']   \n",
       "156             0                        ['knicks', 'golfâ']   \n",
       "24175           0                                         []   \n",
       "\n",
       "                                       lemmatized_tokens  \\\n",
       "0      ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1      ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                     []   \n",
       "3      ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                              ['society', 'motivation']   \n",
       "...                                                  ...   \n",
       "17051                  ['libtard', 'libtard', 'liberal']   \n",
       "6518   ['user', 'user', 'use', 'like', '2', 'hm', 'is...   \n",
       "9183   ['postbrexit', 'history', 'brexit', 'nationali...   \n",
       "156                    ['hand', 'barry', 'lied', 'game']   \n",
       "24175                 ['reply', 'dead', 'ð\\x9f\\x99\\x84']   \n",
       "\n",
       "                                       bow_tokens  \\\n",
       "0        [-44.27634048461914, 25.174989700317383]   \n",
       "1       [-17.095165252685547, 16.130037307739258]   \n",
       "2      [-61.81212615966797, -0.12865515053272247]   \n",
       "3      [-19.474811553955078, -60.077354431152344]   \n",
       "4         [-30.36427879333496, 6.235439777374268]   \n",
       "...                                           ...   \n",
       "17051    [25.654123306274414, -55.03548812866211]   \n",
       "6518      [48.54783630371094, -30.92182159423828]   \n",
       "9183    [-8.348377227783203, -23.413721084594727]   \n",
       "156      [45.90692901611328, -0.9228905439376831]   \n",
       "24175    [20.953445434570312, -7.560249328613281]   \n",
       "\n",
       "                                    bow_hashtags  \n",
       "0      [-7.433860778808594, -15.336506843566895]  \n",
       "1       [-34.860477447509766, -32.4604606628418]  \n",
       "2       [-3.994373321533203, 20.591201782226562]  \n",
       "3        [-18.86371421813965, 39.71250915527344]  \n",
       "4        [20.11435890197754, 57.742855072021484]  \n",
       "...                                          ...  \n",
       "17051   [41.280391693115234, 18.038806915283203]  \n",
       "6518   [30.957664489746094, -48.639408111572266]  \n",
       "9183    [35.726680755615234, -9.232100486755371]  \n",
       "156    [-23.783769607543945, -47.45092010498047]  \n",
       "24175    [7.337237358093262, 14.808087348937988]  \n",
       "\n",
       "[59440 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"bow_tokens\"] = (hero.tsne(X[\"bow_tokens\"]))\n",
    "X[\"bow_hashtags\"] = (hero.tsne(X[\"bow_hashtags\"]))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split vector into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_tokens_1\", \"bow_tokens_\"]] = pd.DataFrame(X.bow_tokens.tolist(), index= X.index)\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_tokens_1\", \"bow_tokens_\"]] = pd.DataFrame(X.bow_tokens.tolist(), index= X.index)\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_hashtags_1\", \"bow_hashtags_2\"]] = pd.DataFrame(X.bow_hashtags.tolist(), index= X.index)\n",
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_14199/2517448426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[[\"bow_hashtags_1\", \"bow_hashtags_2\"]] = pd.DataFrame(X.bow_hashtags.tolist(), index= X.index)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>lemmatized_hashtags</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>bow_tokens</th>\n",
       "      <th>bow_hashtags</th>\n",
       "      <th>bow_tokens_1</th>\n",
       "      <th>bow_tokens_</th>\n",
       "      <th>bow_hashtags_1</th>\n",
       "      <th>bow_hashtags_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['run']</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>[-44.27634048461914, 25.174989700317383]</td>\n",
       "      <td>[-7.433860778808594, -15.336506843566895]</td>\n",
       "      <td>-44.276340</td>\n",
       "      <td>25.174990</td>\n",
       "      <td>-7.433861</td>\n",
       "      <td>-15.336507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lyft', 'disapointed', 'getthanked']</td>\n",
       "      <td>['user', 'credit', 'cant', 'cause', 'dont', 'w...</td>\n",
       "      <td>[-17.095165252685547, 16.130037307739258]</td>\n",
       "      <td>[-34.860477447509766, -32.4604606628418]</td>\n",
       "      <td>-17.095165</td>\n",
       "      <td>16.130037</td>\n",
       "      <td>-34.860477</td>\n",
       "      <td>-32.460461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-61.81212615966797, -0.12865515053272247]</td>\n",
       "      <td>[-3.994373321533203, 20.591201782226562]</td>\n",
       "      <td>-61.812126</td>\n",
       "      <td>-0.128655</td>\n",
       "      <td>-3.994373</td>\n",
       "      <td>20.591202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['model']</td>\n",
       "      <td>['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...</td>\n",
       "      <td>[-19.474811553955078, -60.077354431152344]</td>\n",
       "      <td>[-18.86371421813965, 39.71250915527344]</td>\n",
       "      <td>-19.474812</td>\n",
       "      <td>-60.077354</td>\n",
       "      <td>-18.863714</td>\n",
       "      <td>39.712509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['motivation']</td>\n",
       "      <td>['society', 'motivation']</td>\n",
       "      <td>[-30.36427879333496, 6.235439777374268]</td>\n",
       "      <td>[20.11435890197754, 57.742855072021484]</td>\n",
       "      <td>-30.364279</td>\n",
       "      <td>6.235440</td>\n",
       "      <td>20.114359</td>\n",
       "      <td>57.742855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051</th>\n",
       "      <td>1</td>\n",
       "      <td>['libtard', 'sjw', 'liberal', 'politics']</td>\n",
       "      <td>['libtard', 'libtard', 'liberal']</td>\n",
       "      <td>[25.654123306274414, -55.03548812866211]</td>\n",
       "      <td>[41.280391693115234, 18.038806915283203]</td>\n",
       "      <td>25.654123</td>\n",
       "      <td>-55.035488</td>\n",
       "      <td>41.280392</td>\n",
       "      <td>18.038807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>3</td>\n",
       "      <td>['sandniggers']</td>\n",
       "      <td>['user', 'user', 'use', 'like', '2', 'hm', 'is...</td>\n",
       "      <td>[48.54783630371094, -30.92182159423828]</td>\n",
       "      <td>[30.957664489746094, -48.639408111572266]</td>\n",
       "      <td>48.547836</td>\n",
       "      <td>-30.921822</td>\n",
       "      <td>30.957664</td>\n",
       "      <td>-48.639408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>0</td>\n",
       "      <td>['brexit', 'hatecrime', 'nationalism']</td>\n",
       "      <td>['postbrexit', 'history', 'brexit', 'nationali...</td>\n",
       "      <td>[-8.348377227783203, -23.413721084594727]</td>\n",
       "      <td>[35.726680755615234, -9.232100486755371]</td>\n",
       "      <td>-8.348377</td>\n",
       "      <td>-23.413721</td>\n",
       "      <td>35.726681</td>\n",
       "      <td>-9.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>['knicks', 'golfâ']</td>\n",
       "      <td>['hand', 'barry', 'lied', 'game']</td>\n",
       "      <td>[45.90692901611328, -0.9228905439376831]</td>\n",
       "      <td>[-23.783769607543945, -47.45092010498047]</td>\n",
       "      <td>45.906929</td>\n",
       "      <td>-0.922891</td>\n",
       "      <td>-23.783770</td>\n",
       "      <td>-47.450920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24175</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reply', 'dead', 'ð\\x9f\\x99\\x84']</td>\n",
       "      <td>[20.953445434570312, -7.560249328613281]</td>\n",
       "      <td>[7.337237358093262, 14.808087348937988]</td>\n",
       "      <td>20.953445</td>\n",
       "      <td>-7.560249</td>\n",
       "      <td>7.337237</td>\n",
       "      <td>14.808087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59440 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions                        lemmatized_hashtags  \\\n",
       "0               1                                    ['run']   \n",
       "1               2      ['lyft', 'disapointed', 'getthanked']   \n",
       "2               0                                         []   \n",
       "3               0                                  ['model']   \n",
       "4               0                             ['motivation']   \n",
       "...           ...                                        ...   \n",
       "17051           1  ['libtard', 'sjw', 'liberal', 'politics']   \n",
       "6518            3                            ['sandniggers']   \n",
       "9183            0     ['brexit', 'hatecrime', 'nationalism']   \n",
       "156             0                        ['knicks', 'golfâ']   \n",
       "24175           0                                         []   \n",
       "\n",
       "                                       lemmatized_tokens  \\\n",
       "0      ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1      ['user', 'credit', 'cant', 'cause', 'dont', 'w...   \n",
       "2                                                     []   \n",
       "3      ['u', 'time', 'urð\\x9f\\x93±', 'ð\\x9f\\x92¦ð\\x9f...   \n",
       "4                              ['society', 'motivation']   \n",
       "...                                                  ...   \n",
       "17051                  ['libtard', 'libtard', 'liberal']   \n",
       "6518   ['user', 'user', 'use', 'like', '2', 'hm', 'is...   \n",
       "9183   ['postbrexit', 'history', 'brexit', 'nationali...   \n",
       "156                    ['hand', 'barry', 'lied', 'game']   \n",
       "24175                 ['reply', 'dead', 'ð\\x9f\\x99\\x84']   \n",
       "\n",
       "                                       bow_tokens  \\\n",
       "0        [-44.27634048461914, 25.174989700317383]   \n",
       "1       [-17.095165252685547, 16.130037307739258]   \n",
       "2      [-61.81212615966797, -0.12865515053272247]   \n",
       "3      [-19.474811553955078, -60.077354431152344]   \n",
       "4         [-30.36427879333496, 6.235439777374268]   \n",
       "...                                           ...   \n",
       "17051    [25.654123306274414, -55.03548812866211]   \n",
       "6518      [48.54783630371094, -30.92182159423828]   \n",
       "9183    [-8.348377227783203, -23.413721084594727]   \n",
       "156      [45.90692901611328, -0.9228905439376831]   \n",
       "24175    [20.953445434570312, -7.560249328613281]   \n",
       "\n",
       "                                    bow_hashtags  bow_tokens_1  bow_tokens_  \\\n",
       "0      [-7.433860778808594, -15.336506843566895]    -44.276340    25.174990   \n",
       "1       [-34.860477447509766, -32.4604606628418]    -17.095165    16.130037   \n",
       "2       [-3.994373321533203, 20.591201782226562]    -61.812126    -0.128655   \n",
       "3        [-18.86371421813965, 39.71250915527344]    -19.474812   -60.077354   \n",
       "4        [20.11435890197754, 57.742855072021484]    -30.364279     6.235440   \n",
       "...                                          ...           ...          ...   \n",
       "17051   [41.280391693115234, 18.038806915283203]     25.654123   -55.035488   \n",
       "6518   [30.957664489746094, -48.639408111572266]     48.547836   -30.921822   \n",
       "9183    [35.726680755615234, -9.232100486755371]     -8.348377   -23.413721   \n",
       "156    [-23.783769607543945, -47.45092010498047]     45.906929    -0.922891   \n",
       "24175    [7.337237358093262, 14.808087348937988]     20.953445    -7.560249   \n",
       "\n",
       "       bow_hashtags_1  bow_hashtags_2  \n",
       "0           -7.433861      -15.336507  \n",
       "1          -34.860477      -32.460461  \n",
       "2           -3.994373       20.591202  \n",
       "3          -18.863714       39.712509  \n",
       "4           20.114359       57.742855  \n",
       "...               ...             ...  \n",
       "17051       41.280392       18.038807  \n",
       "6518        30.957664      -48.639408  \n",
       "9183        35.726681       -9.232100  \n",
       "156        -23.783770      -47.450920  \n",
       "24175        7.337237       14.808087  \n",
       "\n",
       "[59440 rows x 9 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[\"bow_tokens_1\", \"bow_tokens_\"]] = pd.DataFrame(X.bow_tokens.tolist(), index= X.index)\n",
    "X[[\"bow_hashtags_1\", \"bow_hashtags_2\"]] = pd.DataFrame(X.bow_hashtags.tolist(), index= X.index)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>bow_tokens_1</th>\n",
       "      <th>bow_tokens_</th>\n",
       "      <th>bow_hashtags_1</th>\n",
       "      <th>bow_hashtags_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-44.276340</td>\n",
       "      <td>25.174990</td>\n",
       "      <td>-7.433861</td>\n",
       "      <td>-15.336507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-17.095165</td>\n",
       "      <td>16.130037</td>\n",
       "      <td>-34.860477</td>\n",
       "      <td>-32.460461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-61.812126</td>\n",
       "      <td>-0.128655</td>\n",
       "      <td>-3.994373</td>\n",
       "      <td>20.591202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-19.474812</td>\n",
       "      <td>-60.077354</td>\n",
       "      <td>-18.863714</td>\n",
       "      <td>39.712509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-30.364279</td>\n",
       "      <td>6.235440</td>\n",
       "      <td>20.114359</td>\n",
       "      <td>57.742855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051</th>\n",
       "      <td>1</td>\n",
       "      <td>25.654123</td>\n",
       "      <td>-55.035488</td>\n",
       "      <td>41.280392</td>\n",
       "      <td>18.038807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>3</td>\n",
       "      <td>48.547836</td>\n",
       "      <td>-30.921822</td>\n",
       "      <td>30.957664</td>\n",
       "      <td>-48.639408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>0</td>\n",
       "      <td>-8.348377</td>\n",
       "      <td>-23.413721</td>\n",
       "      <td>35.726681</td>\n",
       "      <td>-9.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>45.906929</td>\n",
       "      <td>-0.922891</td>\n",
       "      <td>-23.783770</td>\n",
       "      <td>-47.450920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24175</th>\n",
       "      <td>0</td>\n",
       "      <td>20.953445</td>\n",
       "      <td>-7.560249</td>\n",
       "      <td>7.337237</td>\n",
       "      <td>14.808087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_mentions  bow_tokens_1  bow_tokens_  bow_hashtags_1  bow_hashtags_2\n",
       "0               1    -44.276340    25.174990       -7.433861      -15.336507\n",
       "1               2    -17.095165    16.130037      -34.860477      -32.460461\n",
       "2               0    -61.812126    -0.128655       -3.994373       20.591202\n",
       "3               0    -19.474812   -60.077354      -18.863714       39.712509\n",
       "4               0    -30.364279     6.235440       20.114359       57.742855\n",
       "...           ...           ...          ...             ...             ...\n",
       "17051           1     25.654123   -55.035488       41.280392       18.038807\n",
       "6518            3     48.547836   -30.921822       30.957664      -48.639408\n",
       "9183            0     -8.348377   -23.413721       35.726681       -9.232100\n",
       "156             0     45.906929    -0.922891      -23.783770      -47.450920\n",
       "24175           0     20.953445    -7.560249        7.337237       14.808087\n",
       "\n",
       "[59440 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = X[[\"n_mentions\", \"bow_tokens_1\", \"bow_tokens_\", \"bow_hashtags_1\", \"bow_hashtags_2\"]]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41608"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Data, y, test_size=0.3, random_state=55)\n",
    "\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.6685172723194257], [2, 0.735699865410498], [3, 0.7965455361148497], [4, 0.8115746971736204], [5, 0.8237999102736653], [6, 0.8412404665769403], [7, 0.8648497083894123], [8, 0.8816733961417677], [9, 0.8995065051592642], [10, 0.9141431135038134], [11, 0.9215455361148497], [12, 0.9355652759084792], [13, 0.9502018842530283], [14, 0.9582772543741588], [15, 0.9637729923732615], [16, 0.9691004934948407], [17, 0.9718483624943921], [18, 0.9748766262898161], [19, 0.9768393898609242], [20, 0.9777366532077164], [21, 0.9776244952893675], [22, 0.9785778375953342], [23, 0.9781852848811126], [24, 0.9779048900852401], [25, 0.9776805742485419], [26, 0.9789143113503813], [27, 0.9785217586361598], [28, 0.9785778375953342], [29, 0.9787460744728578], [30, 0.9782413638402871], [31, 0.9784656796769852], [32, 0.9785217586361598], [33, 0.9785217586361598], [34, 0.9785217586361598], [35, 0.9785217586361598], [36, 0.9785217586361598], [37, 0.9785217586361598], [38, 0.9785217586361598], [39, 0.9785217586361598], [40, 0.9785217586361598], [41, 0.9785217586361598], [42, 0.9785217586361598], [43, 0.9785217586361598], [44, 0.9785217586361598], [45, 0.9785217586361598], [46, 0.9785217586361598], [47, 0.9785217586361598], [48, 0.9785217586361598], [49, 0.9785217586361598]]\n",
      "0.5043741588156124\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(1, 50):\n",
    "    classifier = DecisionTreeClassifier(random_state=55, max_depth=i)\n",
    "\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    #print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results.append([i,accuracy_score(y_test, y_pred)])\n",
    "\n",
    "print(results)\n",
    "print(y_test.value_counts()[0]/len(y_test))\n",
    "#plot_tree(classifier, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[1, 0.9278339764313276], [2, 0.9278339764313276], [3, 0.9296068411721764], [4, 0.9297111273334029], [5, 0.9311711335905726], [6, 0.9316925643967046], [7, 0.9320054228803838], [8, 0.9322139952028365], [9, 0.931275419751799], [10, 0.9327354260089686], [11, 0.932318281364063], [12, 0.9316925643967046], [13, 0.9298154134946293], [14, 0.9300239858170821], [15, 0.9292939826884973], [16, 0.9285639795599124], [17, 0.9292939826884973], [18, 0.9271039733027427], [19, 0.9248096777557618], [20, 0.9244968192720826], [21, 0.9206382313067056], [22, 0.9203253728230264], [23, 0.9161539263739702], [24, 0.9144853477943476], [25, 0.9147982062780269], [26, 0.911982479924914], [27, 0.9087496089268954], [28, 0.9072896026697257], [29, 0.9055167379288769], [30, 0.9042653039941599], [31, 0.9036395870268016], [32, 0.9040567316717072], [33, 0.9028052977369903], [34, 0.9028052977369903], [35, 0.903222442381896], [36, 0.9017624361247263], [37, 0.900928146834915], [38, 0.900928146834915], [39, 0.9011367191573678], [40, 0.9008238606736886], [41, 0.8987381374491605], [42, 0.8992595682552925], [43, 0.8989467097716133], [44, 0.8973824173532172], [45, 0.8958181249348212], [46, 0.8966524142246324], [47, 0.8961309834185004], [48, 0.8964438419021796], [49, 0.8957138387735948]]\n",
    "\n",
    "Dataset split: 0.9278339764313276"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "616c97465a6025a66a6be12e69d645bc9085c717f842c390f2a0b7dba71434fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
