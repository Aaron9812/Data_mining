{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22350aa6",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cda7c2",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [1. Preparation](#Preparation)\n",
    "* [2 Model Building](#modelBuilding)\n",
    "* [3. Training and Evaluation](#training)\n",
    "    * [Evaluate with only tokenization 1.1](#section_1_1)\n",
    "    * [Evaluate with stopwords removal](sSection_1_2)\n",
    "    * [Evaluate with Stemming](sSection_1_2)\n",
    "    * [Evaluate with Upsampling](sSection_1_2)\n",
    "        * [Section 1.2.1](#section_1_2_1)\n",
    "        * [Section 1.2.2](#section_1_2_2)\n",
    "        * [Section 1.2.3](#section_1_2_3)\n",
    "* [3. Deal with imbalanced classes](#training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91916bd0",
   "metadata": {},
   "source": [
    "### 1. Preparation <a class=\"anchor\" id=\"Preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e48193c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXpgP2m6l4s_",
    "outputId": "a337f89c-9a7d-47a4-df86-f7283641d47a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Requirement already satisfied: datasets in c:\\users\\d073999\\miniconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (2022.3.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (0.5.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\d073999\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4e4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\d073999\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: demoji in c:\\users\\d073999\\miniconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d8b711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Requirement already satisfied: mlxtend in c:\\users\\d073999\\miniconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (52.0.0.post20210125)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlxtend) (1.21.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\d073999\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556c7765",
   "metadata": {
    "id": "aeVbKIG2kdys"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Documents\\uni-Mannheim\\Data_Mining_I\\Data_mining\\src\\models\\preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "#from datasets import list_datasets, load_dataset # hugging face dataset\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "import torch\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "#sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "path = \"preprocessing.py\"\n",
    "\n",
    "file_name = os.path.abspath(os.path.join(os.path.dirname( 'data'), '..'))\n",
    "file_name = os.path.abspath(path)\n",
    "print(file_name)\n",
    "#from src.data.preprocessing import setup\n",
    "\n",
    "\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin, TransformerMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from  sklearn.feature_extraction.text import TfidfTransformer\n",
    "SEED = 1234\n",
    "\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "from datasets import list_datasets, load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b509d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D073999\\Documents\\uni-Mannheim\\Data_Mining_I\\Data_mining\\src\\models\\KNN.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"KNN.ipynb\"\n",
    "\n",
    "file_name = os.path.abspath(os.path.join(os.path.dirname( 'models'), '.'))\n",
    "file_name = os.path.abspath(path)\n",
    "\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a1ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, 'C:\\\\Users\\\\D073999\\\\Documents\\\\uni-Mannheim\\\\Data_Mining_I\\\\Data_mining\\\\src\\\\data')\n",
    "\n",
    "from preprocessing import preprocess,load_data, convert_emoji, upsampling, setup\n",
    "#from src.data import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a81da7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 10:51:25,175 WARNING Using custom data configuration default\n",
      "2022-05-21 10:51:25,207 WARNING Reusing dataset tweets_hate_speech_detection (C:\\Users\\D073999\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c5b296567a49d4ac103b8a99923fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf, df_train, df_test = setup(do_emojis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa34ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadManager():\n",
    "    def __init__(self):\n",
    "        self.db = DBManager()\n",
    "        #self.data_transformer = Transformer()\n",
    "        \n",
    "    def fit(self):\n",
    "        df = db.load_data()\n",
    "        df = db.replace_user(df)\n",
    "        X, y = db.target_feature_selection(df)\n",
    "        X_train, X_test, y_train, y_test = db.split_data(X, y)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1136b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentFeaturizer():\n",
    "    def __init__(self):\n",
    "        self.porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    @staticmethod\n",
    "    def replace_user(df):\n",
    "        assert isinstance(df, pd.DataFrame), \"input musst be a data-frame\"\n",
    "        df['tweet']= df['tweet'].str.replace(\"@user\",\"\")\n",
    "        print(\"removed @user\")\n",
    "        return df\n",
    "\n",
    "    \n",
    "    # Currently not in use\n",
    "    @staticmethod\n",
    "    def remove_punctioation(text:str) -> str:\n",
    "        return \"\".join([i for i in text if i not in punctuation])\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenization(text:str) -> list:\n",
    "        return nltk.word_tokenize(text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_stopwords(tokens) ->list:\n",
    "        stopwords_list = stopwords.words(\"english\")\n",
    "        return [token for token in tokens if token not in stopwords_list]\n",
    "\n",
    "    \n",
    "   \n",
    "    def stemming(self, text:str) -> list:\n",
    "        return [self.porter_stemmer.stem(word) for word in text]\n",
    "\n",
    "    @staticmethod\n",
    "    def lower_case(row):\n",
    "        return row_lower()\n",
    "        #return row.apply(lambda x: stemming(remove_stopwords(tokenization(remove_punctioation(x.lower())))))\n",
    "     \n",
    "    @staticmethod\n",
    "    def convert_emoji(text: str):\n",
    "        return emoji.demojize(text.lower(), language='en')\n",
    "    \n",
    "    \n",
    "\n",
    "    def dummy(self, text):\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def featurize(self, data):\n",
    "        df['tweet']= df['tweet'].str.replace(\"@user\",\"\")\n",
    "        #data['tweet'] = data['tweet'].progress_apply(self.lower_case)\n",
    "        print(\"Remove emojis..\")\n",
    "        data['removed_emoji'] =  data['tweet'].progress_apply(convert_emoji)\n",
    "        print(\"Tokenized..\")\n",
    "        data['tokenized'] = data['removed_emoji'].progress_apply(self.tokenization)\n",
    "        print(\"Remove Stopwords ...\")\n",
    "        data['remove_stopwords'] = data['tokenized'].progress_apply(self.remove_stopwords)\n",
    "        print(\"stemming..\")\n",
    "        data['stemmed_words'] = data['remove_stopwords'].progress_apply(self.stemming)\n",
    "        \n",
    "        feature_dict = {\n",
    "                \"tokenized_sentence\": data['tokenized'],\n",
    "                \"remove_stopwords\": data['remove_stopwords'],\n",
    "                \"stemmed_words\": data['stemmed_words'],\n",
    "                \"removed_emoji\": data['removed_emoji'],\n",
    "                #\"lower_case\": data['lower_case']\n",
    "            }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b79f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "class DBManager(SegmentFeaturizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def __str__(self):\n",
    "            return repr(self) + \" load, splitt, process & encode data\"\n",
    "    \n",
    "    def list_avaliable_data(self):\n",
    "        datasets_list = list_datasets() \n",
    "        pprint(datasets_list)\n",
    "    \n",
    "    \n",
    "    def load_data(self, data_name : str = \"tweets_hate_speech_detection\"):\n",
    "        dataset = load_dataset(data_name)\n",
    "        df = pd.DataFrame.from_dict(dataset['train'])\n",
    "        print(f'{data_name} has been loaded with the shape of {df.shape}')\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def target_feature_selection(self, df):\n",
    "        print('target feature selection')\n",
    "        print(f'Select X as {df.columns.values.tolist()[0]} & y as {df.columns.values.tolist()[1]}')\n",
    "        return df['tweet'], df['label']\n",
    "    \n",
    "        \n",
    "    def split_data(self, X, y, test_size= 0.2, random_state= SEED):\n",
    "         return ms.train_test_split(\n",
    "                                     X,\n",
    "                                     y,\n",
    "                                     test_size=test_size,\n",
    "                                     random_state = 17,\n",
    "                                     stratify=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8773cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2 Downl <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292a5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 23:37:03,225 WARNING Using custom data configuration default\n",
      "2022-05-20 23:37:03,236 WARNING Reusing dataset tweets_hate_speech_detection (C:\\Users\\D073999\\.cache\\huggingface\\datasets\\tweets_hate_speech_detection\\default\\0.0.0\\c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e70bba632f4b97b11f286921eb7cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_hate_speech_detection has been loaded with the shape of (31962, 2)\n"
     ]
    }
   ],
   "source": [
    "db = DBManager()\n",
    "df = db.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df851ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove emojis..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [00:13<00:00, 2360.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [00:04<00:00, 7243.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove Stopwords ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [00:20<00:00, 1590.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemming..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [00:05<00:00, 6147.45it/s]\n"
     ]
    }
   ],
   "source": [
    "data = db.featurize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f827320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>removed_emoji</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>stemmed_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so self...</td>\n",
       "      <td>when a father is dysfunctional and is so self...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "      <td>[thanks, for, #, lyft, credit, i, ca, n't, use...</td>\n",
       "      <td>[thanks, #, lyft, credit, ca, n't, use, cause,...</td>\n",
       "      <td>[thank, #, lyft, credit, ca, n't, use, caus, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>[#, model, i, love, u, take, with, u, all, the...</td>\n",
       "      <td>[#, model, love, u, take, u, time, urmobile, p...</td>\n",
       "      <td>[#, model, love, u, take, u, time, urmobil, ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>[factsguide, :, society, now, #, motivation]</td>\n",
       "      <td>[factsguide, :, society, #, motivation]</td>\n",
       "      <td>[factsguid, :, societi, #, motiv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>0</td>\n",
       "      <td>ate  isz that youuu?ððððððð...</td>\n",
       "      <td>ate  isz that youuu?smiling face with heart-ey...</td>\n",
       "      <td>[ate, isz, that, youuu, ?, smiling, face, with...</td>\n",
       "      <td>[ate, isz, youuu, ?, smiling, face, heart-eyes...</td>\n",
       "      <td>[ate, isz, youuu, ?, smile, face, heart-ey, sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "      <td>to see nina turner on the airwaves trying to w...</td>\n",
       "      <td>[to, see, nina, turner, on, the, airwaves, try...</td>\n",
       "      <td>[see, nina, turner, airwaves, trying, wrap, ma...</td>\n",
       "      <td>[see, nina, turner, airwav, tri, wrap, mantl, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>[listening, to, sad, songs, on, a, monday, mor...</td>\n",
       "      <td>[listening, sad, songs, monday, morning, otw, ...</td>\n",
       "      <td>[listen, sad, song, monday, morn, otw, work, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>#sikh #temple vandalised in in #calgary, #wso...</td>\n",
       "      <td>#sikh #temple vandalised in in #calgary, #wso...</td>\n",
       "      <td>[#, sikh, #, temple, vandalised, in, in, #, ca...</td>\n",
       "      <td>[#, sikh, #, temple, vandalised, #, calgary, ,...</td>\n",
       "      <td>[#, sikh, #, templ, vandalis, #, calgari, ,, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "      <td>[thank, follow]</td>\n",
       "      <td>[thank, follow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet  \\\n",
       "0          0   when a father is dysfunctional and is so self...   \n",
       "1          0    thanks for #lyft credit i can't use cause th...   \n",
       "2          0                                bihday your majesty   \n",
       "3          0  #model   i love u take with u all the time in ...   \n",
       "4          0             factsguide: society now    #motivation   \n",
       "...      ...                                                ...   \n",
       "31957      0  ate  isz that youuu?ððððððð...   \n",
       "31958      0  to see nina turner on the airwaves trying to w...   \n",
       "31959      0  listening to sad songs on a monday morning otw...   \n",
       "31960      1   #sikh #temple vandalised in in #calgary, #wso...   \n",
       "31961      0                        thank you  for you follow     \n",
       "\n",
       "                                           removed_emoji  \\\n",
       "0       when a father is dysfunctional and is so self...   \n",
       "1        thanks for #lyft credit i can't use cause th...   \n",
       "2                                    bihday your majesty   \n",
       "3      #model   i love u take with u all the time in ...   \n",
       "4                 factsguide: society now    #motivation   \n",
       "...                                                  ...   \n",
       "31957  ate  isz that youuu?smiling face with heart-ey...   \n",
       "31958  to see nina turner on the airwaves trying to w...   \n",
       "31959  listening to sad songs on a monday morning otw...   \n",
       "31960   #sikh #temple vandalised in in #calgary, #wso...   \n",
       "31961                        thank you  for you follow     \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [when, a, father, is, dysfunctional, and, is, ...   \n",
       "1      [thanks, for, #, lyft, credit, i, ca, n't, use...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3      [#, model, i, love, u, take, with, u, all, the...   \n",
       "4           [factsguide, :, society, now, #, motivation]   \n",
       "...                                                  ...   \n",
       "31957  [ate, isz, that, youuu, ?, smiling, face, with...   \n",
       "31958  [to, see, nina, turner, on, the, airwaves, try...   \n",
       "31959  [listening, to, sad, songs, on, a, monday, mor...   \n",
       "31960  [#, sikh, #, temple, vandalised, in, in, #, ca...   \n",
       "31961                     [thank, you, for, you, follow]   \n",
       "\n",
       "                                        remove_stopwords  \\\n",
       "0      [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1      [thanks, #, lyft, credit, ca, n't, use, cause,...   \n",
       "2                                      [bihday, majesty]   \n",
       "3      [#, model, love, u, take, u, time, urmobile, p...   \n",
       "4                [factsguide, :, society, #, motivation]   \n",
       "...                                                  ...   \n",
       "31957  [ate, isz, youuu, ?, smiling, face, heart-eyes...   \n",
       "31958  [see, nina, turner, airwaves, trying, wrap, ma...   \n",
       "31959  [listening, sad, songs, monday, morning, otw, ...   \n",
       "31960  [#, sikh, #, temple, vandalised, #, calgary, ,...   \n",
       "31961                                    [thank, follow]   \n",
       "\n",
       "                                           stemmed_words  \n",
       "0      [father, dysfunct, selfish, drag, kid, dysfunc...  \n",
       "1      [thank, #, lyft, credit, ca, n't, use, caus, n...  \n",
       "2                                      [bihday, majesti]  \n",
       "3      [#, model, love, u, take, u, time, urmobil, ph...  \n",
       "4                      [factsguid, :, societi, #, motiv]  \n",
       "...                                                  ...  \n",
       "31957  [ate, isz, youuu, ?, smile, face, heart-ey, sm...  \n",
       "31958  [see, nina, turner, airwav, tri, wrap, mantl, ...  \n",
       "31959  [listen, sad, song, monday, morn, otw, work, sad]  \n",
       "31960  [#, sikh, #, templ, vandalis, #, calgari, ,, #...  \n",
       "31961                                    [thank, follow]  \n",
       "\n",
       "[31962 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f629d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_featurizer = SegmentFeaturizer()  # more on this below\n",
    "class CustomLinguisticFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        return segment_featurizer.featurize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b340bb2",
   "metadata": {},
   "source": [
    "### 1. Upload & Splitt Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c390a8d",
   "metadata": {},
   "source": [
    "### 1.1 check the distribution of labels, i.e. labels-distribution on test are to some extent reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3e929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax=sns.countplot(df_train.label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.countplot(df_test.label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'label distribution on train:\\n {y_train.value_counts()}')\n",
    "print(80*'-')\n",
    "print(f'label distribution on test:\\n {y_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618dcc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label']; X_train = df_train.drop(columns=['label'])\n",
    "y_test = df_test['label']; X_test = df_test.drop(columns=['label'])\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_copy = X_train\n",
    "y_t_copy = y_train\n",
    "X_s_copy = X_test\n",
    "y_s_copy = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e970ed",
   "metadata": {},
   "source": [
    "### TFIDF Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8f222c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.tf_idf = text.TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    def fit(self, X, y=None, tf_idf=True):\n",
    "        print(\"Embedding using TFIDF started\")\n",
    "        #X = check_array(X, accept_sparse=False)\n",
    "        if np.array(X).ndim >= 2: \n",
    "            self.n_features_in_ = X.shape[1]\n",
    "            self.n_features_ = X.shape[1]\n",
    "        X = super().fit_transform(X)\n",
    "        self._tf_idf.fit(X)\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        return self\n",
    "            \n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, ['is_fitted_'])\n",
    "\n",
    "        #X = check_array(X, accept_sparse=False)\n",
    "        if np.array(X).ndim >= 2:\n",
    "            if X.shape[1] != self.n_features_:\n",
    "                raise ValueError('Shape of input is different from what was seen in `fit`')\n",
    "\n",
    "\n",
    "        return self.tf_idf.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c2d16",
   "metadata": {},
   "source": [
    "### Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31004261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.co = text.CountVectorizer(stop_words='english')\n",
    "\n",
    "    def fit(self, X, y=None, tf_idf=True):\n",
    "        print(\"Embedding using CountVectorizer started\")\n",
    "        if np.array(X).ndim >= 2: \n",
    "            self.n_features_in_ = X.shape[1]\n",
    "            self.n_features_ = X.shape[1]\n",
    "        X = self.co.fit(X)\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "            \n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, ['is_fitted_'])\n",
    "\n",
    "        #X = check_array(X, accept_sparse=False)\n",
    "        if np.array(X).ndim >= 2:\n",
    "            if X.shape[1] != self.n_features_:\n",
    "                raise ValueError('Shape of input is different from what was seen in `fit`')\n",
    "        return self.co.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d782f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "\n",
    "def time_decorater(function):\n",
    "\n",
    "    @functools.wraps(function)\n",
    "    def time_measurement(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = function(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(\"function: {} finished in {} seconds.\".format(repr(function.__name__), round((end - start), 2)))\n",
    "        return result\n",
    "\n",
    "    return time_measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0166e6",
   "metadata": {},
   "source": [
    "# 2. Model Building <a class=\"anchor\" id=\"modelBuilding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8065eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_DM(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass    \n",
    "                \n",
    "    \n",
    "    def __get_pipeline(self):\n",
    "        \n",
    "            classifier = KNeighborsClassifier(**{\n",
    "                'n_neighbors': 3\n",
    "            })\n",
    "\n",
    "            steps=[\n",
    "                #(\"vect\",  CountVectorizer()),\n",
    "                #(\"tfidf\", TfidfTransformer()),\n",
    "                ('clf', classifier)]\n",
    "\n",
    "            self.pipeline = Pipeline(steps=steps)\n",
    "            return self.pipeline\n",
    "    \n",
    "    \n",
    "    def __get_model(self, feature_range, n_estimators, X, y): \n",
    "        \n",
    "        self.parameters = {\n",
    "                'clf__n_neighbors': n_estimators,                                   \n",
    "                'clf__algorithm': ['ball_tree', 'kd_tree', 'auto'],          \n",
    "                'clf__metric': ['euclidean', 'manhattan']\n",
    "        }\n",
    "        \"\"\"self.parameters = {\n",
    "                'clf__n_neighbors': n_estimators.\n",
    "                'clf__metric': ['l1', 'l2']\n",
    "        }\"\"\"\n",
    "        grid_search = GridSearchCV(**{\n",
    "                'estimator': self.__get_pipeline(),\n",
    "                'cv': 2,\n",
    "                'param_grid': self.parameters,\n",
    "                'scoring': 'f1',#{'F1': 'f1', 'Precision': 'precision', 'Recall':'recall'},\n",
    "                 'refit': True,\n",
    "                'verbose': 5,\n",
    "                 'n_jobs': -1\n",
    "            })\n",
    "        return grid_search\n",
    "    \n",
    "    @time_decorater\n",
    "    def fit(self, X, y, optim):\n",
    "        print(100* '-')\n",
    "        display(HTML(\"<h4>[1/5] Started Fitting...</h4>\"))\n",
    "        if y is None:\n",
    "                raise ValueError('requires y to be passed, but the target y is None')\n",
    "        \n",
    "        X, y = check_X_y(X, y)\n",
    "        self.is_fitted_ = True\n",
    "        if optim:\n",
    "            self.model_ = self.__get_model(feature_range=None, n_estimators =[3,5,10], X =X, y=y) #np.arange(1, 21)\n",
    "            print(\"Performing grid search...\")\n",
    "            print(\"pipeline:\", [name for name, _ in self.pipeline.steps])\n",
    "            print(\"parameters:\")\n",
    "            pprint(self.parameters)\n",
    "            #t0 = time()\n",
    "            self.model_.fit(X, y)\n",
    "            #print(\"done in %0.3fs\" % (time() - t0))\n",
    "            print(\"Done\")\n",
    "            print()\n",
    "\n",
    "            print(\"Best score: %0.3f\" % self.model_.best_score_)\n",
    "            print(\"Best parameters set:\")\n",
    "            best_parameters = self.model_.best_estimator_.get_params()\n",
    "            for param_name in sorted(self.parameters.keys()):\n",
    "                print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        else:\n",
    "            # if not opt true, create knn with default 3 neigh.\n",
    "            self.model_  = KNeighborsClassifier(**{\n",
    "                    'n_neighbors': 3\n",
    "                })\n",
    "\n",
    "            self.model_ .fit(X, y)\n",
    "        print()\n",
    "        return self\n",
    "            \n",
    "    @time_decorater        \n",
    "    def predict(self, X, y=None):\n",
    "        print(100* '-')\n",
    "        display(HTML(\"<h4>[2/5] Started Prediction...</h4>\"))\n",
    "        self.y_test = y\n",
    "        #check_is_fitted(self, ['is_fitted_', 'model_'])\n",
    "        X = check_array(X)\n",
    "        self.y_pred = self.model_.predict(X)\n",
    "        print(\"head of y_pred is \\t%s: \" % (self.y_pred[0:6]))\n",
    "        print()\n",
    "        return self.y_pred #self.model_.predict(X)\n",
    "    \n",
    "    @time_decorater\n",
    "    def predict_proba(self, X, y=None):\n",
    "        print(100* '-')\n",
    "        display(HTML(\"<h4>Started Predicting Model confidence...</h4>\"))\n",
    "        print()\n",
    "        return self.model_ .predict_propa(X, y)\n",
    "     \n",
    "    @time_decorater\n",
    "    def evaluate(self, title = \"KNN Classifier on Test Set\"):\n",
    "        print(100* '-')\n",
    "        display(HTML(\"<h4>[3/5] Started Evaluation...</h4>\"))\n",
    "     \n",
    "        f1 = f1_score(self.y_test, self.y_pred)\n",
    "        accuracy = accuracy_score(self.y_test, self.y_pred)*100\n",
    "        recall = recall_score(self.y_test, self.y_pred)\n",
    "        precision = precision_score(self.y_test, self.y_pred)\n",
    "        \n",
    "        #scores\n",
    "        print(\"f1-score         \\t%s: \" % (f1))\n",
    "        print(\"accuracy-score   \\t%s: \" % (accuracy))\n",
    "        print(\"precision-score  \\t%s: \" % (precision))\n",
    "        print(\"recall-score     \\t%s: \" % (recall))\n",
    "        print()\n",
    "        self.report = self.print_report(self.y_test, self.y_pred)\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "        self.__plot_confusion_matrix(cm, unique_labels(self.y_test),  title = title) #classes = np.unique(y_train),\n",
    "        \n",
    "        return self.report, accuracy, recall, precision, f1\n",
    "    \n",
    "    @staticmethod\n",
    "    @time_decorater  \n",
    "    def print_report(y_test, y_pred):\n",
    "        print(100* '-')\n",
    "        display(HTML(\"<h4>[4/5] Started creating a report...</h4>\"))\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report = pd.DataFrame(report).transpose()\n",
    "        display(report)\n",
    "        print()\n",
    "        return report\n",
    "        \n",
    "    @staticmethod   \n",
    "    @time_decorater   \n",
    "    def __plot_confusion_matrix(cm, classes,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        print(100* '-')\n",
    "        display(HTML(\"<h4>[5/5] Started plotting the confusion matrix...</h4>\"))\n",
    "        print(\"Start plotting the confusion matrix...\\n\")\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c66c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.array(X_train)\n",
    "#knn = KNeighborsClassifier()\n",
    "#print(knn.get_params().keys())\n",
    "#check_estimator(KNN_DM())\n",
    "#knn = KNN_DM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986df23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30405</th>\n",
       "      <td>0</td>\n",
       "      <td>[everyon, free, your, exam, mode, wtf, badtim,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27807</th>\n",
       "      <td>0</td>\n",
       "      <td>[jacksonvil, rooster, simul, want, climb, vast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8660</th>\n",
       "      <td>0</td>\n",
       "      <td>[user, run, 10km, user, user, loveisal, pour, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19185</th>\n",
       "      <td>0</td>\n",
       "      <td>[user, got, prototyp, new, usb, today, think, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>0</td>\n",
       "      <td>[amp, healthi, fathersday, runnerdad, eathealt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       preprocessed\n",
       "30405      0  [everyon, free, your, exam, mode, wtf, badtim,...\n",
       "27807      0  [jacksonvil, rooster, simul, want, climb, vast...\n",
       "8660       0  [user, run, 10km, user, user, loveisal, pour, ...\n",
       "19185      0  [user, got, prototyp, new, usb, today, think, ...\n",
       "10355      0  [amp, healthi, fathersday, runnerdad, eathealt..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f2c5a05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ord() expected a character, but string of length 7 found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# prepare data \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memojis_to_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m  \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrem_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_stem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_lem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_emojis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\uni-Mannheim\\Data_Mining_I\\Data_mining\\src\\data\\preprocessing.py:52\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(data, rem_stop, do_stem, do_lem, do_emojis)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m do_emojis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         tweet \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_emoji\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenization(remove_punctuation(tweet))\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rem_stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\uni-Mannheim\\Data_Mining_I\\Data_mining\\src\\data\\preprocessing.py:126\u001b[0m, in \u001b[0;36mconvert_emoji\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_emoji\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# convert string to binary representation\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     binary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# convert binary representation to utf8 representation\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     listRes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(binary\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\Documents\\uni-Mannheim\\Data_Mining_I\\Data_mining\\src\\data\\preprocessing.py:126\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_emoji\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# convert string to binary representation\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     binary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mformat\u001b[39m(\u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m text)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# convert binary representation to utf8 representation\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     listRes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(binary\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: ord() expected a character, but string of length 7 found"
     ]
    }
   ],
   "source": [
    "# prepare data \n",
    "data['emojis_to_text'] =  preprocess(df_train['preprocessed'], rem_stop=False, do_stem=False, do_lem=False, do_emojis=True)\n",
    "#data['tokenized'] = preprocess(df_train['emojis_to_text'], rem_stop=False, do_stem=False, do_lem=False, do_emojis=False)  \n",
    "#data['removed_stopwords'] = preprocess(df_train['tokenized'], rem_stop=True, do_stem=False, do_lem=False, do_emojis=False)  \n",
    "#data['stemmed_words'] = preprocess(df_train['removed_stopwords'], rem_stop=False, do_stem=True, do_lem=False, do_emojis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd724458",
   "metadata": {},
   "source": [
    "# 3. Training & Evaluation  <a class=\"anchor\" id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f47a5",
   "metadata": {},
   "source": [
    "### try differnt steps to find the best ones to choosse\n",
    "accroding to previous tries, removing the emoji have a positive effect to the accuracy\n",
    "so, this step will not be perfromed. \n",
    "follows the steps will be performed:\n",
    "\n",
    "1- tokenization\n",
    "\n",
    "2- stopwords removal\n",
    "\n",
    "3- stemming \n",
    "\n",
    "4- upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c1417f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c38a0",
   "metadata": {},
   "source": [
    "# 1. With only Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aae4336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature selection\n",
      "Select X as label & y as tweet\n"
     ]
    }
   ],
   "source": [
    "# Only tokenization \n",
    "df[['tweet', 'label']] = data[['tokenized', 'label']]\n",
    "X, y = db.target_feature_selection(df)\n",
    "# Splitting of data into training and test data\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5834c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_idf(X_train, X_test):\n",
    "    count_vect = CountVectorizer(stop_words='english')\n",
    "    transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "    xd = pd.Series(X_train)\n",
    "    text = xd.map(' '.join)\n",
    "    X_train_counts = count_vect.fit_transform(text)\n",
    "    X_train = transformer.fit_transform(X_train_counts)\n",
    "    print(X_train_counts.shape)\n",
    "    print(X_train.shape)\n",
    "    text = X_test.map(' '.join)\n",
    "    X_test_counts = count_vect.transform(text)\n",
    "    X_test = transformer.transform(X_test_counts)\n",
    "    print(X_test_counts.shape)\n",
    "    print(X_test.shape)\n",
    "    return X_train, X_test, X_train_counts, X_test_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6c85c",
   "metadata": {},
   "source": [
    "## 1.1. Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60c711b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 34768)\n",
      "(25569, 34768)\n",
      "(6393, 34768)\n",
      "(6393, 34768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25569x34768 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 203529 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, X_train_c, X_test_c = convert_to_tf_idf(X_train, X_test); X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965ec7e",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e607d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 3.71 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0 0 0 0 0 0]: \n",
      "\n",
      "function: 'predict' finished in 48.75 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.3202979515828678: \n",
      "accuracy-score   \t94.29063037697482: \n",
      "precision-score  \t0.9662921348314607: \n",
      "recall-score     \t0.19196428571428573: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.942576</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.970202</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.320298</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.942906</td>\n",
       "      <td>0.942906</td>\n",
       "      <td>0.942906</td>\n",
       "      <td>0.942906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.954434</td>\n",
       "      <td>0.595730</td>\n",
       "      <td>0.645250</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.944238</td>\n",
       "      <td>0.942906</td>\n",
       "      <td>0.924659</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.942576  0.999495  0.970202  5945.000000\n",
       "1              0.966292  0.191964  0.320298   448.000000\n",
       "accuracy       0.942906  0.942906  0.942906     0.942906\n",
       "macro avg      0.954434  0.595730  0.645250  6393.000000\n",
       "weighted avg   0.944238  0.942906  0.924659  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.01 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.08 seconds.\n",
      "function: 'evaluate' finished in 0.1 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "\"\"\"results_a.append({\n",
    "                'activation function__'+str(i): fct_names[idx],\n",
    "                \"layers\": com['layers'][i],\n",
    "                \"training error\": training_error,\n",
    "                \"test error\": test_error\n",
    "            })\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6caf33",
   "metadata": {},
   "source": [
    "## 1.2 Using Count-Vectroizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaba21e",
   "metadata": {},
   "source": [
    " ### classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3945833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 0.0 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0 0 0 0 0 0]: \n",
      "\n",
      "function: 'predict' finished in 56.66 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.3623445825932504: \n",
      "accuracy-score   \t94.38448302831222: \n",
      "precision-score  \t0.8869565217391304: \n",
      "recall-score     \t0.22767857142857142: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944887</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0.970629</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.227679</td>\n",
       "      <td>0.362345</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.943845</td>\n",
       "      <td>0.943845</td>\n",
       "      <td>0.943845</td>\n",
       "      <td>0.943845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.915922</td>\n",
       "      <td>0.612746</td>\n",
       "      <td>0.666487</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.940827</td>\n",
       "      <td>0.943845</td>\n",
       "      <td>0.928003</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.944887  0.997813  0.970629  5945.000000\n",
       "1              0.886957  0.227679  0.362345   448.000000\n",
       "accuracy       0.943845  0.943845  0.943845     0.943845\n",
       "macro avg      0.915922  0.612746  0.666487  6393.000000\n",
       "weighted avg   0.940827  0.943845  0.928003  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.04 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.09 seconds.\n",
      "function: 'evaluate' finished in 0.17 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train_c.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test_c.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce6082",
   "metadata": {},
   "source": [
    "# 2 with only Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only tokenization \n",
    "df[['tweet', 'label']] = data[['remove_stopwords', 'label']]\n",
    "X, y = db.target_feature_selection(df)\n",
    "# Splitting of data into training and test data\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c0184",
   "metadata": {},
   "source": [
    "### vectorize with tfidf countvectorizer\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56779044",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_train_c, X_test_c = convert_to_tf_idf(X_train, X_test); X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebf719",
   "metadata": {},
   "source": [
    "## 2.1 Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777aa640",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1446c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f3c6b0",
   "metadata": {},
   "source": [
    "## 2.2 Using Count-Vectroizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3bcc68",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3714c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 0.0 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0 0 0 0 0 0]: \n",
      "\n",
      "function: 'predict' finished in 62.61 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.36332179930795844: \n",
      "accuracy-score   \t94.24370405130612: \n",
      "precision-score  \t0.8076923076923077: \n",
      "recall-score     \t0.234375: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945234</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.969856</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.363322</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.942437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.876463</td>\n",
       "      <td>0.615085</td>\n",
       "      <td>0.666589</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.935595</td>\n",
       "      <td>0.942437</td>\n",
       "      <td>0.927352</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.945234  0.995795  0.969856  5945.000000\n",
       "1              0.807692  0.234375  0.363322   448.000000\n",
       "accuracy       0.942437  0.942437  0.942437     0.942437\n",
       "macro avg      0.876463  0.615085  0.666589  6393.000000\n",
       "weighted avg   0.935595  0.942437  0.927352  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.04 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.1 seconds.\n",
      "function: 'evaluate' finished in 0.19 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEYCAYAAADGepQzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjU0lEQVR4nO3deZwU1bnG8d/DIqKIuCCiorgjbkBU3EMgKrgE4zWuMahE1MjVxJhcTW7ibky8UWOUuF9x1ywqLokSd1wBRRNRr7gFkEU2BdxY3vtHnSHtMNPTY09PT/c8Xz/1mapTp6re7nFeTtWpOqWIwMystWtT7gDMzFoCJ0MzM5wMzcwAJ0MzM8DJ0MwMcDI0MwOcDFs8ST0lhaR2Jdr/zyRdn7P8bUlTJS2S1FfSa5IGlOLYZi2Jk2EOSe9J+mbO8hGS5kv6ek5SeqjWNrdKOifND0h1RtWqM07SsXmOu5WkP0qaI+kjSa9KOl1S26b9hCuLiIsi4vs5Rf8DjIyIThHxckRsGxFPlDqOxpB0dUrWiyR9IWlJzvJfv8L+jpU0roE620p6RNI8SQskTZS0f4H7/9L/V9YyORnWQ9Iw4CrggIh4MmdVf0m759l0MXCMpJ4FHmdz4AVgKrB9RKwJfAfYCVjjq8RepE2A14rdSalasgARcVJK1p2Ai4C7apYjYkiJDns/MBZYH1gPOBX4uETHsjJwMqyDpBOB3wL7RcSztVb/Brgwz+YLgJuAsws83LnAsxFxekTMAIiINyPiqIhYUEdsx0l6XdJCSe+kWGvWrSvpgdRymSfpaUlt0rr/kjQ9bfempEGp/JzUuu0gaRHQFnhF0ttp/YpWjaQ2ks6U9LakuZLulrR2WlfTch4u6V/AY3V9WEknSJqS4hsjaYOcdSHpJElvpc9wlSQV+D3W7GNXSc+m7V/JPcVPLcB30nfwrqSjJW0DXA3sllqWdX3n6wKbAtdFxBdpeiYixuXUOVDSpHTcZyXtkMpvATYG7k/7/2ljPo81o4jwlCbgPeDPwCxgx1rregJB1lqbDnwzld8KnJPmBwDTyFoPHwNbp/JxwLH1HHMmcFyemGqO2y4tHwBsDgj4OvAJ0C+t+xXZH3b7NO2V6m1N1vLcIGefm6f5c4Bbc44XwBa1vpOaz3oa8DywEdABuAa4o1acNwOrAx3r+CwDgTlAv7T974Gnah37AaALWQL5EBjcwO9sRfzAhsBcYH+yf+j3SctdU0y5v5PuwLZp/lhgXJ5jCHgrxXYw0K3W+r7AbKA/2T8mw9L31qH2d+ip5U5uGa5sH7I/+H/Us/5TspbhBfXtICJmkiWl8wo43jrAjEKDi4gHI+LtyDwJPEKW9ACWkP2RbxIRSyLi6cj+GpeRJZ/ektpHxHsR8Xahx8xxEvDziJgWEZ+TJaJDa50SnxMRiyPi0zq2Pxq4MSJeStufRdYi65lT5+KIWBAR/wIeB/o0Ir7vAg9FxEMRsTwixgITyJIjwHJgO0kdI2JGRBR0OSB9h98gS2q/BWZIekrSlqnKCOCaiHghIpZFxGjgc2DXRsRuZeZkuLKTga2A6/Ocol0PdJN0UJ79/BrYT9KODRxvLlkCK4ikIZKer7mQT/aHvm5afQkwBXgknQ6eCRARU4AfkiWv2ZLuzD09bYRNgHvSqeAC4HWyRNstp87UPNtvALxfsxARi8g+/4Y5dWbmzH8CdGpkfN+piS/FuCfQPSIWA4eTJfQZkh6U1KvQHad/AEZGxObpOIvJWsE1x/1xreP2SJ/XKoST4cpmAYPIWluj6qoQEV+QXes7n+wUqq46c4HLU518/g78RyGBSepAdhr/P2Snal2Ah2piiIiFEfHjiNgM+BZwes21wYi4PSL2JPvDDbJk3VhTgSER0SVnWjUipufUyTcM0gfp+DWfZ3WylvH0erdofHy31Ipv9Yi4GCAiHo6Ifcj+8XkDuK6AmFcSEVPJOte2yznuhbWOu1pE3PFV9m/l4WRYh4j4gCwhDpZ0WT3VbgFWBQbn2dWlwO7ANnnqnA3sLukSSesDSNoidWp0qVV3FbLT3Q+BpZKGAPvWrEwX8bdILdqPyFptyyVtLWlgSqafkZ3qL88TU32uBi6UtEk6XldJQxux/R3AcZL6pFguAl6IiPe+Qix1uRU4SNJ+ktpKWlXZ7U4bSeomaWhKwJ8Di/j3dzAL2EjSKnXtVNJaks5N322b1KFyPNnlFMiS6kmS+iuzuqQDJK2Rs//NmugzWok4GdYjXbMaSHZN7Fd1rF8G/BJYO88+Pibrfc5X521gN7IOiNckfUTW+psALKxVdyHZLR13A/OBo4AxOVW2JGtpLgKeA0ZFxONkCfRiss6LmWS3hpxV74ev3+/S8R6RtJAsGfQvdOOI+DvwC7LPN4OsI+iIrxBHffufCgwFfkb2D8ZU4Cdk/5+3AU4na53OI+t8Ojlt+hjZ7UQzJc2pY9dfkP1+/k7WCfNPsoR6bDruBOAE4Eqy38uUmnXJr4D/TqfQZzTFZ7Wmp+zasJlZ6+aWoZkZToZmZoCToZkZ4GRoZgZAyR6m/yrUrmNolXKMTWBfVd9tNi53CNYI77//HnPmzGnU894Nadt5k4ildT1wtLL49MOHIyLf7Whl07KS4Spr0GHrw8odhjXCMy9cWe4QrBH26L9Tk+8zln5Gh16F3SH12cu/X7fhWuXRopKhmVUgAY0bXKhFcjI0s+Kp8rsfnAzNrHhuGZqZyS1DMzMEtCn563pKzsnQzIoknyabmQE+TTYzA9wyNDNzB4qZGbgDxcws45ahmVmmja8ZmllrJ9wyNDMD3JtsZuZrhmZmNdybbGatnvw4nplZxqfJZma4ZWhm5g4UM7MabhmaWasnQZvKTyWV/wnMrPzcMjQzw9cMzcwAtwzNzLKbrt0yNDNDbZwMzayVEyCfJptZq6c0VbjKb9uaWZkJqbCpoL1J70n6h6RJkiaksrUljZX0Vvq5ViqXpCskTZH0qqR+OfsZluq/JWlYQ8d1MjSzojVlMky+ERF9ImKntHwm8GhEbAk8mpYBhgBbpmkE8IcUz9rA2UB/YBfg7JoEWh8nQzMrWgmSYW1DgdFpfjRwcE75zZF5HugiqTuwHzA2IuZFxHxgLDA43wGcDM2sOAK1UUETsK6kCTnTiDr2GMAjkibmrO8WETPS/EygW5rfEJias+20VFZfeb3cgWJmRRGNavXNyTn1rc+eETFd0nrAWElv5K6MiJAUXyXWfNwyNLOiNeVpckRMTz9nA/eQXfOblU5/ST9np+rTgR45m2+Uyuorr5eToZkVramSoaTVJa1RMw/sC/wTGAPU9AgPA+5L82OA76Ve5V2Bj9Lp9MPAvpLWSh0n+6ayevk02cyK1oQ3XXcD7kn7awfcHhF/kzQeuFvScOB94LBU/yFgf2AK8AlwHEBEzJN0PjA+1TsvIublO7CToZkVpwlvuo6Id4Ad6yifCwyqozyAU+rZ143AjYUe28nQzIoiRBs/m2xm5meTzcwylZ8LnQzNrEhyy9DMDHAyNDNzB4qZ2QqV3zB0MjSzIvmaYev2xoPnsnDx5yxbvpyly5az59G/YfutNuT3Pz+C1Tt24P0P5nLcz0ezcPFnDOzfi/NP/RartG/HF0uW8rPL7+XJ8f8HQN9tenDtucfQsUN7Hn7mNX78mz+V+ZO1LlOnTuX7x32P2bNnIYnjh49g5KmnccF553DjDdfRdd2uAJx7wUUMHrJ/eYNtwZwMW7nBI37H3AWLVyz/4ZdHceZl9zBu4hS+N3RXfjRsEOeNepC5CxZx6A+vYcaHH9F78+7cP+oUNt/vvwG44meHc8r5t/PiP97j3itPZt89evPIM5PL9ZFanXbt2nHxb35L3379WLhwIbv3/xqDvrkPAP952o/40elnlDnCylANybDyr3q2IFtsvB7jJk4B4LHn3+DgQX0AeOXNacz48CMAJr89g1U7tGeV9u1Yf93OrLH6qrz4j/cAuP2BFzlowA7lCL3V6t69O337ZSPFr7HGGvTqtQ0ffJB3cBOriwqcWjAnw68oIrh/1Eieue2nHH/IHgC8/s6MFcnskH36sVG3lUcZ//Y3+zDpjal8sWQpG6zXhemzF6xYN33WAjZYr0tzhG91eP+995g06WV23qU/AFePupKd++7Aid8/nvnz55c5upZLynqTC5laspJGJ2mwpDfTy1rObHiLyjHouMvY/ahfc/DIUZx4+F7s0W9zTjznNkYcthfP3PZTOq3WgS+WLPvSNttstj4XnDqUkRfcWaaorT6LFi3iyMP+g0t+ezmdO3fmhBNPZvKbb/PCxEms3707Z/7kx+UOsUVrhmH/S65k1wwltQWuAvYhG3J7vKQxEVEVF8Q+SKe9H85fxJjHXmXnbXty+S2PctAPrgKyU+Yhe227ov6G63XhrktH8P1f3MK70+Zk+5i9gA1zWoIbduvCBzktRWseS5Ys4cjD/oPDjzyag799CADdunVbsf744SdwyMEHliu8itDSE10hStky3AWYEhHvRMQXwJ1kL2+peKutugqdVuuwYv6bu/Xitbc/oOtanYDsf4wzT9iP6/40DoA1O3XkL78/iV9ccR/PvfLOiv3MnPMxCxd/xi7b9wTgqAN34YEnX23eD9PKRQQnnTCcrXttw2k/On1F+YwZM1bM33fvPfTedrtyhFc5quCaYSl7k+t6IUv/2pXSC1+yl76071TCcJrOeuuswV2XngBAu7ZtueuvExj77OuccuQATjx8bwDue2wSN9/3PAAnHbE3m/foylkjhnDWiCEAHHTylXw4fxGn/epurj33u3Ts0J5HnpnMw+OqouFcMZ595hluv+0Wtttue/p/rQ+Q3UZz95138Oork5DEJj178vtR15Q30BauGlqGysZGLMGOpUOBwRHx/bR8DNA/IkbWt02b1daLDlsfVt9qa4Hmj7+y3CFYI+zRfycmTpzQpJmrw/pbxkZHX1FQ3Xcu3X9iAS+EKotStgwb/UIWM6s82bPJld8yLOU1w/HAlpI2lbQKcATZy1vMrMpIhU0tWclahhGxVNJIsjdStQVujIjXSnU8MyufarhmWNLH8SLiIbK3V5lZtaqAVl8h/GyymRVFUBXXDJ0MzaxobhmamcktQzOz7OGSKmgaOhmaWZFa/iAMhXAyNLOiVUEudDI0s+JVQ8uwZY+2aGYtnlIHSiFTYftTW0kvS3ogLW8q6YU0Lupd6Yk2JHVIy1PS+p45+zgrlb8pab9CjutkaGZFa+LH8U4DXs9Z/jVwWURsAcwHhqfy4cD8VH5Zqoek3mSP/24LDAZGpfFV83IyNLOiNdVI15I2Ag4Ark/LAgYCNa+NHA0cnOaHpmXS+kGp/lDgzoj4PCLeBaaQja+al5OhmRWtES3DdSVNyJlG1NrV5cBPgeVpeR1gQUQsTcvTyMZKhZwxU9P6j1L9usZS3ZAGuAPFzIrTuJfIz6lvPENJBwKzI2KipAFNFF3BnAzNrCjZTddNsqs9gG9J2h9YFegM/A7oIqldav3ljotaM2bqNEntgDWBuXzFsVR9mmxmRSqsJ7mh3uSIOCsiNoqInmQdII9FxNHA48Chqdow4L40PyYtk9Y/FtnQ/WOAI1Jv86bAlsCLDX0KtwzNrGglvs/wv4A7JV0AvAzckMpvAG6RNAWYR5ZAiYjXJN0NTAaWAqdExLKVd/tlToZmVpwSjGcYEU8AT6T5d6ijNzgiPgO+U8/2FwIXNuaYToZmVhQP1GBmljgZmpnhgRrMzDy4q5kZZO9N9mmymRk+TTYzA6BNFWRDJ0MzK1oV5EInQzMrjgRt3YFiZlbl9xlK+j0Q9a2PiFNLEpGZVZwqyIV5W4YTmi0KM6tYIru9ptLVmwwjYnTusqTVIuKT0odkZpWmCi4ZNjyeoaTdJE0G3kjLO0oaVfLIzKwyFPj+k5Z+XbGQwV0vB/YjG0GWiHgF2LuEMZlZBRFZb3IhU0tWUG9yREytldUbHCjRzFqPFt7oK0ghyXCqpN2BkNSeld9pamatXEs/BS5EIafJJwGnkL1q7wOgT1o2Myv4NaEtPV822DKMiDnA0c0Qi5lVqGp4NrmQ3uTNJN0v6UNJsyXdJ2mz5gjOzCqDCpxaskJOk28H7ga6AxsAfwTuKGVQZlY5qqU3uZBkuFpE3BIRS9N0K9kLns3MquY+w3zPJq+dZv8q6UzgTrJnlQ8HHmqG2MysQrTwPFeQfB0oE8mSX83HPDFnXQBnlSooM6ssLb3VV4h8zyZv2pyBmFllEtXxbHJBT6BI2g7oTc61woi4uVRBmVllqeqWYQ1JZwMDyJLhQ8AQYBzgZGhm2UjXVZAMC+lNPhQYBMyMiOOAHYE1SxqVmVWUangCpZBk+GlELAeWSuoMzAZ6lDYsM6skTXVrjaRVJb0o6RVJr0k6N5VvKukFSVMk3SVplVTeIS1PSet75uzrrFT+pqT9Gjp2IclwgqQuwHVkPcwvAc8VsJ2ZtRJN2DL8HBgYETuSjYMwWNKuwK+ByyJiC2A+MDzVHw7MT+WXpXpI6g0cAWwLDAZGSWqb78ANJsOI+EFELIiIq4F9gGHpdNnMDCHaqLCpIZFZlBbbpymAgcCfUvlo4OA0PzQtk9YPUtYEHQrcGRGfR8S7wBRgl3zHznfTdb986yLipXw7NrNWQtCm8Htr1pWU+36layPi2i/tLmvBTQS2AK4C3gYWRMTSVGUa2ShapJ9TASJiqaSPgHVS+fM5u83dpk75epN/m2ddTaZuUjv06sGjT1/e1Lu1Elq2vN4XKFoLVKrfViHX25I5EbFTvgoRsQzoky7P3QP0Kia2QuW76fobzRGAmVU2UZr7DCNigaTHgd2ALpLapdbhRsD0VG06WYfuNEntyO50mZtTXiN3mzo1IqGbmdWtjQqbGiKpa2oRIqkjWT/F68DjZLf5AQwD7kvzY9Iyaf1jERGp/IjU27wpsCXwYr5jF/QEiplZPk34OF53YHS6btgGuDsiHkhv6LxT0gXAy8ANqf4NwC2SpgDzyHqQiYjXJN0NTAaWAqek0+96ORmaWVGy22aaJhtGxKtA3zrK36GO3uCI+Az4Tj37uhC4sNBjFzLStSR9V9Iv0/LGkvJ2UZtZ69K2TWFTS1ZIeKPILmAemZYXknV3m5mlUWua5j7DcirkNLl/RPST9DJARMyveRTGzAyqoye2kGS4JF3MDMh6e4DlJY3KzCpKC2/0FaSQZHgF2Y2P60m6kKz7+r9LGpWZVQxVwClwIQp5b/JtkiaSDeMl4OCIeL3kkZlZxaiCXFjQ4K4bA58A9+eWRcS/ShmYmVUGAe2qYNz/Qk6TH+TfL4ZaFdgUeJNsaBwzs9bRMoyI7XOX02g2PyhZRGZWWQp81K6la/QTKBHxkqT+pQjGzCqTqPxsWMg1w9NzFtsA/YAPShaRmVWU1vSq0DVy5peSXUP8c2nCMbNK1LYKsmHeZJhutl4jIs5opnjMrMJUfcuwZiBFSXs0Z0BmVmEq4DWghcjXMnyR7PrgJEljgD8Ci2tWRsRfShybmVWIVvEECtm9hXPJ3nlSc79hAE6GZlb9p8lkzyKfDvyTfyfBGn4LkJmtUAUNw7zJsC3QCeq8gcjJ0MyA7B7DtlWQDfMlwxkRcV6zRWJmlakVPIFSBR/PzJpDtXegDGq2KMysYmXvTS53FMXL9xL5ec0ZiJlVrmpvGZqZFaQKcqGToZkVR6Lqe5PNzApS+anQydDMilTz3uRK52RoZkWr/FToZGhmTaAKGoa0KXcAZlbZah7HK2RqcF9SD0mPS5os6TVJp6XytSWNlfRW+rlWKpekKyRNkfRqekdTzb6GpfpvSRrW0LGdDM2saJIKmgqwFPhxRPQGdgVOkdQbOBN4NCK2BB5NywBDgC3TNAL4Q4pnbeBsoD+wC3B2TQKtj5OhmRVNBU4NiYgZEfFSml8IvA5sCAwFRqdqo4GD0/xQ4ObIPA90kdQd2A8YGxHzImI+MBYYnO/YvmZoZsURhbb6ANaVNCFn+dqIuLbO3Uo9gb7AC0C3iJiRVs0EuqX5DYGpOZtNS2X1ldfLydDMiiIadYo5JyJ2anCfUieyF8/9MCI+zk22ERGSmnwYQZ8mm1nRmvCaIZLakyXC23JeLzIrnf6Sfs5O5dOBHjmbb5TK6iuvl5OhmRWtjQqbGqIsY94AvB4Rl+asGgPU9AgPA+7LKf9e6lXeFfgonU4/DOwraa3UcbJvKquXT5PNrCjZaXKT3Wi4B3AM8A9Jk1LZz4CLgbslDQfeBw5L6x4C9gemAJ8Ax0E26pak84Hxqd55DY3E5WRoZkVrqpuuI2Ic9Xc8rzTGakQEcEo9+7oRuLHQYzsZmlmRhKrggTwnQzMrWjU8judkaGZFaeJrhmXjZGhmxRG0qYL7UpwMzaxovmZoZq1eNrhruaMoXhU0bsvrs88+Y5+v78bXd+3HHjvtyMUXnPul9Wed8UM26dZlxfL/Xn8Ne+3ShwG7fY0D9vk6b74+uZkjNoCTRxxPz426sXPf7VeUzZs3j4OG7MuOvbfioCH7Mn/+fACeevIJNujahd127stuO/flVxeeV66wWywV+F9L5mRYpA4dOnDPg2N58vmXeOK5CTz294eZ8OLzALz80gQWLJj/pfqHHnYkT784iSeem8jIH57BL876STnCbvWOPuZY7r3/r18qu/SSixkwcCCvTP4/BgwcyKWXXLxi3e577MVz41/mufEvc9bPf9nc4bZ4UmFTS+ZkWCRJdOrUCYAlS5awZMkSJLFs2TLO+fmZnH3BxV+qv0bnzivmP1m8uDGjfVgT2nOvvVlrrbW/VPbg/WM4+rvZE19Hf3cYD4y5r65NrQ7V0DL0NcMmsGzZMgbtuQvvvvM2x484ma/t3J9rrrqCwQccyPrrd1+p/g3XjOIPV/6OL774gnsefKQMEVtdZs+exfrds99Xt/XXZ/bsWSvWvfjCc+y6Ux+6d9+AC399Cb17b1uuMFucmpGuK13JWoaSbpQ0W9I/S3WMlqJt27Y88dxEXn3zPV6aMJ5nxz3NmHv/zAknjayz/vATf8CEf7zJL8+/iEt/c1EzR2uFyB1lpU/ffkx+6z2enzCJk34wkiMP/XaZo2thCjxFbun5spSnyTfRwMiy1WbNLl3Yc+8BjHvqCd59+2123qEXfXtvwSeffMLOO/Raqf4hhx7OQw+MKUOkVpf11uvGzBnZ+KEzZ8yga9f1AOjcufOKSyH7DdmfJUuXMGfOnLLF2RI11UjX5VSyZBgRTwF5R4moBnM+/JCPFiwA4NNPP+XJx/7Ojn37Mfmdabw8eQovT57CaqutxvhX3wDg7Slvrdj2kb89xGabb1GOsK0O+x94ELfdmo0sf9utozngoG8BMGvmTLLxAGDC+BdZvnw566yzTtnibGlq3ptcyNSSlf2aoaQRZC9yYaMeG5c5msabNWsGI0ccz7Jly1i+PBh6yKHsN+SAeuvfcM0onnz8Mdq3b8eaXdbiqmsKHlTDmtCxxxzF0089wdw5c9hqsx78/BfncPpPzuR7Rx3Ozf97Iz023oSbb78LgHv+8ieuv/Zq2rVrR8eOHbnpljvc8VVLNXwbqvkXryQ7z95h8EBEbFdI/T79vhaPPv1CyeKxprdq+7blDsEaYa/ddualiROaNHdts33fuOneJwqqu+sWXSYWMux/OZS9ZWhmla8aGspOhmZWtCrIhSW9teYO4Dlga0nT0nDdZlaNqqA7uWQtw4g4slT7NrOWI8tzLTzTFcCnyWZWnAq4oboQToZmVjQnQzOzChiEoRBOhmZWNLcMzazVq4CO4oI4GZpZ8aogGzoZmlnRfM3QzIzqeCGUk6GZFadKLhr6HShmVrSmegdKXSPkS1pb0lhJb6Wfa6VySbpC0hRJr0rql7PNsFT/LUnDCvkMToZmVhTRpMP+38TKI+SfCTwaEVsCj6ZlgCHAlmkaAfwBsuQJnA30B3YBzq5JoPk4GZpZ0ZpqnIZ6RsgfCoxO86OBg3PKb47M80AXSd2B/YCxETEvIuYDYyngFSS+ZmhmRWvEyN/rSpqQs3xtRFzbwDbdImJGmp8JdEvzGwJTc+pNS2X1leflZGhmRWvEEyhzihnpOiJCUkmG5/dpspkVrcTDGc5Kp7+kn7NT+XSgR069jVJZfeV5ORmaWfFKmw3HADU9wsOA+3LKv5d6lXcFPkqn0w8D+0paK3Wc7JvK8vJpspkVpSkHd00j5A8gu7Y4jaxX+GLg7jRa/vvAYan6Q8D+wBTgE+A4gIiYJ+l8YHyqd15ENPjaYidDMytOEw7ummeE/EF11A3glHr2cyPQqPfwOhmaWdE8hJeZmQd3NTPLuGVoZq1elYzT4GRoZk2gCrKhk6GZFc3XDM3M8OCuZmZ+ibyZ2b9VfjZ0MjSzotQM7lrpnAzNrGhVkAudDM2seG4ZmpnRqJGuWywnQzMrWuWnQidDMytSI95816I5GZpZ0fwEipkZVMV5spOhmRXNj+OZmXlwVzOz6nkCxa8KNTPDLUMzawLV0DJ0MjSzovmaoZm1epJ7k83MMk6GZmY+TTYzA9yBYmYGVMVZspOhmTWBKsiGToZmVhQBbargPFkRUe4YVpD0IfB+ueMogXWBOeUOwhqlWn9nm0RE16bcoaS/kX1fhZgTEYOb8vhNpUUlw2olaUJE7FTuOKxw/p21Pn422cwMJ0MzM8DJsLlcW+4ArNH8O2tlfM3QzAy3DM3MACdDMzPAydDMDHAyLBlJW0vaTVJ7SW3LHY8Vxr+r1ssdKCUg6RDgImB6miYAN0XEx2UNzOolaauI+L803zYilpU7Jmtebhk2MUntgcOB4RExCLgP6AH8l6TOZQ3O6iTpQGCSpNsBImKZW4itj5NhaXQGtkzz9wAPAO2Bo6QqeKK9ikhaHRgJ/BD4QtKt4ITYGjkZNrGIWAJcChwiaa+IWA6MAyYBe5YzNltZRCwGjgduB84AVs1NiOWMzZqXk2FpPA08Ahwjae+IWBYRtwMbADuWNzSrLSI+iIhFETEHOBHoWJMQJfWT1Ku8EVpz8HiGJRARn0m6DQjgrPTH9DnQDZhR1uAsr4iYK+lE4BJJbwBtgW+UOSxrBk6GJRIR8yVdB0wma218Bnw3ImaVNzJrSETMkfQqMATYJyKmlTsmKz3fWtMM0oX4SNcPrYWTtBZwN/DjiHi13PFY83AyNKuDpFUj4rNyx2HNx8nQzAz3JpuZAU6GZmaAk6GZGeBkaGYGOBlWFEnLJE2S9E9Jf5S0WhH7uknSoWn+ekm989QdIGn3r3CM9ySt9D7d+spr1VnUyGOdI+mMxsZoVsPJsLJ8GhF9ImI74AvgpNyVkr7STfQR8f2ImJynygCg0cnQrJI4GVaup4EtUqvtaUljgMmS2kq6RNJ4Sa+mR8tQ5kpJb0r6O7BezY4kPSFppzQ/WNJLkl6R9KiknmRJ90epVbqXpK6S/pyOMV7SHmnbdSQ9Iuk1SdcDDY7QI+leSRPTNiNqrbsslT8qqWsq21zS39I2T/u5YWsqfhyvAqUW4BDgb6moH7BdRLybEspHEbGzpA7AM5IeAfoCWwO9yZ6RngzcWGu/XYHrgL3TvtaOiHmSrgYWRcT/pHq3A5dFxDhJGwMPA9sAZwPjIuI8SQcAwwv4OMenY3QExkv6c0TMBVYHJkTEjyT9Mu17JNkrPE+KiLck9QdGAQO/wtdo9iVOhpWlo6RJaf5p4Aay09cXI+LdVL4vsEPN9UBgTbKxFfcG7kjDUn0g6bE69r8r8FTNviJiXj1xfBPonTM0Y2dJndIxDknbPihpfgGf6VRJ307zPVKsc4HlwF2p/FbgL+kYuwN/zDl2hwKOYdYgJ8PK8mlE9MktSElhcW4R8J8R8XCtevs3YRxtgF1rP67W2HFrJQ0gS6y7RcQnkp4AVq2neqTjLqj9HZg1BV8zrD4PAyen1w8gaas0mvNTwOHpmmJ36h6W6nlgb0mbpm3XTuULgTVy6j0C/GfNgqQ+afYp4KhUNgRYq4FY1wTmp0TYi6xlWqMNUNO6PYrs9Ptj4F1J30nHkCSPD2lNwsmw+lxPdj3wJUn/BK4hOwO4B3grrbsZeK72hhHxITCC7JT0Ff59mno/8O2aDhTgVGCn1EEzmX/3ap9LlkxfIztd/lcDsf4NaCfpdeBismRcYzGwS/oMA4HzUvnRwPAU32vA0AK+E7MGeaAGMzPcMjQzA5wMzcwAJ0MzM8DJ0MwMcDI0MwOcDM3MACdDMzMA/h8kTdCmZEBtlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train_c.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test_c.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35edf07",
   "metadata": {},
   "source": [
    "# 3 with  Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f31b0d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature selection\n",
      "Select X as label & y as tweet\n"
     ]
    }
   ],
   "source": [
    "# Only tokenization \n",
    "df[['tweet', 'label']] = data[['stemmed_words', 'label']]\n",
    "X, y = db.target_feature_selection(df)\n",
    "# Splitting of data into training and test data\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a46fa0",
   "metadata": {},
   "source": [
    "### vectorize with tfidf countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e73da3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 30055)\n",
      "(25569, 30055)\n",
      "(6393, 30055)\n",
      "(6393, 30055)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25569x30055 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 201642 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, X_train_c, X_test_c = convert_to_tf_idf(X_train, X_test); X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de39b5d",
   "metadata": {},
   "source": [
    "## 3.1 Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb678eb9",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd52b9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 3.01 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0 0 0 0 0 0]: \n",
      "\n",
      "function: 'predict' finished in 44.24 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.3171641791044776: \n",
      "accuracy-score   \t94.27498826841858: \n",
      "precision-score  \t0.9659090909090909: \n",
      "recall-score     \t0.18973214285714285: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.942427</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.970122</td>\n",
       "      <td>5945.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.189732</td>\n",
       "      <td>0.317164</td>\n",
       "      <td>448.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.942750</td>\n",
       "      <td>0.942750</td>\n",
       "      <td>0.942750</td>\n",
       "      <td>0.94275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.954168</td>\n",
       "      <td>0.594614</td>\n",
       "      <td>0.643643</td>\n",
       "      <td>6393.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.944072</td>\n",
       "      <td>0.942750</td>\n",
       "      <td>0.924365</td>\n",
       "      <td>6393.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.942427  0.999495  0.970122  5945.00000\n",
       "1              0.965909  0.189732  0.317164   448.00000\n",
       "accuracy       0.942750  0.942750  0.942750     0.94275\n",
       "macro avg      0.954168  0.594614  0.643643  6393.00000\n",
       "weighted avg   0.944072  0.942750  0.924365  6393.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.01 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.05 seconds.\n",
      "function: 'evaluate' finished in 0.07 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387dc58",
   "metadata": {},
   "source": [
    "## 3 .2 Using Count-Vectroizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61c37e",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a78583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 0.0 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0 0 0 0 0 0]: \n",
      "\n",
      "function: 'predict' finished in 47.6 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.3875432525951557: \n",
      "accuracy-score   \t94.46269357109338: \n",
      "precision-score  \t0.8615384615384616: \n",
      "recall-score     \t0.25: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946352</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.971003</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387543</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.944627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.903945</td>\n",
       "      <td>0.623486</td>\n",
       "      <td>0.679273</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.940408</td>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.930116</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.946352  0.996972  0.971003  5945.000000\n",
       "1              0.861538  0.250000  0.387543   448.000000\n",
       "accuracy       0.944627  0.944627  0.944627     0.944627\n",
       "macro avg      0.903945  0.623486  0.679273  6393.000000\n",
       "weighted avg   0.940408  0.944627  0.930116  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.01 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.05 seconds.\n",
      "function: 'evaluate' finished in 0.08 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train_c.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test_c.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4214e5af",
   "metadata": {},
   "source": [
    "# 4 with Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392eacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best results were achieved after the stemming and count_vectorizer therefore this will be upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69b2ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature selection\n",
      "Select X as label & y as tweet\n"
     ]
    }
   ],
   "source": [
    "df[['tweet', 'label']] = data[['stemmed_words', 'label']]\n",
    "X, y = db.target_feature_selection(df)\n",
    "# Splitting of data into training and test data\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 17, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a178aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df['label'] = y_train\n",
    "new_df['tweet'] = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e649721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    23775\n",
       "1.0    23775\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsample train set\n",
    "df = upsampling(new_df)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce5b992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['tweet']\n",
    "y_train = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0a5e2",
   "metadata": {},
   "source": [
    "### vectorize with tfidf countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3181a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 30055)\n",
      "(25569, 30055)\n",
      "(6393, 30055)\n",
      "(6393, 30055)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25569x30055 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 201644 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, X_train_c, X_test_c = convert_to_tf_idf(X_train, X_test); X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a09b74",
   "metadata": {},
   "source": [
    "## 4.1 Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa6ae3",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a69fc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 5.8 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0. 0. 0. 0. 0. 0.]: \n",
      "\n",
      "function: 'predict' finished in 82.4 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.5333333333333333: \n",
      "accuracy-score   \t95.29172532457375: \n",
      "precision-score  \t0.8730964467005076: \n",
      "recall-score     \t0.38392857142857145: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955455</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.975208</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.873096</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.952917</td>\n",
       "      <td>0.952917</td>\n",
       "      <td>0.952917</td>\n",
       "      <td>0.952917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.914276</td>\n",
       "      <td>0.689862</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.949684</td>\n",
       "      <td>0.952917</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.955455  0.995795  0.975208  5945.000000\n",
       "1              0.873096  0.383929  0.533333   448.000000\n",
       "accuracy       0.952917  0.952917  0.952917     0.952917\n",
       "macro avg      0.914276  0.689862  0.754271  6393.000000\n",
       "weighted avg   0.949684  0.952917  0.944243  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.02 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.05 seconds.\n",
      "function: 'evaluate' finished in 0.07 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c23896",
   "metadata": {},
   "source": [
    "## 4 .2 Using Count-Vectroizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12639e94",
   "metadata": {},
   "source": [
    "###  classification, Evaluation & plotting with only tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b10ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 0.0 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0 0 0 0 0 0]: \n",
      "\n",
      "function: 'predict' finished in 64.31 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.3875432525951557: \n",
      "accuracy-score   \t94.46269357109338: \n",
      "precision-score  \t0.8615384615384616: \n",
      "recall-score     \t0.25: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946352</td>\n",
       "      <td>0.996972</td>\n",
       "      <td>0.971003</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.387543</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.944627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.903945</td>\n",
       "      <td>0.623486</td>\n",
       "      <td>0.679273</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.940408</td>\n",
       "      <td>0.944627</td>\n",
       "      <td>0.930116</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.946352  0.996972  0.971003  5945.000000\n",
       "1              0.861538  0.250000  0.387543   448.000000\n",
       "accuracy       0.944627  0.944627  0.944627     0.944627\n",
       "macro avg      0.903945  0.623486  0.679273  6393.000000\n",
       "weighted avg   0.940408  0.944627  0.930116  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.08 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.16 seconds.\n",
      "function: 'evaluate' finished in 0.29 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train_c.toarray(), y_train, optim=False)\n",
    "y_pred = model.predict(X_test_c.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa8d4e",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef1ca944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['clf']\n",
      "parameters:\n",
      "{'clf__algorithm': ['ball_tree', 'kd_tree', 'auto'],\n",
      " 'clf__metric': ['euclidean', 'manhattan'],\n",
      " 'clf__n_neighbors': [3, 5, 10]}\n",
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.86 GiB for an array with shape (12785, 30055) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 673, in _fit_and_score\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 288, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 378, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 202, in _array_indexing\n    return array[key] if axis == 0 else array[:, key]\n  File \"C:\\Users\\D073999\\Miniconda3\\lib\\site-packages\\numpy\\core\\memmap.py\", line 334, in __getitem__\n    res = super().__getitem__(index)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.86 GiB for an array with shape (12785, 30055) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNN_DM()\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mtime_decorater.<locals>.time_measurement\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(function)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_measurement\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      9\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     11\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m finished in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mrepr\u001b[39m(function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mround\u001b[39m((end \u001b[38;5;241m-\u001b[39m start), \u001b[38;5;241m2\u001b[39m)))\n",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36mKNN_DM.fit\u001b[1;34m(self, X, y, optim)\u001b[0m\n\u001b[0;32m     58\u001b[0m pprint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#t0 = time()\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#print(\"done in %0.3fs\" % (time() - t0))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.86 GiB for an array with shape (12785, 30055) and data type int64"
     ]
    }
   ],
   "source": [
    "knn = KNN_DM()\n",
    "model = knn.fit(X_train_c.toarray(), y_train, optim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c459d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "911bf5d4",
   "metadata": {},
   "source": [
    "### Impalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e59f4f",
   "metadata": {},
   "source": [
    "F1-score is very low, \n",
    "try to find tech. that specifically target the f-1 (like ensambles targets  overfitting).\n",
    "the idea is rather to deal with imbalanced classes and not directly the f1-score, but as a result of handling the \n",
    "imbalance state in the right way, the f1-score should also be boosted:\n",
    "\n",
    "1- use Ensembles or balanced-bagging-classifier: this is a rather simple solution and redandant, it is a normal classifier\n",
    "but it will resample the data without having to use a sampler, so the results should be the same as if one resampled and then used another normal classifier\n",
    "\n",
    "2- Resampling like resample from sklearn: already used above\n",
    "\n",
    "3- SMOTE Synthetic Minority Oversampling Technique: oversampling the minor class by creating synthetic examples\n",
    "    form original data and not only deleting or duplicating the examples\n",
    "    \n",
    "4- Threshold moving: most of the learners in sklearn have predict_proba, which give a probabillity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d3a1d62",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.6 GiB for an array with shape (30055, 47550) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# KNeighborsClassifier\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# KNN_DM is just a convient way to reuse the code, it will not work on all cases, because, \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#they are not covered during the impl.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# in this case we use the original classifier\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Create an instance\u001b[39;00m\n\u001b[0;32m      7\u001b[0m classifier \u001b[38;5;241m=\u001b[39m BalancedBaggingClassifier(base_estimator\u001b[38;5;241m=\u001b[39mKNeighborsClassifier(),\n\u001b[0;32m      8\u001b[0m                                 sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot majority\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                 replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m preds \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_test_c)\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py:331\u001b[0m, in \u001b[0;36mBalancedBaggingClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"Build a Bagging ensemble of estimators from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# overwrite the base class method by disallowing `sample_weight`\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:269\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    261\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[0;32m    263\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    268\u001b[0m )\n\u001b[1;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py:346\u001b[0m, in \u001b[0;36mBalancedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler_ \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# RandomUnderSampler is not supporting sample_weight. We need to pass\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# None.\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:394\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    391\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 394\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    412\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    413\u001b[0m )\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:126\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[0;32m    123\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X[:, features], y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m, y[indices])\n\u001b[0;32m    128\u001b[0m estimators\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[0;32m    129\u001b[0m estimators_features\u001b[38;5;241m.\u001b[39mappend(features)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.6 GiB for an array with shape (30055, 47550) and data type int64"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "# KNeighborsClassifier\n",
    "# KNN_DM is just a convient way to reuse the code, it will not work on all cases, because, \n",
    "#they are not covered during the impl.\n",
    "# in this case we use the original classifier\n",
    "#Create an instance\n",
    "classifier = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(),\n",
    "                                sampling_strategy='not majority',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "classifier.fit(X_train_c.toarray(), y_train)\n",
    "preds = classifier.predict(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "10c0daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[1/5] Started Fitting...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'fit' finished in 0.01 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[2/5] Started Prediction...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of y_pred is \t[0. 0. 0. 0. 0. 0.]: \n",
      "\n",
      "function: 'predict' finished in 171.95 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[3/5] Started Evaluation...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score         \t0.5423242467718794: \n",
      "accuracy-score   \t95.01016737056155: \n",
      "precision-score  \t0.7590361445783133: \n",
      "recall-score     \t0.421875: \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[4/5] Started creating a report...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957845</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.973612</td>\n",
       "      <td>5945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.542324</td>\n",
       "      <td>448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.950102</td>\n",
       "      <td>0.950102</td>\n",
       "      <td>0.950102</td>\n",
       "      <td>0.950102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.858441</td>\n",
       "      <td>0.705891</td>\n",
       "      <td>0.757968</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.943913</td>\n",
       "      <td>0.950102</td>\n",
       "      <td>0.943389</td>\n",
       "      <td>6393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.957845  0.989907  0.973612  5945.000000\n",
       "1              0.759036  0.421875  0.542324   448.000000\n",
       "accuracy       0.950102  0.950102  0.950102     0.950102\n",
       "macro avg      0.858441  0.705891  0.757968  6393.000000\n",
       "weighted avg   0.943913  0.950102  0.943389  6393.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function: 'print_report' finished in 0.04 seconds.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>[5/5] Started plotting the confusion matrix...</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start plotting the confusion matrix...\n",
      "\n",
      "function: '__plot_confusion_matrix' finished in 0.1 seconds.\n",
      "function: 'evaluate' finished in 0.18 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X, oversampled_Y = sm.fit_resample(X_train_c, y_train)\n",
    "#oversampled = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)\n",
    "knn = KNN_DM()\n",
    "model = knn.fit(oversampled_X.toarray(), oversampled_Y, optim=False)\n",
    "y_pred = model.predict(X_test_c.toarray(), y_test)\n",
    "report, accuracy, recall, precision, f1 = model.evaluate()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50b367f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving threshold \n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_c.toarray(),y_train)\n",
    "knn.predict_proba(X_test_c.toarray()) #probability of the class label predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c0f1835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2 -- 0.7348490252913613\n",
      "Threshold 0.25 -- 0.6617824852817493\n",
      "Threshold 0.3 -- 0.6617824852817493\n",
      "Threshold 0.35 -- 0.6617824852817493\n",
      "Threshold 0.39999999999999997 -- 0.6617824852817493\n",
      "Threshold 0.44999999999999996 -- 0.590845022828307\n",
      "Threshold 0.49999999999999994 -- 0.590845022828307\n",
      "Threshold 0.5499999999999999 -- 0.590845022828307\n",
      "Threshold 0.6 -- 0.590845022828307\n",
      "Threshold 0.65 -- 0.5667960771356482\n",
      "Threshold 0.7000000000000001 -- 0.5667960771356482\n",
      "Threshold 0.7500000000000001 -- 0.5667960771356482\n",
      "---Optimum Threshold --- 0.2 --ROC-- 0.7348490252913613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "step_factor = 0.05 \n",
    "threshold_value = 0.2 \n",
    "roc_score=0\n",
    "predicted_proba = knn.predict_proba(X_test_c.toarray()) #probability of prediction\n",
    "while threshold_value <=0.8: #continue to check best threshold upto probability 0.8\n",
    "    temp_thresh = threshold_value\n",
    "    predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "    print('Threshold',temp_thresh,'--',roc_auc_score(y_test, predicted))\n",
    "    if roc_score<roc_auc_score(y_test, predicted): #store the threshold for best classification\n",
    "        roc_score = roc_auc_score(y_test, predicted)\n",
    "        thrsh_score = threshold_value\n",
    "    threshold_value = threshold_value + step_factor\n",
    "print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e40d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_c.toarray(),y_train)\n",
    "y_pred = knn.predict(X_test_c.toarray())  # default threshold is 0.5\n",
    "\n",
    "y_pred = (knn.predict_proba(X_test.toarray())[:,1] >= 0.2).astype(bool) # set threshold as 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3cbb676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 after changing the threshold:  0.133422281521014\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred);\n",
    "print(\"f1 after changing the threshold: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "413d67fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\d073999\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting mlens\n",
      "  Downloading https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/packages/packages/0b/f7/c04bda423ac93ddb54bc4c3a21c79c9a24bc83844efc30dc4c11c289e894/mlens-0.2.3-py2.py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlens) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from mlens) (1.21.5)\n",
      "Installing collected packages: mlens\n",
      "Successfully installed mlens-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6113ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "ensemble = SuperLearner(scorer=f1_score, verbose=0)\n",
    "# Build the first layer\n",
    "ensemble.add([KNeighborsClassifier(algorithm='ball_tree', metric='l1', n_neighbors=2), SVC(C=5)])\n",
    "\n",
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(DecisionTreeClassifier())\n",
    "\n",
    "# Fit ensemble\n",
    "ensemble.fit(X_train_c.toarray(),y_train)\n",
    "\n",
    "# Predict\n",
    "preds = ensemble.predict(X_test_c)\n",
    "\n",
    "print(classification_report(y_test,preds))\n",
    "#print(\"Fit data:\\n%r\" % ensemble.data)\n",
    "#print(\"Prediction score: %.3f\" % accuracy_score(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc4cf6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbNGkkX63lx4",
    "outputId": "a65ee0a9-78e0-4285-e9e4-56d15f5ccc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py:504: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='ball_tree', metric='l1', n_neighbors=2)\n",
      "0.5182829888712241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.26044110746129"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#, 'auto'\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [2, 5, 10, 15],                                   \n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'auto'],          \n",
    "    'metric': ['euclidean', 'l1', 'l2', 'manhattan']\n",
    "}\n",
    "\n",
    "kNNModel_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid_knn, verbose=1, cv=10, n_jobs=-1)\n",
    "kNNModel_grid.fit(x_train_tfidf, y_train_balanced)\n",
    "print(kNNModel_grid.best_estimator_)\n",
    "\n",
    "y_pred = kNNModel_grid.predict(x_test_tfidf)\n",
    "\n",
    "print(f1_score(y_test,y_pred))\n",
    "accuracy_score(y_test,y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b62cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eulgAyINEX0r",
    "outputId": "5f92103c-6cc8-4873-8cc0-430ba796517f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan', 'precomputed']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.neighbors.VALID_METRICS_SPARSE['brute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efc117",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI7h2ESYcW9c",
    "outputId": "7afe3743-d617-4cca-a93c-0ecc3bf05362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chebyshev',\n",
       " 'cityblock',\n",
       " 'euclidean',\n",
       " 'infinity',\n",
       " 'l1',\n",
       " 'l2',\n",
       " 'manhattan',\n",
       " 'minkowski',\n",
       " 'p']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.neighbors.VALID_METRICS['kd_tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2d507a69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75ZbAFory4RZ",
    "outputId": "1a906c5e-2e92-4de2-a159-7c783bebbbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://int.repositories.cloud.sap/artifactory/api/pypi/build-releases-pypi/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/build-milestones-pypi/simple\n",
      "Requirement already satisfied: xgboost in c:\\users\\d073999\\miniconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from xgboost) (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\d073999\\miniconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\d073999\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb7b5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "Guh2jx-EzBgm",
    "outputId": "79ad41e4-435f-4924-93b5-9546413396d5"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3f12261bffec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mxgb_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(f1_score(y_test,xgb_preds))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxgb_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# read in data\n",
    "dtrain = xgb.DMatrix(x_train_tfidf, label=y_train_balanced)\n",
    "dtest = xgb.DMatrix(x_test_tfidf, y_test)\n",
    "# specify parameters via map\n",
    "param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# make prediction\n",
    "xgb_preds = bst.predict(dtest)\n",
    "print()\n",
    "#print(f1_score(y_test,xgb_preds))\n",
    "#print(accuracy_score(y_test,xgb_preds)*100)\n",
    "#print(\"Prediction score xgboost: %.3f\" % accuracy_score(y_test, xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7c486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUrko_UAt9z8",
    "outputId": "9d2a7259-47c1-46ec-b8ae-122fe4708663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlens\n",
      "  Downloading mlens-0.2.3-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |█▍                              | 10 kB 22.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 20 kB 29.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 30 kB 22.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 40 kB 8.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 51 kB 8.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 61 kB 10.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 71 kB 9.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 81 kB 9.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 92 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 102 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 112 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 122 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 133 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 143 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 153 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 163 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 174 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 184 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 194 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 204 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 215 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 225 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 227 kB 9.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlens) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from mlens) (1.21.6)\n",
      "Installing collected packages: mlens\n",
      "Successfully installed mlens-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4433346",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "9JetywURsZFY",
    "outputId": "d685000a-0ce0-4e62-c586-7d326f9e529e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-65a27b7b5ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Fit ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_balanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "ensemble = SuperLearner(scorer=f1_score, verbose=0)\n",
    "# Build the first layer\n",
    "ensemble.add([KNeighborsClassifier(algorithm='ball_tree', metric='l1', n_neighbors=2), SVC(C=5)])\n",
    "\n",
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(DecisionTreeClassifier())\n",
    "\n",
    "# Fit ensemble\n",
    "ensemble.fit(x_train_tfidf.toarray(),y_train_balanced)\n",
    "\n",
    "# Predict\n",
    "preds = ensemble.predict(x_test_tfidf)\n",
    "print(\"Fit data:\\n%r\" % ensemble.data)\n",
    "print(\"Prediction score: %.3f\" % accuracy_score(y_test, preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cd4b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VzWYCRgjpXw",
    "outputId": "5e3c57b4-7842-4e13-a30c-f4ca9e545f5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47566, 33166)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_balanced)\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393c1e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIbkSaK_LYJI",
    "outputId": "f3e188f0-ec65-4dce-b8df-c2c784955487"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6676e6",
   "metadata": {
    "id": "1XX6MLOnmf1E"
   },
   "source": [
    "Aaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97526e0d",
   "metadata": {
    "id": "KBIqdozAl2gl"
   },
   "outputs": [],
   "source": [
    "##Aaron\n",
    "X_train = x_train_tfidf\n",
    "y_train = y_train_balanced\n",
    "X_test = x_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e76d0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v90nZ3CSlgU5",
    "outputId": "164a3f9e-822b-471e-988d-47a7502d4667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.1484436101986548, 0.14321687126219704], [2, 0.1484436101986548, 0.14321687126219704], [3, 0.9321132488659472, 0.2359154929577465], [4, 0.23072110120444236, 0.1541107671138631], [5, 0.9164711403097138, 0.28989361702127664], [6, 0.9189738776787111, 0.3272727272727273], [7, 0.923197246988894, 0.37292464878671777], [8, 0.9239793524167058, 0.40586797066014674], [9, 0.9242921945878304, 0.42105263157894735], [10, 0.9253871421867668, 0.4341637010676157], [11, 0.9256999843578915, 0.4431418522860492], [12, 0.9242921945878304, 0.4561797752808988], [13, 0.9258564054434538, 0.4709821428571429], [14, 0.9255435632723291, 0.46993318485523383], [15, 0.9253871421867668, 0.47292817679558014], [16, 0.9244486156733928, 0.4755700325732899], [17, 0.9264820897857031, 0.4812362030905077], [18, 0.9261692476145784, 0.47902869757174393], [19, 0.9266385108712655, 0.48404840484048406], [20, 0.9255435632723291, 0.4870689655172414], [21, 0.9264820897857031, 0.4978632478632478], [22, 0.9272641952135148, 0.507936507936508], [23, 0.9250743000156421, 0.4941921858500528], [24, 0.9253871421867668, 0.4984227129337539], [25, 0.9271077741279524, 0.51255230125523], [26, 0.9263256687001408, 0.5098855359001041], [27, 0.9275770373846395, 0.5211995863495347], [28, 0.9272641952135148, 0.5151199165797706], [29, 0.9297669325825121, 0.5278654048370136], [30, 0.9292976693258251, 0.5291666666666667], [31, 0.9297669325825121, 0.5288562434417629], [32, 0.9308618801814484, 0.5357142857142858], [33, 0.9296105114969498, 0.527310924369748], [34, 0.9322696699515095, 0.5437302423603793], [35, 0.9300797747536368, 0.5358255451713396], [36, 0.9285155638980135, 0.5388496468213926], [37, 0.9264820897857031, 0.5281124497991968], [38, 0.9286719849835758, 0.5318275154004106], [39, 0.9297669325825121, 0.537590113285273], [40, 0.9296105114969498, 0.5360824742268041], [41, 0.9288284060691381, 0.5333333333333334], [42, 0.9250743000156421, 0.5233830845771145], [43, 0.9260128265290161, 0.5284147557328016], [44, 0.9264820897857031, 0.5290581162324649], [45, 0.9267949319568278, 0.5347912524850894], [46, 0.9278898795557641, 0.5403788634097707], [47, 0.9272641952135148, 0.5317220543806647], [48, 0.9277334584702018, 0.5352112676056338], [49, 0.9275770373846395, 0.5383848454636092]]\n",
      "0.9286719849835758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "results = []\n",
    "for i in range(1, 50):\n",
    "    classifier = DecisionTreeClassifier(random_state=55, max_depth=i)\n",
    "\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    #print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results.append([i,accuracy_score(y_test, y_pred), f1_score(y_test, y_pred)])\n",
    "\n",
    "print(results)\n",
    "print(y_test.value_counts()[0]/len(y_test))\n",
    "\n",
    "#plot_tree(classifier, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04a301",
   "metadata": {
    "id": "f7a90r0lLaPK"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "# Stack matrices horizontally (column wise) using hstack().\n",
    "trainX_tfidf = sparse.hstack([x_train_tfidf, x_train_tfidf])\n",
    "\n",
    "# Convert Spare Matrix into an Array using toarray() \n",
    "trainX_tfidf_arr = trainX_tfidf.toarray()\n",
    "\n",
    "# Concatenate TF-IDF and Cosine Similarity using numpy.c_[], \n",
    "# which is just another column stack.\n",
    "trainX_tfidf_cos = np.c_[trainX_tfidf_arr, trainX_tfidf_arr]\n",
    "trainX_tfidf_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392089fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHh4n0owqi7X",
    "outputId": "89191b1a-06db-4278-e176-7420b00b22e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "[CV] END ................................ score: (test=0.795) total time=   4.1s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.800) total time=   3.2s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.798) total time=   3.2s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   10.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.798) total time=   3.5s\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   14.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.802) total time=   2.0s\n",
      "[0.79548798 0.79995136 0.79795396 0.79810955 0.80174715]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7986500004807436"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def corss_val(model):\n",
    "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "    auc = cross_val_score(\n",
    "        model, x_train_tfidf, y_train_balanced, scoring=\"f1\", cv=kf, verbose=10)\n",
    "    print(auc)\n",
    "    return auc.mean()\n",
    "    \n",
    "corss_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b5a68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdCnGQvJusL-",
    "outputId": "906bbd56-5a82-4e97-c407-367570d8b4b7"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START C=1, class_weight=None, kernel=linear.......................\n",
      "[CV 1/5; 1/4] END C=1, class_weight=None, kernel=linear; AUC: (train=0.999, test=0.998) F1: (train=0.993, test=0.988) Precision: (train=0.992, test=0.981) Recall: (train=0.994, test=0.995) total time= 1.9min\n",
      "[CV 2/5; 1/4] START C=1, class_weight=None, kernel=linear.......................\n",
      "[CV 2/5; 1/4] END C=1, class_weight=None, kernel=linear; AUC: (train=0.999, test=0.998) F1: (train=0.994, test=0.987) Precision: (train=0.992, test=0.980) Recall: (train=0.995, test=0.995) total time= 2.0min\n",
      "[CV 3/5; 1/4] START C=1, class_weight=None, kernel=linear.......................\n",
      "[CV 3/5; 1/4] END C=1, class_weight=None, kernel=linear; AUC: (train=0.999, test=0.998) F1: (train=0.994, test=0.987) Precision: (train=0.992, test=0.980) Recall: (train=0.995, test=0.994) total time= 2.0min\n",
      "[CV 4/5; 1/4] START C=1, class_weight=None, kernel=linear.......................\n",
      "[CV 4/5; 1/4] END C=1, class_weight=None, kernel=linear; AUC: (train=0.999, test=0.997) F1: (train=0.994, test=0.986) Precision: (train=0.993, test=0.976) Recall: (train=0.995, test=0.995) total time= 1.9min\n",
      "[CV 5/5; 1/4] START C=1, class_weight=None, kernel=linear.......................\n",
      "[CV 5/5; 1/4] END C=1, class_weight=None, kernel=linear; AUC: (train=0.999, test=0.997) F1: (train=0.994, test=0.986) Precision: (train=0.992, test=0.978) Recall: (train=0.995, test=0.995) total time= 1.9min\n",
      "[CV 1/5; 2/4] START C=1, class_weight=None, kernel=rbf..........................\n",
      "[CV 1/5; 2/4] END C=1, class_weight=None, kernel=rbf; AUC: (train=0.999, test=0.999) F1: (train=0.999, test=0.997) Precision: (train=0.998, test=0.994) Recall: (train=1.000, test=1.000) total time= 4.3min\n",
      "[CV 2/5; 2/4] START C=1, class_weight=None, kernel=rbf..........................\n",
      "[CV 2/5; 2/4] END C=1, class_weight=None, kernel=rbf; AUC: (train=0.999, test=0.999) F1: (train=0.999, test=0.998) Precision: (train=0.998, test=0.996) Recall: (train=1.000, test=1.000) total time= 4.5min\n",
      "[CV 3/5; 2/4] START C=1, class_weight=None, kernel=rbf..........................\n",
      "[CV 3/5; 2/4] END C=1, class_weight=None, kernel=rbf; AUC: (train=0.999, test=0.998) F1: (train=0.999, test=0.998) Precision: (train=0.998, test=0.995) Recall: (train=1.000, test=1.000) total time= 4.4min\n",
      "[CV 4/5; 2/4] START C=1, class_weight=None, kernel=rbf..........................\n",
      "[CV 4/5; 2/4] END C=1, class_weight=None, kernel=rbf; AUC: (train=0.999, test=1.000) F1: (train=0.999, test=0.997) Precision: (train=0.998, test=0.994) Recall: (train=1.000, test=1.000) total time= 4.4min\n",
      "[CV 5/5; 2/4] START C=1, class_weight=None, kernel=rbf..........................\n",
      "[CV 5/5; 2/4] END C=1, class_weight=None, kernel=rbf; AUC: (train=0.999, test=0.999) F1: (train=0.999, test=0.997) Precision: (train=0.998, test=0.995) Recall: (train=1.000, test=1.000) total time= 4.4min\n",
      "[CV 1/5; 3/4] START C=1, class_weight=balanced, kernel=linear...................\n",
      "[CV 1/5; 3/4] END C=1, class_weight=balanced, kernel=linear; AUC: (train=0.999, test=0.998) F1: (train=0.993, test=0.988) Precision: (train=0.992, test=0.981) Recall: (train=0.994, test=0.995) total time= 1.9min\n",
      "[CV 2/5; 3/4] START C=1, class_weight=balanced, kernel=linear...................\n",
      "[CV 2/5; 3/4] END C=1, class_weight=balanced, kernel=linear; AUC: (train=0.999, test=0.998) F1: (train=0.994, test=0.988) Precision: (train=0.992, test=0.981) Recall: (train=0.995, test=0.995) total time= 2.0min\n",
      "[CV 3/5; 3/4] START C=1, class_weight=balanced, kernel=linear...................\n",
      "[CV 3/5; 3/4] END C=1, class_weight=balanced, kernel=linear; AUC: (train=0.999, test=0.998) F1: (train=0.994, test=0.987) Precision: (train=0.992, test=0.980) Recall: (train=0.995, test=0.994) total time= 2.0min\n",
      "[CV 4/5; 3/4] START C=1, class_weight=balanced, kernel=linear...................\n",
      "[CV 4/5; 3/4] END C=1, class_weight=balanced, kernel=linear; AUC: (train=0.999, test=0.997) F1: (train=0.994, test=0.986) Precision: (train=0.993, test=0.976) Recall: (train=0.995, test=0.995) total time= 2.0min\n",
      "[CV 5/5; 3/4] START C=1, class_weight=balanced, kernel=linear...................\n",
      "[CV 5/5; 3/4] END C=1, class_weight=balanced, kernel=linear; AUC: (train=0.999, test=0.997) F1: (train=0.994, test=0.986) Precision: (train=0.992, test=0.978) Recall: (train=0.995, test=0.995) total time= 2.0min\n",
      "[CV 1/5; 4/4] START C=1, class_weight=balanced, kernel=rbf......................\n",
      "[CV 1/5; 4/4] END C=1, class_weight=balanced, kernel=rbf; AUC: (train=0.999, test=0.999) F1: (train=0.999, test=0.997) Precision: (train=0.998, test=0.994) Recall: (train=1.000, test=1.000) total time= 4.5min\n",
      "[CV 2/5; 4/4] START C=1, class_weight=balanced, kernel=rbf......................\n",
      "[CV 2/5; 4/4] END C=1, class_weight=balanced, kernel=rbf; AUC: (train=0.999, test=0.999) F1: (train=0.999, test=0.998) Precision: (train=0.998, test=0.996) Recall: (train=1.000, test=1.000) total time= 4.6min\n",
      "[CV 3/5; 4/4] START C=1, class_weight=balanced, kernel=rbf......................\n",
      "[CV 3/5; 4/4] END C=1, class_weight=balanced, kernel=rbf; AUC: (train=0.999, test=0.999) F1: (train=0.999, test=0.998) Precision: (train=0.998, test=0.995) Recall: (train=1.000, test=1.000) total time= 4.8min\n",
      "[CV 4/5; 4/4] START C=1, class_weight=balanced, kernel=rbf......................\n",
      "[CV 4/5; 4/4] END C=1, class_weight=balanced, kernel=rbf; AUC: (train=1.000, test=1.000) F1: (train=0.999, test=0.997) Precision: (train=0.998, test=0.994) Recall: (train=1.000, test=1.000) total time= 4.7min\n",
      "[CV 5/5; 4/4] START C=1, class_weight=balanced, kernel=rbf......................\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "svm_estimator = svm.SVC()\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F1': 'f1', 'Precision': 'precision', 'Recall':'recall'}\n",
    "svm = GridSearchCV(estimator=svm_estimator,\n",
    "             param_grid={'C': [1, ], 'kernel': (\"linear\", \"rbf\"), 'class_weight': (None, \"balanced\")},\n",
    "             scoring=scoring,\n",
    "             refit='AUC',\n",
    "             return_train_score=True, \n",
    "             verbose=10)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039795fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpTGdsa5uxUU",
    "outputId": "08ef6633-4c8a-4877-e2af-a5ad1b344e6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6241519674355496"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae534dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "gyd2l8rBooji",
    "outputId": "9910980c-1f40-4013-d724-f7feb98c1697"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a404435d526b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGammas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "#svm_estimator = svm.SVC()\n",
    "\n",
    "clf_ = svm.SVC(kernel='rbf')\n",
    "Cs = [1, 10, 100, 1000]\n",
    "Gammas = [1e-3, 1e-4]\n",
    "clf = GridSearchCV(clf_,\n",
    "            dict(C=Cs,\n",
    "                 gamma=Gammas),\n",
    "                 cv=2,\n",
    "                 pre_dispatch='1*n_jobs',\n",
    "                 n_jobs=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = [x[1] for x in clf.grid_scores_]\n",
    "scores = np.array(scores).reshape(len(Cs), len(Gammas))\n",
    "\n",
    "for ind, i in enumerate(Cs):\n",
    "    plt.plot(Gammas, scores[ind], label='C: ' + str(i))\n",
    "plt.legend()\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('Mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08163a49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxpM3aUP9Aju",
    "outputId": "0d82410c-fa3f-43dc-be1a-54f918150751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\");\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib\n",
    "SEED = 1234\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a19751",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mW6lxign9HmR",
    "outputId": "3456e41c-40f2-48c9-9b6f-366ff87480cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12443 sentences\n"
     ]
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "book = urllib.request.urlopen(url=\"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/harrypotter.txt\")\n",
    "sentences = tokenizer.tokenize(str(book.read()))\n",
    "print (f\"{len(sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b56a8",
   "metadata": {
    "id": "rPDfkspo9KXH"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"Conditional preprocessing on our text.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # Separate into word tokens\n",
    "    text = text.split(\" \")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec62f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6bhNb8S9R2e",
    "outputId": "3b410a2a-fccf-4d0b-f2b5-4d77dedaf0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snape nodded, but did not elaborate.\n",
      "['snape', 'nodded', 'but', 'did', 'not', 'elaborate']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess sentences\n",
    "print (sentences[11])\n",
    "sentences = [preprocess(sentence) for sentence in sentences]\n",
    "print (sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b81df2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pDU9y4S9YAL",
    "outputId": "80114e03-c2ac-449e-ad53-d7c229721e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07e68b",
   "metadata": {
    "id": "gJfAMt3T-Fsd"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c24ca1",
   "metadata": {
    "id": "cn6B0lqq-GON"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed402d77",
   "metadata": {
    "id": "KVpFyoCg-GtC"
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0c8ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vhfqu59W-C66",
    "outputId": "64b9db22-7f06-4296-d4cf-d55156e19cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.6B.50d.txt',\n",
       " 'glove.6B.100d.txt',\n",
       " 'glove.6B.200d.txt',\n",
       " 'glove.6B.300d.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unzip the file (may take ~3-5 minutes)\n",
    "resp = urlopen(\"http://nlp.stanford.edu/data/glove.6B.zip\")\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "zipfile.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1af70a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "iJpL5YVR-uKy",
    "outputId": "c1544182-165c-4edc-f381-a7cc556be5d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/glove.6B.100d.txt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write embeddings to file\n",
    "embeddings_file = \"glove.6B.{0}d.txt\".format(100)\n",
    "zipfile.extract(embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13340e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-bINWif_Y6e",
    "outputId": "cab83c1a-1f1e-410d-a00e-7e14fdc66d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: the\n",
      "embedding:\n",
      "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n",
      "embedding dim: 100\n"
     ]
    }
   ],
   "source": [
    "# Preview of the GloVe embeddings file\n",
    "with open(embeddings_file, \"r\") as fp:\n",
    "    line = next(fp)\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embedding = np.asarray(values[1:], dtype='float32')\n",
    "    print (f\"word: {word}\")\n",
    "    print (f\"embedding:\\n{embedding}\")\n",
    "    print (f\"embedding dim: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdf5f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK0NP4sa_bMx",
    "outputId": "3fe110b1-8705-483a-8bb4-3012f983b7ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save GloVe embeddings to local directory in word2vec format\n",
    "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\n",
    "glove2word2vec(embeddings_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf7676",
   "metadata": {
    "id": "8dM_QdEZ_yql"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88844e6d",
   "metadata": {
    "id": "OIBWqRvO_nVE"
   },
   "outputs": [],
   "source": [
    "# Load embeddings (may take a minute)\n",
    "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d30e7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faq27mGX_0ij",
    "outputId": "600f5796-0df5-4d45-8243-1df410368aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380928039551),\n",
       " ('throne', 0.6755735874176025),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534753799438)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (king - man) + woman = ?\n",
    "# king - man = ? -  woman\n",
    "glove.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d62c71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTByGuAo_t8o",
    "outputId": "22315c1a-32eb-4ade-d27c-a4699e9475ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gohan', 0.7246542572975159),\n",
       " ('bulma', 0.6497020125389099),\n",
       " ('raistlin', 0.6443604230880737),\n",
       " ('skaar', 0.6316742897033691),\n",
       " ('guybrush', 0.6231324672698975)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nearest neighbors (excluding itself)\n",
    "glove.wv.most_similar(positive=\"goku\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db09611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqlmbEYGAASh",
    "outputId": "676fdae9-5cd9-4dad-c406-19950d33a944"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Reduce dimensionality for plotting\n",
    "X = glove[glove.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064289a0",
   "metadata": {
    "id": "NU05bgv1_KD4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3a213",
   "metadata": {
    "id": "R32oe5DrALf-"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533cd2e6",
   "metadata": {
    "id": "xyJpYIC_AS1x"
   },
   "outputs": [],
   "source": [
    "set_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417941d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvUpd0OiAYrF",
    "outputId": "31755e0e-f085-4dc1-8bc3-7bdd6e2d4df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f3c71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FGjTtjLHAZYF",
    "outputId": "b4473bd2-bf5e-4fc7-fa0f-9f2884874aaf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3c091898-0514-49e8-adb5-4dddcb8823a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The New Faces of Reality TV</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c091898-0514-49e8-adb5-4dddcb8823a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3c091898-0514-49e8-adb5-4dddcb8823a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3c091898-0514-49e8-adb5-4dddcb8823a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               title  category\n",
       "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
       "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
       "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
       "3          Growing Signs of a Slowing on Wall Street  Business\n",
       "4                        The New Faces of Reality TV     World"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/news.csv\"\n",
    "df = pd.read_csv(url, header=0) # load\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61c31d",
   "metadata": {
    "id": "ka-hI-taA3bY"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad917c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drsCXsRSA6zS",
    "outputId": "76e6969c-b310-4ec4-9bd3-5857691fe9c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "print (STOPWORDS[:5])\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b64cca",
   "metadata": {
    "id": "zPaHgkk1A9N6"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stopwords=STOPWORDS):\n",
    "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "    text = pattern.sub(\"\", text)\n",
    "\n",
    "    # Remove words in paranthesis\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe18ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gNIViGLtBAAK",
    "outputId": "658f0cf6-a6c5-4f88-c1d4-a572c85634e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'great week nyse'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "text = \"Great week for the NYSE!\"\n",
    "preprocess(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76848042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjFKOs8CBDqk",
    "outputId": "8f5fc7a3-9159-4967-e04c-e08e4f9d2903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
      "\n",
      "sharon accepts plan reduce gaza army operation haaretz says\n"
     ]
    }
   ],
   "source": [
    "# Apply to dataframe\n",
    "preprocessed_df = df.copy()\n",
    "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
    "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707c1c7",
   "metadata": {
    "id": "vobBIvnqBGOf"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d3613",
   "metadata": {
    "id": "E82ff7FWBVDB"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de91729",
   "metadata": {
    "id": "Z-Y8_B1PBXaP"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size):\n",
    "    \"\"\"Split dataset into data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e8a30",
   "metadata": {
    "id": "4dFFKm1DBZts"
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "X = preprocessed_df[\"title\"].values\n",
    "y = preprocessed_df[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48e59a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxDvjMDmBeN7",
    "outputId": "e5ad67d0-ddc1-4cc8-eea5-0471236e9145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84000,), y_train: (84000,)\n",
      "X_val: (18000,), y_val: (18000,)\n",
      "X_test: (18000,), y_test: (18000,)\n",
      "Sample point: china battles north korea nuclear talks → World\n"
     ]
    }
   ],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, train_size=TRAIN_SIZE)\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e7cb2",
   "metadata": {
    "id": "L8KPRKk598ff"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad4886",
   "metadata": {
    "id": "shuU8eCBB5Fp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5b07e",
   "metadata": {
    "id": "hzm2mLkTBoLr"
   },
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {'class_to_index': self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399082f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5f6RPOoB8is",
    "outputId": "be553382-32c2-4e5c-b828-b4b9903b03f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "NUM_CLASSES = len(label_encoder)\n",
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58527f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRudgusPB9JJ",
    "outputId": "9665fcc5-5423-40a2-97f3-d50daa1995cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0]: World\n",
      "y_train[0]: 3\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = label_encoder.encode(y_train)\n",
    "y_val = label_encoder.encode(y_val)\n",
    "y_test = label_encoder.encode(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2b200",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FdshaYQCDzN",
    "outputId": "84913173-ee76-4a84-9ea1-24eb9906bff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [21000 21000 21000 21000]\n",
      "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"counts: {counts}\\nweights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d786be",
   "metadata": {
    "id": "ZiOYRhY6CPul"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from more_itertools import take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facce869",
   "metadata": {
    "id": "TfusLDEOCURY"
   },
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, char_level, num_tokens=None,\n",
    "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
    "                 token_to_index=None):\n",
    "        self.char_level = char_level\n",
    "        self.separator = \"\" if self.char_level else \" \"\n",
    "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
    "        self.num_tokens = num_tokens\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        if not token_to_index:\n",
    "            token_to_index = {pad_token: 0, oov_token: 1}\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        if not self.char_level:\n",
    "            texts = [text.split(\" \") for text in texts]\n",
    "        all_tokens = [token for text in texts for token in text]\n",
    "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
    "        self.min_token_freq = counts[-1][1]\n",
    "        for token, count in counts:\n",
    "            index = len(self)\n",
    "            self.token_to_index[token] = index\n",
    "            self.index_to_token[index] = token\n",
    "        return self\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            if not self.char_level:\n",
    "                text = text.split(\" \")\n",
    "            sequence = []\n",
    "            for token in text:\n",
    "                sequence.append(self.token_to_index.get(\n",
    "                    token, self.token_to_index[self.oov_token]))\n",
    "            sequences.append(np.asarray(sequence))\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = []\n",
    "            for index in sequence:\n",
    "                text.append(self.index_to_token.get(index, self.oov_token))\n",
    "            texts.append(self.separator.join([token for token in text]))\n",
    "        return texts\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\n",
    "                \"char_level\": self.char_level,\n",
    "                \"oov_token\": self.oov_token,\n",
    "                \"token_to_index\": self.token_to_index\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c84fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hw-yzDeCXC_",
    "outputId": "9901e9c9-d40c-421b-bad7-4002a9c9a74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=5000)>\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
    "tokenizer.fit_on_texts(texts=X_train)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print (tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6057b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZFzQSs-CaM5",
    "outputId": "9a4b74bc-7765-49ba-a720-4aa1f20755f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
      "least freq token's freq: 14\n"
     ]
    }
   ],
   "source": [
    "# Sample of tokens\n",
    "print (take(5, tokenizer.token_to_index.items()))\n",
    "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cc465",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RzOVnCvCdVV",
    "outputId": "4e4c0e19-9739-4d81-850e-7b702d6e2741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to indices:\n",
      "  (preprocessed) → china battles north korea nuclear talks\n",
      "  (tokenized) → [  16 1491  285  142  114   24]\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences of indices\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
    "print (\"Text to indices:\\n\"\n",
    "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
    "    f\"  (tokenized) → {X_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91319d09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZX2_UclChxn",
    "outputId": "4ff0cacf-33c5-4bd3-c3c3-42f2eb5dc855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 1, 6, 5, 6]])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "vocab_size = 10\n",
    "x = torch.randint(high=vocab_size, size=(1,5))\n",
    "print (x)\n",
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f81b30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZ8fOxJuC-7B",
    "outputId": "d982b3c6-cb26-4524-a024-b32742df6329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10, 100)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0826f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLJXn4EECpEe",
    "outputId": "eb3fb5a5-67bf-4e4a-db07-7e55828fbf66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer\n",
    "embeddings = nn.Embedding(embedding_dim=100, num_embeddings=vocab_size)\n",
    "print (embeddings.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f88e7c",
   "metadata": {
    "id": "KEsFtF9AC9Uk"
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_seq_len=0):\n",
    "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
    "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
    "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        padded_sequences[i][:len(sequence)] = sequence\n",
    "    return padded_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92a842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DFGr7aFFPW4",
    "outputId": "49c247f3-a3e7-451e-ba75-8520241ecde9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "[[1.600e+01 1.491e+03 2.850e+02 1.420e+02 1.140e+02 2.400e+01]\n",
      " [1.445e+03 2.300e+01 6.560e+02 2.197e+03 1.000e+00 0.000e+00]\n",
      " [1.200e+02 1.400e+01 1.955e+03 1.005e+03 1.529e+03 4.014e+03]]\n"
     ]
    }
   ],
   "source": [
    "# 2D sequences\n",
    "padded = pad_sequences(X_train[0:3])\n",
    "print (padded.shape)\n",
    "print (padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10c3d4",
   "metadata": {
    "id": "a80gKRykFUrm"
   },
   "outputs": [],
   "source": [
    "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2027e5",
   "metadata": {
    "id": "U0FeOp4mFZxf"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, max_filter_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.max_filter_size = max_filter_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return [X, y]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Processing on a batch.\"\"\"\n",
    "        # Get inputs\n",
    "        batch = np.array(batch)\n",
    "        X = batch[:, 0]\n",
    "        y = batch[:, 1]\n",
    "\n",
    "        # Pad sequences\n",
    "        X = pad_sequences(X)\n",
    "\n",
    "        # Cast\n",
    "        X = torch.LongTensor(X.astype(np.int32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d95e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILWbQOhrFnNf",
    "outputId": "52e747ea-fd69-418c-8d68-fd5857cda782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train dataset:<Dataset(N=84000)>\n",
      "  Val dataset: <Dataset(N=18000)>\n",
      "  Test dataset: <Dataset(N=18000)>\n",
      "Sample point:\n",
      "  X: [  16 1491  285  142  114   24]\n",
      "  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "max_filter_size = max(FILTER_SIZES)\n",
    "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\n",
    "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\n",
    "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\n",
    "print (\"Datasets:\\n\"\n",
    "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
    "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
    "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {train_dataset[0][0]}\\n\"\n",
    "    f\"  y: {train_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d94bd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVU5OALCFqKK",
    "outputId": "860c78b3-ab8e-44d9-84cb-b94d95fcebbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: [64, 14]\n",
      "  y: [64]\n",
      "Sample point:\n",
      "  X: tensor([  16, 1491,  285,  142,  114,   24,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      "  y: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf35ac",
   "metadata": {
    "id": "ZYAnuwKOIq0d"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ea58a",
   "metadata": {
    "id": "UhYdq6XcIsKW"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 100\n",
    "DROPOUT_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68daae8",
   "metadata": {
    "id": "RXPOCt3bIvI7"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
    "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
    "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
    "                 padding_idx=0):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Filter sizes\n",
    "        self.filter_sizes = filter_sizes\n",
    "\n",
    "        # Initialize embeddings\n",
    "        if pretrained_embeddings is None:\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx)\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
    "\n",
    "        # Freeze embeddings or not\n",
    "        if freeze_embeddings:\n",
    "            self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        # Conv weights\n",
    "        self.conv = nn.ModuleList(\n",
    "            [nn.Conv1d(in_channels=embedding_dim,\n",
    "                       out_channels=num_filters,\n",
    "                       kernel_size=f) for f in filter_sizes])\n",
    "\n",
    "        # FC weights\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs, channel_first=False):\n",
    "\n",
    "        # Embed\n",
    "        x_in, = inputs\n",
    "        x_in = self.embeddings(x_in)\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        if not channel_first:\n",
    "            x_in = x_in.transpose(1, 2)\n",
    "\n",
    "        # Conv outputs\n",
    "        z = []\n",
    "        max_seq_len = x_in.shape[2]\n",
    "        for i, f in enumerate(self.filter_sizes):\n",
    "            # `SAME` padding\n",
    "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
    "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
    "\n",
    "            # Conv + pool\n",
    "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
    "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
    "            z.append(_z)\n",
    "\n",
    "        # Concat conv outputs\n",
    "        z = torch.cat(z, 1)\n",
    "\n",
    "        # FC layers\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421cef6",
   "metadata": {
    "id": "8t4Rujw9OwE8"
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(embeddings_file):\n",
    "    \"\"\"Load embeddings from a file.\"\"\"\n",
    "    embeddings = {}\n",
    "    with open(embeddings_file, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = embedding\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88688fd2",
   "metadata": {
    "id": "3-z20z_jOz-6"
   },
   "outputs": [],
   "source": [
    "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\n",
    "    \"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\n",
    "    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511de0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-axf5AkEO2cJ",
    "outputId": "9e063edd-20f4-428e-fdb9-7c5d0a783efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Embeddings(words=5000, dim=100)>\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings_file = 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
    "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
    "embedding_matrix = make_embeddings_matrix(\n",
    "    embeddings=glove_embeddings, word_index=tokenizer.token_to_index,\n",
    "    embedding_dim=EMBEDDING_DIM)\n",
    "print (f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d4210",
   "metadata": {
    "id": "xAumI9qcO-_f"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def reviews_preprocess(reviews, labels):\n",
    "    \"\"\"\n",
    "    Remove punctuation from review data and replace multiple space with single space.\n",
    "    Map labels from positive/negative to 1/0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reviews: list of reviews\n",
    "    labels: list of labels\n",
    "    Returns\n",
    "    -------\n",
    "    all_reviews: reviews with punctuation removed\n",
    "    all_words: list of all words occurring in the reviews\n",
    "    labels: labels with 1 for positive and 0 for negative\n",
    "    \"\"\"\n",
    "    all_reviews = list()\n",
    "    for text in reviews:\n",
    "        text = text.lower()\n",
    "        text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "        # replace multiple spaces with single space\n",
    "        text = \" \".join(text.split())\n",
    "        all_reviews.append(text)\n",
    "    all_text = \" \".join(all_reviews)\n",
    "    all_words = all_text.split()\n",
    "\n",
    "    # map labels: \"positive\" = 1 and \"negative\" = 0\n",
    "    labels = [1 if label.strip() == \"positive\" else 0 for label in labels]\n",
    "\n",
    "    return all_reviews, all_words, labels\n",
    "\n",
    "\n",
    "def reviews_create_word_ids(all_words):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping each word to an unique id.\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_words: list of all words occurring in the data\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary with word as key and corresponding id as value\n",
    "    \"\"\"\n",
    "    count_words = Counter(all_words)\n",
    "    total_words = len(all_words)\n",
    "    sorted_words = count_words.most_common(total_words)\n",
    "    word_ids = {w: i + 1 for i, (w, c) in enumerate(sorted_words)}\n",
    "    return word_ids\n",
    "\n",
    "\n",
    "def reviews_encode(word_ids, reviews):\n",
    "    \"\"\"\n",
    "    Replace each word in the review with its corresponding id specified in the\n",
    "    dictionary word_ids\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word_ids: dictionary with word as key and id as value\n",
    "    reviews: review data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    review data with each word replaced by its corresponding id\n",
    "\n",
    "    \"\"\"\n",
    "    encoded_reviews = list()\n",
    "    for review in reviews:\n",
    "        encoded_review = list()\n",
    "        for word in review.split():\n",
    "            if word not in word_ids.keys():\n",
    "                # if word is not available in word_ids put 0 in that place\n",
    "                encoded_review.append(0)\n",
    "            else:\n",
    "                encoded_review.append(word_ids[word])\n",
    "        encoded_reviews.append(encoded_review)\n",
    "\n",
    "    return encoded_reviews\n",
    "\n",
    "\n",
    "def reviews_pad(encoded_reviews, sequence_length):\n",
    "    \"\"\"\n",
    "    Pad/truncate encoded reviews to the same sequence length, by adding zeros at the\n",
    "    beginning or cutting the end.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoded_reviews: review data with each word encoded with corresponding id\n",
    "    sequence_length: length to pad/truncate the reviews to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Encoded reviews padded/truncated to sequence_length\n",
    "\n",
    "    \"\"\"\n",
    "    padded_reviews = np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "    for i, review in enumerate(encoded_reviews):\n",
    "        review_len = len(review)\n",
    "        if review_len <= sequence_length:\n",
    "            zeros = list(np.zeros(sequence_length - review_len, dtype=int))\n",
    "            new = zeros + review\n",
    "        else:\n",
    "            new = review[:sequence_length]\n",
    "        padded_reviews[i, :] = np.array(new)\n",
    "    return padded_reviews\n",
    "\n",
    "\n",
    "def reviews_split(padded_reviews, labels):\n",
    "    \"\"\"\n",
    "    Splits data into train, validation and test set with a 80, 10, 10 split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    padded_reviews: reviews padded to the same sequence length\n",
    "    labels: labels correspoding to reviews\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_x: Training data\n",
    "    train_y: Training labels\n",
    "    valid_x: Validation data\n",
    "    valid_y: Validation labels\n",
    "    test_x: Test data\n",
    "    test_y: Test labels\n",
    "    \"\"\"\n",
    "    train_x = padded_reviews[: int(0.8 * len(padded_reviews))]\n",
    "    train_y = labels[: int(0.8 * len(padded_reviews))]\n",
    "    valid_x = padded_reviews[\n",
    "        int(0.8 * len(padded_reviews)) : int(0.9 * len(padded_reviews))\n",
    "    ]\n",
    "    valid_y = labels[int(0.8 * len(padded_reviews)) : int(0.9 * len(padded_reviews))]\n",
    "    test_x = padded_reviews[int(0.9 * len(padded_reviews)) :]\n",
    "    test_y = labels[int(0.9 * len(padded_reviews)) :]\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c7abc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9s8CfxOtf46",
    "outputId": "e48ad7f1-ded7-4207-cdf6-9097066047ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction run\n",
      "First ten words:  ['user', 'when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish']\n",
      "First label:  0\n"
     ]
    }
   ],
   "source": [
    "reviews_lines = df_hate_speech[\"tweet\"]\n",
    "label_lines = df_hate_speech[\"tweet\"]\n",
    "raw_reviews, words, labels = reviews_preprocess(reviews_lines, label_lines)\n",
    "print(raw_reviews[0])\n",
    "print(\"First ten words: \", words[:10])\n",
    "print(\"First label: \", labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e6a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTwfoM6KuFUL",
    "outputId": "72c677c0-34f9-4651-a5a1-1516ea3af45c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "499\n"
     ]
    }
   ],
   "source": [
    "# Determine an integer id for each unique word\n",
    "word_ids = reviews_create_word_ids(words)\n",
    "print(word_ids.get(\"the\"))\n",
    "print(word_ids.get(\"movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc0a82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaAB9iImuKZq",
    "outputId": "1c3dff51-8375-4d3b-90f7-7133d052cb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction run\n",
      "[1, 34, 4, 261, 10, 16392, 7, 10, 20, 3338, 100, 6525, 93, 254, 253, 93, 7974, 472]\n"
     ]
    }
   ],
   "source": [
    "# Encode each word in the review by its unique identifier\n",
    "encoded_reviews = reviews_encode(word_ids, raw_reviews)\n",
    "print(raw_reviews[0])\n",
    "print(encoded_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fcfcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_hvnY6CuPXZ",
    "outputId": "40979fec-70c1-495e-f932-646075b30d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     1    34     4   261    10 16392     7    10    20  3338\n",
      "   100  6525    93   254   253    93  7974   472]\n"
     ]
    }
   ],
   "source": [
    "# Padding/truncating all reviews to the same length. Although this isn't strictly\n",
    "# necessary, it facilitates batch processing: all inputs of a batch need to have the\n",
    "# same length.\n",
    "sequence_length = 200\n",
    "padded_reviews = reviews_pad(encoded_reviews, sequence_length)\n",
    "print(padded_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d03e5",
   "metadata": {
    "id": "BMo3nDqRuLgv"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def reviews_split(padded_reviews, labels):\n",
    "    \"\"\"\n",
    "    Splits data into train, validation and test set with a 80, 10, 10 split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    padded_reviews: reviews padded to the same sequence length\n",
    "    labels: labels correspoding to reviews\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_x: Training data\n",
    "    train_y: Training labels\n",
    "    valid_x: Validation data\n",
    "    valid_y: Validation labels\n",
    "    test_x: Test data\n",
    "    test_y: Test labels\n",
    "    \"\"\"\n",
    "    train_x = padded_reviews[: int(0.8 * len(padded_reviews))]\n",
    "    train_y = labels[: int(0.8 * len(padded_reviews))]\n",
    "    valid_x = padded_reviews[\n",
    "        int(0.8 * len(padded_reviews)) : int(0.9 * len(padded_reviews))\n",
    "    ]\n",
    "    valid_y = labels[int(0.8 * len(padded_reviews)) : int(0.9 * len(padded_reviews))]\n",
    "    test_x = padded_reviews[int(0.9 * len(padded_reviews)) :]\n",
    "    test_y = labels[int(0.9 * len(padded_reviews)) :]\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
    "\n",
    "\n",
    "def reviews_create_dataloaders(\n",
    "    train_x, train_y, valid_x, valid_y, test_x, test_y, batch_size=50\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates PyTorch data loaders\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_x: Training data\n",
    "    train_y: Training labels\n",
    "    valid_x: Validation data\n",
    "    valid_y: Validation labels\n",
    "    test_x: Test data\n",
    "    test_y: Test labels\n",
    "    batch_size: size of the batch\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PyTorch data loaders for train, validation and test\n",
    "    \"\"\"\n",
    "    # create Tensor Dataset\n",
    "    train_data = TensorDataset(torch.LongTensor(train_x), torch.IntTensor(train_y))\n",
    "    valid_data = TensorDataset(torch.LongTensor(valid_x), torch.IntTensor(valid_y))\n",
    "    test_data = TensorDataset(torch.LongTensor(test_x), torch.IntTensor(test_y))\n",
    "\n",
    "    # dataloader\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def reviews_train(\n",
    "    net,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    lr=0.01,\n",
    "    lr_decay=0.0001,\n",
    "    epochs=3,\n",
    "    clip=5,\n",
    "    print_every=5,\n",
    "    criterion=nn.BCELoss(),\n",
    "    device=DEVICE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a network on the review data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net: Initialized model\n",
    "    train_loader: Dataloader containing the training data\n",
    "    valid_loader: Dataloader containing the validation data\n",
    "    lr: learning rate\n",
    "    epochs: number of epochs\n",
    "    clip: clip gradients at this value\n",
    "    print_every: print current train and validation loss every x steps\n",
    "    criterion: Loss function\n",
    "    device: device to train on - cpu or cuda\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adagrad(\n",
    "        [param for param in net.parameters() if param.requires_grad == True], lr=lr, lr_decay=lr_decay,\n",
    "    )\n",
    "    batch_processed_counter = 0\n",
    "\n",
    "    net = net.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # train for some number of epochs\n",
    "    for e in range(epochs):\n",
    "        valid_counter = 0\n",
    "        epoch_val_losses = []\n",
    "        losses = []\n",
    "        print(\"Starting epoch\", e + 1)\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            batch_processed_counter += 1\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            # output, h = net(inputs, h)\n",
    "            output = net(inputs)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs /\n",
    "            # LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if batch_processed_counter % print_every == 0:\n",
    "                valid_counter += 1\n",
    "                # Get validation loss\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                num_correct = 0\n",
    "                for inputs, labels in valid_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    output = net(inputs)\n",
    "                    val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "                    epoch_val_losses.append(val_loss.item())\n",
    "                    \n",
    "                    # convert output probabilities to predicted class (0 or 1)\n",
    "                    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "                    # compare predictions to true label\n",
    "                    correct_tensor = pred.eq(labels.float().view_as(pred)).cpu()\n",
    "                    correct = np.squeeze(correct_tensor.numpy())\n",
    "                    num_correct += np.sum(correct)\n",
    "                    \n",
    "                val_acc = num_correct / len(valid_loader.dataset)\n",
    "                net.train()\n",
    "                print(\n",
    "                    \"Epoch: {:2d}/{:2d}   \".format(e + 1, epochs),\n",
    "                    \"Batch: {:2d}  \".format(batch_processed_counter),\n",
    "                    \"Batch loss: {:.6f}   \".format(loss.item()),\n",
    "                    \"Val loss: {:.6f}\".format(np.mean(val_losses)),\n",
    "                    \"Val acc: {:.6f}\".format(val_acc),\n",
    "                )\n",
    "        print(len(epoch_val_losses))\n",
    "\n",
    "        print(\n",
    "            (\n",
    "                \"Finished epoch {}. Average batch loss: {}. \"\n",
    "                \"Average validation loss: {}\"\n",
    "            ).format(e + 1, np.mean(losses), np.mean(epoch_val_losses))\n",
    "        )\n",
    "\n",
    "\n",
    "def reviews_test(net, test_loader, criterion=nn.BCELoss(), device=DEVICE):\n",
    "    \"\"\"\n",
    "    Evaluate a trained network on the review data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net: trained model\n",
    "    test_loader: Dataloader containing the training data\n",
    "    criterion: Loss function\n",
    "    device: device to train on - cpu or cuda\n",
    "    \"\"\"\n",
    "    test_losses = []  # track loss\n",
    "    num_correct = 0\n",
    "\n",
    "    correct = 0  # number of correct predictions\n",
    "    total = 0  # total number of examples\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    net = net.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = net(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        test_loss = criterion(output.squeeze(), labels.float())\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        # convert output probabilities to predicted class (0 or 1)\n",
    "        pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred)).cpu()\n",
    "        correct = np.squeeze(correct_tensor.numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "\n",
    "        total += labels.shape[0]\n",
    "\n",
    "\n",
    "    # -- stats! -- ##\n",
    "    # avg test loss\n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "    # accuracy over all test data\n",
    "    test_acc = num_correct / len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c3d41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFRoX9Uqubqg",
    "outputId": "501b128e-d32d-470d-88f9-2b3c70b0f14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25569 3196 3197\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into 80% training, 10% test, and 10% validation Dataset\n",
    "train_x, train_y, valid_x, valid_y, test_x, test_y = reviews_split(\n",
    "    padded_reviews, labels\n",
    ")\n",
    "print(len(train_y), len(valid_y), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b4304",
   "metadata": {
    "id": "JwzpjuXYuwEw"
   },
   "outputs": [],
   "source": [
    "# Create data loaders for training\n",
    "train_loader, valid_loader, test_loader = reviews_create_dataloaders(\n",
    "    train_x, train_y, valid_x, valid_y, test_x, test_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea01d1",
   "metadata": {
    "id": "6ZDPuV2fu312"
   },
   "outputs": [],
   "source": [
    "# ME\n",
    "class SimpleLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        num_layers=1,\n",
    "        lstm_dropout_prob=0.5,\n",
    "        dropout_prob=0.3,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocab_size: number of unique words in the reviews\n",
    "        embeddings_dim: size of the embeddings\n",
    "        hidden_dim: dimension of the LSTM output\n",
    "        num_layers: number of LSTM layers\n",
    "        lstm_dropout_prob: dropout applied between the LSTM layers\n",
    "        dropout_prob: dropout applied before the fully connected layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=lstm_dropout_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: batch as a (batch_size, sequence_length) tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Probability of positive class.\n",
    "        \"\"\"\n",
    "        # init hidden layer, which is needed for the LSTM\n",
    "        batch_size = len(x)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        # YOUR CODE HERE\n",
    "        #x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize hidden state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Empty hidden LSTM state.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create two new tensors with sizes num_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters())  # only used to determine device\n",
    "\n",
    "        hidden = (\n",
    "            weight.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "            weight.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "        )\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4c95e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKts2FzTu-W3",
    "outputId": "b2954c41-6f17-4125-b0a4-bdb294b7a153"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(word_ids) + 1  # +1 for the 0 padding\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "\n",
    "\n",
    "# this may raise a warning when num_layers=1 (which is fine)\n",
    "# make sure to reinizialize the model if you want to train multiple times\n",
    "model = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, num_layers).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1df882",
   "metadata": {
    "id": "BmXl1IFcwPfG"
   },
   "outputs": [],
   "source": [
    "embeddings = nn.Embedding(len(word_ids) + 1, 100).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ee00f",
   "metadata": {
    "id": "CvnLlE_3wk0p"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reviews_load_embeddings(\n",
    "    embedding_layer, word_ids, pretrained_embeddings_file=\"data/word-embeddings.txt\"\n",
    "):\n",
    "    \"\"\"Load pretrained embeddings into an embedding layer.\n",
    "\n",
    "    Updates the weights of the embedding layer with with the embeddings given in the\n",
    "    provided word embeddings file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_layer: torch.nn.Embedding used in the model\n",
    "    word_ids: dictionary mapping each word to its unique identifier\n",
    "    pretrained_embeddings_file: path to the file containing pretrained embeddings\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Initializing embedding layer with pretrained word embeddings...\")\n",
    "    embeddings_index = dict()\n",
    "    words_initialized = 0\n",
    "    with open(pretrained_embeddings_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            encoded_word = word_ids.get(word)\n",
    "            if encoded_word is not None:\n",
    "                words_initialized += 1\n",
    "                embedding_layer.weight[encoded_word, :] = torch.from_numpy(\n",
    "                    np.asarray(values[1:], dtype=\"float32\")\n",
    "                )\n",
    "    print(\n",
    "        \"Initialized {}/{} word embeddings\".format(\n",
    "            words_initialized, embedding_layer.num_embeddings\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541da83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvgzGZ60wSSM",
    "outputId": "38eacbcc-751a-4b3b-c450-4cff22c335d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with pretrained word embeddings...\n",
      "Initialized 20948/47522 word embeddings\n"
     ]
    }
   ],
   "source": [
    "reviews_load_embeddings(embeddings, word_ids, embeddings_file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367ed9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Mc6ubOXw3fF",
    "outputId": "c3fe57fb-05d7-4f33-f8e9-dd13d53c831e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch:  1/ 5    Batch:  5   Batch loss: 0.040715    Val loss: 0.020985 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 10   Batch loss: 0.008147    Val loss: 0.006501 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 15   Batch loss: 0.004446    Val loss: 0.004354 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 20   Batch loss: 0.004189    Val loss: 0.003352 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 25   Batch loss: 0.003335    Val loss: 0.002743 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 30   Batch loss: 0.002622    Val loss: 0.002354 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 35   Batch loss: 0.002305    Val loss: 0.002080 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 40   Batch loss: 0.001956    Val loss: 0.001864 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 45   Batch loss: 0.002153    Val loss: 0.001688 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 50   Batch loss: 0.001736    Val loss: 0.001545 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 55   Batch loss: 0.001545    Val loss: 0.001430 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 60   Batch loss: 0.001427    Val loss: 0.001329 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 65   Batch loss: 0.001458    Val loss: 0.001243 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 70   Batch loss: 0.001342    Val loss: 0.001167 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 75   Batch loss: 0.001269    Val loss: 0.001098 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 80   Batch loss: 0.001338    Val loss: 0.001039 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 85   Batch loss: 0.001289    Val loss: 0.000986 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 90   Batch loss: 0.001018    Val loss: 0.000941 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 95   Batch loss: 0.001011    Val loss: 0.000900 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 100   Batch loss: 0.001119    Val loss: 0.000858 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 105   Batch loss: 0.001149    Val loss: 0.000822 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 110   Batch loss: 0.000992    Val loss: 0.000788 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 115   Batch loss: 0.001057    Val loss: 0.000757 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 120   Batch loss: 0.000866    Val loss: 0.000729 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 125   Batch loss: 0.000904    Val loss: 0.000702 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 130   Batch loss: 0.000714    Val loss: 0.000679 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 135   Batch loss: 0.000866    Val loss: 0.000655 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 140   Batch loss: 0.000967    Val loss: 0.000634 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 145   Batch loss: 0.000699    Val loss: 0.000613 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 150   Batch loss: 0.000737    Val loss: 0.000595 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 155   Batch loss: 0.000750    Val loss: 0.000578 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 160   Batch loss: 0.000575    Val loss: 0.000562 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 165   Batch loss: 0.000679    Val loss: 0.000546 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 170   Batch loss: 0.000725    Val loss: 0.000530 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 175   Batch loss: 0.000597    Val loss: 0.000515 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 180   Batch loss: 0.000592    Val loss: 0.000502 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 185   Batch loss: 0.000566    Val loss: 0.000491 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 190   Batch loss: 0.000621    Val loss: 0.000479 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 195   Batch loss: 0.000556    Val loss: 0.000467 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 200   Batch loss: 0.000553    Val loss: 0.000457 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 205   Batch loss: 0.000617    Val loss: 0.000446 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 210   Batch loss: 0.000579    Val loss: 0.000437 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 215   Batch loss: 0.000566    Val loss: 0.000428 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 220   Batch loss: 0.000449    Val loss: 0.000418 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 225   Batch loss: 0.000504    Val loss: 0.000410 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 230   Batch loss: 0.000433    Val loss: 0.000402 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 235   Batch loss: 0.000486    Val loss: 0.000394 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 240   Batch loss: 0.000462    Val loss: 0.000386 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 245   Batch loss: 0.000510    Val loss: 0.000379 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 250   Batch loss: 0.000510    Val loss: 0.000371 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 255   Batch loss: 0.000421    Val loss: 0.000365 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 260   Batch loss: 0.000474    Val loss: 0.000358 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 265   Batch loss: 0.000482    Val loss: 0.000351 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 270   Batch loss: 0.000443    Val loss: 0.000345 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 275   Batch loss: 0.000430    Val loss: 0.000339 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 280   Batch loss: 0.000489    Val loss: 0.000333 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 285   Batch loss: 0.000390    Val loss: 0.000328 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 290   Batch loss: 0.000448    Val loss: 0.000323 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 295   Batch loss: 0.000444    Val loss: 0.000317 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 300   Batch loss: 0.000414    Val loss: 0.000313 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 305   Batch loss: 0.000431    Val loss: 0.000308 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 310   Batch loss: 0.000391    Val loss: 0.000303 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 315   Batch loss: 0.000343    Val loss: 0.000299 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 320   Batch loss: 0.000368    Val loss: 0.000294 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 325   Batch loss: 0.000416    Val loss: 0.000290 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 330   Batch loss: 0.000303    Val loss: 0.000286 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 335   Batch loss: 0.000321    Val loss: 0.000282 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 340   Batch loss: 0.000295    Val loss: 0.000278 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 345   Batch loss: 0.000331    Val loss: 0.000274 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 350   Batch loss: 0.000314    Val loss: 0.000271 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 355   Batch loss: 0.000427    Val loss: 0.000267 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 360   Batch loss: 0.000331    Val loss: 0.000264 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 365   Batch loss: 0.000353    Val loss: 0.000260 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 370   Batch loss: 0.000323    Val loss: 0.000257 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 375   Batch loss: 0.000296    Val loss: 0.000253 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 380   Batch loss: 0.000317    Val loss: 0.000250 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 385   Batch loss: 0.000259    Val loss: 0.000247 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 390   Batch loss: 0.000251    Val loss: 0.000244 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 395   Batch loss: 0.000259    Val loss: 0.000241 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 400   Batch loss: 0.000281    Val loss: 0.000238 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 405   Batch loss: 0.000396    Val loss: 0.000235 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 410   Batch loss: 0.000307    Val loss: 0.000233 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 415   Batch loss: 0.000312    Val loss: 0.000230 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 420   Batch loss: 0.000313    Val loss: 0.000227 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 425   Batch loss: 0.000250    Val loss: 0.000225 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 430   Batch loss: 0.000298    Val loss: 0.000222 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 435   Batch loss: 0.000252    Val loss: 0.000220 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 440   Batch loss: 0.000284    Val loss: 0.000218 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 445   Batch loss: 0.000244    Val loss: 0.000215 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 450   Batch loss: 0.000275    Val loss: 0.000213 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 455   Batch loss: 0.000395    Val loss: 0.000210 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 460   Batch loss: 0.000265    Val loss: 0.000208 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 465   Batch loss: 0.000325    Val loss: 0.000206 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 470   Batch loss: 0.000236    Val loss: 0.000204 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 475   Batch loss: 0.000235    Val loss: 0.000202 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 480   Batch loss: 0.000229    Val loss: 0.000200 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 485   Batch loss: 0.000243    Val loss: 0.000198 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 490   Batch loss: 0.000273    Val loss: 0.000196 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 495   Batch loss: 0.000258    Val loss: 0.000194 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 500   Batch loss: 0.000282    Val loss: 0.000192 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 505   Batch loss: 0.000259    Val loss: 0.000190 Val acc: 1.000000\n",
      "Epoch:  1/ 5    Batch: 510   Batch loss: 0.000279    Val loss: 0.000189 Val acc: 1.000000\n",
      "6528\n",
      "Finished epoch 1. Average batch loss: 0.003853913106837581. Average validation loss: 0.0008630759947548131\n",
      "Starting epoch 2\n",
      "Epoch:  2/ 5    Batch: 515   Batch loss: 0.000222    Val loss: 0.000187 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 520   Batch loss: 0.000219    Val loss: 0.000185 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 525   Batch loss: 0.000188    Val loss: 0.000184 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 530   Batch loss: 0.000293    Val loss: 0.000182 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 535   Batch loss: 0.000217    Val loss: 0.000180 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 540   Batch loss: 0.000221    Val loss: 0.000179 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 545   Batch loss: 0.000195    Val loss: 0.000177 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 550   Batch loss: 0.000227    Val loss: 0.000176 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 555   Batch loss: 0.000210    Val loss: 0.000174 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 560   Batch loss: 0.000262    Val loss: 0.000173 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 565   Batch loss: 0.000218    Val loss: 0.000171 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 570   Batch loss: 0.000237    Val loss: 0.000170 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 575   Batch loss: 0.000259    Val loss: 0.000168 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 580   Batch loss: 0.000213    Val loss: 0.000167 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 585   Batch loss: 0.000252    Val loss: 0.000166 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 590   Batch loss: 0.000202    Val loss: 0.000164 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 595   Batch loss: 0.000215    Val loss: 0.000163 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 600   Batch loss: 0.000187    Val loss: 0.000162 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 605   Batch loss: 0.000225    Val loss: 0.000161 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 610   Batch loss: 0.000222    Val loss: 0.000159 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 615   Batch loss: 0.000191    Val loss: 0.000158 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 620   Batch loss: 0.000221    Val loss: 0.000157 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 625   Batch loss: 0.000189    Val loss: 0.000156 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 630   Batch loss: 0.000163    Val loss: 0.000154 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 635   Batch loss: 0.000257    Val loss: 0.000153 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 640   Batch loss: 0.000269    Val loss: 0.000152 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 645   Batch loss: 0.000217    Val loss: 0.000151 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 650   Batch loss: 0.000206    Val loss: 0.000150 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 655   Batch loss: 0.000190    Val loss: 0.000149 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 660   Batch loss: 0.000250    Val loss: 0.000147 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 665   Batch loss: 0.000166    Val loss: 0.000146 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 670   Batch loss: 0.000198    Val loss: 0.000145 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 675   Batch loss: 0.000225    Val loss: 0.000144 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 680   Batch loss: 0.000218    Val loss: 0.000143 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 685   Batch loss: 0.000198    Val loss: 0.000142 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 690   Batch loss: 0.000182    Val loss: 0.000141 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 695   Batch loss: 0.000210    Val loss: 0.000140 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 700   Batch loss: 0.000209    Val loss: 0.000139 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 705   Batch loss: 0.000204    Val loss: 0.000138 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 710   Batch loss: 0.000157    Val loss: 0.000138 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 715   Batch loss: 0.000172    Val loss: 0.000137 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 720   Batch loss: 0.000181    Val loss: 0.000136 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 725   Batch loss: 0.000164    Val loss: 0.000135 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 730   Batch loss: 0.000196    Val loss: 0.000134 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 735   Batch loss: 0.000155    Val loss: 0.000133 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 740   Batch loss: 0.000175    Val loss: 0.000132 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 745   Batch loss: 0.000207    Val loss: 0.000131 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 750   Batch loss: 0.000200    Val loss: 0.000130 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 755   Batch loss: 0.000151    Val loss: 0.000130 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 760   Batch loss: 0.000174    Val loss: 0.000129 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 765   Batch loss: 0.000145    Val loss: 0.000128 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 770   Batch loss: 0.000210    Val loss: 0.000127 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 775   Batch loss: 0.000156    Val loss: 0.000126 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 780   Batch loss: 0.000136    Val loss: 0.000126 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 785   Batch loss: 0.000185    Val loss: 0.000125 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 790   Batch loss: 0.000135    Val loss: 0.000124 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 795   Batch loss: 0.000175    Val loss: 0.000123 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 800   Batch loss: 0.000152    Val loss: 0.000123 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 805   Batch loss: 0.000162    Val loss: 0.000122 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 810   Batch loss: 0.000174    Val loss: 0.000121 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 815   Batch loss: 0.000165    Val loss: 0.000121 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 820   Batch loss: 0.000154    Val loss: 0.000120 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 825   Batch loss: 0.000180    Val loss: 0.000119 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 830   Batch loss: 0.000130    Val loss: 0.000119 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 835   Batch loss: 0.000114    Val loss: 0.000118 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 840   Batch loss: 0.000134    Val loss: 0.000117 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 845   Batch loss: 0.000130    Val loss: 0.000117 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 850   Batch loss: 0.000161    Val loss: 0.000116 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 855   Batch loss: 0.000137    Val loss: 0.000115 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 860   Batch loss: 0.000153    Val loss: 0.000115 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 865   Batch loss: 0.000149    Val loss: 0.000114 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 870   Batch loss: 0.000173    Val loss: 0.000113 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 875   Batch loss: 0.000141    Val loss: 0.000113 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 880   Batch loss: 0.000115    Val loss: 0.000112 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 885   Batch loss: 0.000146    Val loss: 0.000112 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 890   Batch loss: 0.000149    Val loss: 0.000111 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 895   Batch loss: 0.000180    Val loss: 0.000111 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 900   Batch loss: 0.000121    Val loss: 0.000110 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 905   Batch loss: 0.000144    Val loss: 0.000109 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 910   Batch loss: 0.000143    Val loss: 0.000109 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 915   Batch loss: 0.000141    Val loss: 0.000108 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 920   Batch loss: 0.000160    Val loss: 0.000108 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 925   Batch loss: 0.000132    Val loss: 0.000107 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 930   Batch loss: 0.000126    Val loss: 0.000107 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 935   Batch loss: 0.000125    Val loss: 0.000106 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 940   Batch loss: 0.000144    Val loss: 0.000105 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 945   Batch loss: 0.000131    Val loss: 0.000105 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 950   Batch loss: 0.000128    Val loss: 0.000104 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 955   Batch loss: 0.000143    Val loss: 0.000104 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 960   Batch loss: 0.000123    Val loss: 0.000103 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 965   Batch loss: 0.000117    Val loss: 0.000103 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 970   Batch loss: 0.000133    Val loss: 0.000102 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 975   Batch loss: 0.000130    Val loss: 0.000102 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 980   Batch loss: 0.000128    Val loss: 0.000101 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 985   Batch loss: 0.000138    Val loss: 0.000101 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 990   Batch loss: 0.000133    Val loss: 0.000100 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 995   Batch loss: 0.000130    Val loss: 0.000100 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 1000   Batch loss: 0.000126    Val loss: 0.000099 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 1005   Batch loss: 0.000123    Val loss: 0.000099 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 1010   Batch loss: 0.000136    Val loss: 0.000098 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 1015   Batch loss: 0.000105    Val loss: 0.000098 Val acc: 1.000000\n",
      "Epoch:  2/ 5    Batch: 1020   Batch loss: 0.000147    Val loss: 0.000097 Val acc: 1.000000\n",
      "6528\n",
      "Finished epoch 2. Average batch loss: 0.00017576850348177686. Average validation loss: 0.00013248755601803257\n",
      "Starting epoch 3\n",
      "Epoch:  3/ 5    Batch: 1025   Batch loss: 0.000186    Val loss: 0.000097 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1030   Batch loss: 0.000122    Val loss: 0.000096 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1035   Batch loss: 0.000105    Val loss: 0.000096 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1040   Batch loss: 0.000119    Val loss: 0.000096 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1045   Batch loss: 0.000127    Val loss: 0.000095 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1050   Batch loss: 0.000151    Val loss: 0.000095 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1055   Batch loss: 0.000120    Val loss: 0.000094 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1060   Batch loss: 0.000157    Val loss: 0.000094 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1065   Batch loss: 0.000126    Val loss: 0.000093 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1070   Batch loss: 0.000139    Val loss: 0.000093 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1075   Batch loss: 0.000123    Val loss: 0.000093 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1080   Batch loss: 0.000123    Val loss: 0.000092 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1085   Batch loss: 0.000127    Val loss: 0.000092 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1090   Batch loss: 0.000127    Val loss: 0.000091 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1095   Batch loss: 0.000120    Val loss: 0.000091 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1100   Batch loss: 0.000140    Val loss: 0.000091 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1105   Batch loss: 0.000120    Val loss: 0.000090 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1110   Batch loss: 0.000133    Val loss: 0.000090 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1115   Batch loss: 0.000107    Val loss: 0.000089 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1120   Batch loss: 0.000117    Val loss: 0.000089 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1125   Batch loss: 0.000111    Val loss: 0.000089 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1130   Batch loss: 0.000097    Val loss: 0.000088 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1135   Batch loss: 0.000116    Val loss: 0.000088 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1140   Batch loss: 0.000131    Val loss: 0.000088 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1145   Batch loss: 0.000105    Val loss: 0.000087 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1150   Batch loss: 0.000132    Val loss: 0.000087 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1155   Batch loss: 0.000131    Val loss: 0.000086 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1160   Batch loss: 0.000154    Val loss: 0.000086 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1165   Batch loss: 0.000130    Val loss: 0.000086 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1170   Batch loss: 0.000130    Val loss: 0.000085 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1175   Batch loss: 0.000117    Val loss: 0.000085 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1180   Batch loss: 0.000122    Val loss: 0.000085 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1185   Batch loss: 0.000102    Val loss: 0.000084 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1190   Batch loss: 0.000099    Val loss: 0.000084 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1195   Batch loss: 0.000130    Val loss: 0.000084 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1200   Batch loss: 0.000117    Val loss: 0.000083 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1205   Batch loss: 0.000168    Val loss: 0.000083 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1210   Batch loss: 0.000100    Val loss: 0.000083 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1215   Batch loss: 0.000133    Val loss: 0.000082 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1220   Batch loss: 0.000131    Val loss: 0.000082 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1225   Batch loss: 0.000093    Val loss: 0.000082 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1230   Batch loss: 0.000141    Val loss: 0.000081 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1235   Batch loss: 0.000124    Val loss: 0.000081 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1240   Batch loss: 0.000094    Val loss: 0.000081 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1245   Batch loss: 0.000097    Val loss: 0.000080 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1250   Batch loss: 0.000114    Val loss: 0.000080 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1255   Batch loss: 0.000129    Val loss: 0.000080 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1260   Batch loss: 0.000102    Val loss: 0.000079 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1265   Batch loss: 0.000127    Val loss: 0.000079 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1270   Batch loss: 0.000115    Val loss: 0.000079 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1275   Batch loss: 0.000125    Val loss: 0.000079 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1280   Batch loss: 0.000100    Val loss: 0.000078 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1285   Batch loss: 0.000114    Val loss: 0.000078 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1290   Batch loss: 0.000094    Val loss: 0.000078 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1295   Batch loss: 0.000096    Val loss: 0.000077 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1300   Batch loss: 0.000115    Val loss: 0.000077 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1305   Batch loss: 0.000093    Val loss: 0.000077 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1310   Batch loss: 0.000114    Val loss: 0.000077 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1315   Batch loss: 0.000087    Val loss: 0.000076 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1320   Batch loss: 0.000104    Val loss: 0.000076 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1325   Batch loss: 0.000105    Val loss: 0.000076 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1330   Batch loss: 0.000111    Val loss: 0.000075 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1335   Batch loss: 0.000086    Val loss: 0.000075 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1340   Batch loss: 0.000087    Val loss: 0.000075 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1345   Batch loss: 0.000108    Val loss: 0.000075 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1350   Batch loss: 0.000121    Val loss: 0.000074 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1355   Batch loss: 0.000093    Val loss: 0.000074 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1360   Batch loss: 0.000104    Val loss: 0.000074 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1365   Batch loss: 0.000120    Val loss: 0.000074 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1370   Batch loss: 0.000107    Val loss: 0.000073 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1375   Batch loss: 0.000101    Val loss: 0.000073 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1380   Batch loss: 0.000105    Val loss: 0.000073 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1385   Batch loss: 0.000099    Val loss: 0.000073 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1390   Batch loss: 0.000076    Val loss: 0.000072 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1395   Batch loss: 0.000075    Val loss: 0.000072 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1400   Batch loss: 0.000103    Val loss: 0.000072 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1405   Batch loss: 0.000096    Val loss: 0.000072 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1410   Batch loss: 0.000125    Val loss: 0.000071 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1415   Batch loss: 0.000084    Val loss: 0.000071 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1420   Batch loss: 0.000085    Val loss: 0.000071 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1425   Batch loss: 0.000076    Val loss: 0.000071 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1430   Batch loss: 0.000085    Val loss: 0.000070 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1435   Batch loss: 0.000105    Val loss: 0.000070 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1440   Batch loss: 0.000109    Val loss: 0.000070 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1445   Batch loss: 0.000089    Val loss: 0.000070 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1450   Batch loss: 0.000115    Val loss: 0.000069 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1455   Batch loss: 0.000112    Val loss: 0.000069 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1460   Batch loss: 0.000090    Val loss: 0.000069 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1465   Batch loss: 0.000087    Val loss: 0.000069 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1470   Batch loss: 0.000101    Val loss: 0.000069 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1475   Batch loss: 0.000110    Val loss: 0.000068 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1480   Batch loss: 0.000084    Val loss: 0.000068 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1485   Batch loss: 0.000101    Val loss: 0.000068 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1490   Batch loss: 0.000090    Val loss: 0.000068 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1495   Batch loss: 0.000076    Val loss: 0.000067 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1500   Batch loss: 0.000108    Val loss: 0.000067 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1505   Batch loss: 0.000110    Val loss: 0.000067 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1510   Batch loss: 0.000088    Val loss: 0.000067 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1515   Batch loss: 0.000085    Val loss: 0.000067 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1520   Batch loss: 0.000091    Val loss: 0.000066 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1525   Batch loss: 0.000075    Val loss: 0.000066 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1530   Batch loss: 0.000082    Val loss: 0.000066 Val acc: 1.000000\n",
      "Epoch:  3/ 5    Batch: 1535   Batch loss: 0.000088    Val loss: 0.000066 Val acc: 1.000000\n",
      "6592\n",
      "Finished epoch 3. Average batch loss: 0.00010947744496547784. Average validation loss: 7.93054114911657e-05\n",
      "Starting epoch 4\n",
      "Epoch:  4/ 5    Batch: 1540   Batch loss: 0.000122    Val loss: 0.000066 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1545   Batch loss: 0.000086    Val loss: 0.000065 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1550   Batch loss: 0.000085    Val loss: 0.000065 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1555   Batch loss: 0.000075    Val loss: 0.000065 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1560   Batch loss: 0.000083    Val loss: 0.000065 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1565   Batch loss: 0.000096    Val loss: 0.000065 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1570   Batch loss: 0.000122    Val loss: 0.000064 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1575   Batch loss: 0.000073    Val loss: 0.000064 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1580   Batch loss: 0.000087    Val loss: 0.000064 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1585   Batch loss: 0.000086    Val loss: 0.000064 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1590   Batch loss: 0.000089    Val loss: 0.000064 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1595   Batch loss: 0.000070    Val loss: 0.000063 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1600   Batch loss: 0.000082    Val loss: 0.000063 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1605   Batch loss: 0.000079    Val loss: 0.000063 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1610   Batch loss: 0.000080    Val loss: 0.000063 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1615   Batch loss: 0.000058    Val loss: 0.000063 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1620   Batch loss: 0.000084    Val loss: 0.000063 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1625   Batch loss: 0.000086    Val loss: 0.000062 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1630   Batch loss: 0.000088    Val loss: 0.000062 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1635   Batch loss: 0.000095    Val loss: 0.000062 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1640   Batch loss: 0.000074    Val loss: 0.000062 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1645   Batch loss: 0.000130    Val loss: 0.000062 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1650   Batch loss: 0.000096    Val loss: 0.000061 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1655   Batch loss: 0.000095    Val loss: 0.000061 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1660   Batch loss: 0.000091    Val loss: 0.000061 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1665   Batch loss: 0.000085    Val loss: 0.000061 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1670   Batch loss: 0.000092    Val loss: 0.000061 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1675   Batch loss: 0.000083    Val loss: 0.000061 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1680   Batch loss: 0.000069    Val loss: 0.000060 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1685   Batch loss: 0.000084    Val loss: 0.000060 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1690   Batch loss: 0.000080    Val loss: 0.000060 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1695   Batch loss: 0.000090    Val loss: 0.000060 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1700   Batch loss: 0.000102    Val loss: 0.000060 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1705   Batch loss: 0.000099    Val loss: 0.000060 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1710   Batch loss: 0.000093    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1715   Batch loss: 0.000100    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1720   Batch loss: 0.000071    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1725   Batch loss: 0.000067    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1730   Batch loss: 0.000103    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1735   Batch loss: 0.000074    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1740   Batch loss: 0.000070    Val loss: 0.000059 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1745   Batch loss: 0.000084    Val loss: 0.000058 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1750   Batch loss: 0.000074    Val loss: 0.000058 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1755   Batch loss: 0.000086    Val loss: 0.000058 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1760   Batch loss: 0.000082    Val loss: 0.000058 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1765   Batch loss: 0.000068    Val loss: 0.000058 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1770   Batch loss: 0.000062    Val loss: 0.000058 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1775   Batch loss: 0.000083    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1780   Batch loss: 0.000093    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1785   Batch loss: 0.000095    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1790   Batch loss: 0.000116    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1795   Batch loss: 0.000061    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1800   Batch loss: 0.000091    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1805   Batch loss: 0.000085    Val loss: 0.000057 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1810   Batch loss: 0.000063    Val loss: 0.000056 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1815   Batch loss: 0.000074    Val loss: 0.000056 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1820   Batch loss: 0.000072    Val loss: 0.000056 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1825   Batch loss: 0.000095    Val loss: 0.000056 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1830   Batch loss: 0.000079    Val loss: 0.000056 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1835   Batch loss: 0.000056    Val loss: 0.000056 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1840   Batch loss: 0.000074    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1845   Batch loss: 0.000071    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1850   Batch loss: 0.000091    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1855   Batch loss: 0.000083    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1860   Batch loss: 0.000078    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1865   Batch loss: 0.000080    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1870   Batch loss: 0.000067    Val loss: 0.000055 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1875   Batch loss: 0.000084    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1880   Batch loss: 0.000067    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1885   Batch loss: 0.000068    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1890   Batch loss: 0.000071    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1895   Batch loss: 0.000085    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1900   Batch loss: 0.000075    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1905   Batch loss: 0.000059    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1910   Batch loss: 0.000069    Val loss: 0.000054 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1915   Batch loss: 0.000069    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1920   Batch loss: 0.000076    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1925   Batch loss: 0.000077    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1930   Batch loss: 0.000068    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1935   Batch loss: 0.000063    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1940   Batch loss: 0.000073    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1945   Batch loss: 0.000068    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1950   Batch loss: 0.000059    Val loss: 0.000053 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1955   Batch loss: 0.000074    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1960   Batch loss: 0.000058    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1965   Batch loss: 0.000084    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1970   Batch loss: 0.000076    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1975   Batch loss: 0.000069    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1980   Batch loss: 0.000074    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1985   Batch loss: 0.000084    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1990   Batch loss: 0.000063    Val loss: 0.000052 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 1995   Batch loss: 0.000058    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2000   Batch loss: 0.000061    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2005   Batch loss: 0.000077    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2010   Batch loss: 0.000054    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2015   Batch loss: 0.000071    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2020   Batch loss: 0.000058    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2025   Batch loss: 0.000067    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2030   Batch loss: 0.000082    Val loss: 0.000051 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2035   Batch loss: 0.000103    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2040   Batch loss: 0.000092    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  4/ 5    Batch: 2045   Batch loss: 0.000077    Val loss: 0.000050 Val acc: 1.000000\n",
      "6528\n",
      "Finished epoch 4. Average batch loss: 8.094658931412368e-05. Average validation loss: 5.72150006090111e-05\n",
      "Starting epoch 5\n",
      "Epoch:  5/ 5    Batch: 2050   Batch loss: 0.000073    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2055   Batch loss: 0.000068    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2060   Batch loss: 0.000076    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2065   Batch loss: 0.000086    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2070   Batch loss: 0.000049    Val loss: 0.000050 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2075   Batch loss: 0.000064    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2080   Batch loss: 0.000053    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2085   Batch loss: 0.000066    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2090   Batch loss: 0.000066    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2095   Batch loss: 0.000070    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2100   Batch loss: 0.000069    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2105   Batch loss: 0.000050    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2110   Batch loss: 0.000074    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2115   Batch loss: 0.000084    Val loss: 0.000049 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2120   Batch loss: 0.000070    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2125   Batch loss: 0.000056    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2130   Batch loss: 0.000055    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2135   Batch loss: 0.000076    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2140   Batch loss: 0.000056    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2145   Batch loss: 0.000077    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2150   Batch loss: 0.000074    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2155   Batch loss: 0.000067    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2160   Batch loss: 0.000065    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2165   Batch loss: 0.000070    Val loss: 0.000048 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2170   Batch loss: 0.000084    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2175   Batch loss: 0.000099    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2180   Batch loss: 0.000074    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2185   Batch loss: 0.000063    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2190   Batch loss: 0.000070    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2195   Batch loss: 0.000064    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2200   Batch loss: 0.000049    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2205   Batch loss: 0.000062    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2210   Batch loss: 0.000073    Val loss: 0.000047 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2215   Batch loss: 0.000068    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2220   Batch loss: 0.000076    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2225   Batch loss: 0.000061    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2230   Batch loss: 0.000061    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2235   Batch loss: 0.000068    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2240   Batch loss: 0.000060    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2245   Batch loss: 0.000070    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2250   Batch loss: 0.000063    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2255   Batch loss: 0.000069    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2260   Batch loss: 0.000054    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2265   Batch loss: 0.000065    Val loss: 0.000046 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2270   Batch loss: 0.000073    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2275   Batch loss: 0.000048    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2280   Batch loss: 0.000061    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2285   Batch loss: 0.000087    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2290   Batch loss: 0.000059    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2295   Batch loss: 0.000055    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2300   Batch loss: 0.000078    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2305   Batch loss: 0.000072    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2310   Batch loss: 0.000071    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2315   Batch loss: 0.000071    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2320   Batch loss: 0.000058    Val loss: 0.000045 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2325   Batch loss: 0.000068    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2330   Batch loss: 0.000066    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2335   Batch loss: 0.000045    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2340   Batch loss: 0.000060    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2345   Batch loss: 0.000061    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2350   Batch loss: 0.000076    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2355   Batch loss: 0.000064    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2360   Batch loss: 0.000060    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2365   Batch loss: 0.000056    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2370   Batch loss: 0.000059    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2375   Batch loss: 0.000067    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2380   Batch loss: 0.000059    Val loss: 0.000044 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2385   Batch loss: 0.000074    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2390   Batch loss: 0.000055    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2395   Batch loss: 0.000077    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2400   Batch loss: 0.000078    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2405   Batch loss: 0.000082    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2410   Batch loss: 0.000066    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2415   Batch loss: 0.000054    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2420   Batch loss: 0.000046    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2425   Batch loss: 0.000061    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2430   Batch loss: 0.000067    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2435   Batch loss: 0.000048    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2440   Batch loss: 0.000051    Val loss: 0.000043 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2445   Batch loss: 0.000056    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2450   Batch loss: 0.000071    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2455   Batch loss: 0.000046    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2460   Batch loss: 0.000059    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2465   Batch loss: 0.000072    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2470   Batch loss: 0.000053    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2475   Batch loss: 0.000060    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2480   Batch loss: 0.000054    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2485   Batch loss: 0.000054    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2490   Batch loss: 0.000060    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2495   Batch loss: 0.000067    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2500   Batch loss: 0.000058    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2505   Batch loss: 0.000050    Val loss: 0.000042 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2510   Batch loss: 0.000061    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2515   Batch loss: 0.000044    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2520   Batch loss: 0.000063    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2525   Batch loss: 0.000037    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2530   Batch loss: 0.000078    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2535   Batch loss: 0.000049    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2540   Batch loss: 0.000043    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2545   Batch loss: 0.000057    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2550   Batch loss: 0.000069    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2555   Batch loss: 0.000042    Val loss: 0.000041 Val acc: 1.000000\n",
      "Epoch:  5/ 5    Batch: 2560   Batch loss: 0.000054    Val loss: 0.000041 Val acc: 1.000000\n",
      "6592\n",
      "Finished epoch 5. Average batch loss: 6.415359928269027e-05. Average validation loss: 4.499377151269426e-05\n",
      "Test loss: 0.000\n",
      "Test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate a model with pretrained embeddings with fine-tuning.\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Fit and evaluate a model with pretrained embeddings without fine-tuning\n",
    "# YOUR CODE HERE\n",
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(word_ids) + 1  # +1 for the 0 padding\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "\n",
    "model = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, num_layers).to(DEVICE)\n",
    "model.embedding = embeddings\n",
    "model.embedding.weight.requires_grad = True\n",
    "#print(model.named_parameters)\n",
    "# Fit and evaluate a model (without pretrained embeddings)\n",
    "n_epochs = 5\n",
    "# YOUR CODE HERE\n",
    "reviews_train(model, train_loader, valid_loader, epochs=n_epochs, device=DEVICE)\n",
    "reviews_test(model, test_loader, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9803bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "292AMUaQv1v8",
    "outputId": "c2102090-2767-4ab0-d5d2-33490d143afc"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e34b7647139c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m embedding_matrix = make_embeddings_matrix(\n\u001b[1;32m      5\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglove_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     embedding_dim=embedding_dim)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-7a00103c9cd9>\u001b[0m in \u001b[0;36mmake_embeddings_matrix\u001b[0;34m(embeddings, word_index, embedding_dim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_embeddings_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings_file = 'glove.6B.{0}d.txt'.format(embedding_dim)\n",
    "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
    "embedding_matrix = make_embeddings_matrix(\n",
    "    embeddings=glove_embeddings, word_index=vocab_size,\n",
    "    embedding_dim=embedding_dim)\n",
    "print (f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "KNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03829352802b45299b092ec73ffbe49f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13a6debd591544988d322459c85677fe",
      "placeholder": "​",
      "style": "IPY_MODEL_113ca1dac48648688ad6cc6c49aa6f57",
      "value": " 3.14k/? [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "0e2f4b3f9bc04a8c8e529b4a5be9a008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "113ca1dac48648688ad6cc6c49aa6f57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11638d748b2a403c811bf61162c4d8ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13a6debd591544988d322459c85677fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15c088e1d8c74da99f3fb0c955c62875": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_888faf1e019744d8906833d08e8c5bde",
      "max": 881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1f98dd1e5224d76b6b732ea18716213",
      "value": 881
     }
    },
    "1a73d15415be47efbffd40bbb84fe6fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c99bc480b00439eb20565d122e1d060",
      "max": 31962,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5c27deea54c416e9b668457f62ad5a7",
      "value": 31962
     }
    },
    "1c8aa4225399435097dd95237e5724e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f14c080703c4f1e859db27476484600": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22134f7c3292447d8f2998bc44976122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28424ef7db684103a1224dd5e94e018b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29ecece00f374776a89b5ce6e7bdc31d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3486229ed2e4423a9d7e4de9cdd74b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_604053a05295405da7d14ecbde3539f8",
       "IPY_MODEL_c0304393e2884ff2ba7b7f274a1f72e7",
       "IPY_MODEL_a3c46c3b134d4b9fb9934cfd6151a66c"
      ],
      "layout": "IPY_MODEL_f4de580834004ad09b9ddd4cb438e8e4"
     }
    },
    "3515335c7ac54574833cc6fcf50fc797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c5685109af480bbbe592b7081f06cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77692eb292644914b34ad9fba0f3980b",
       "IPY_MODEL_a7ba5003ed9349459582a76d15145cf3",
       "IPY_MODEL_03829352802b45299b092ec73ffbe49f"
      ],
      "layout": "IPY_MODEL_bb10b4d0ccf04b4aa5197970072fa5ea"
     }
    },
    "3bc8c5dd6474418f83245208c073cbd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e7ca544decf448aaa3b807925d4f260": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d82cb59b8824654a21ded08004c01f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3ae8057eca44439950d36d9ec08a987",
       "IPY_MODEL_15c088e1d8c74da99f3fb0c955c62875",
       "IPY_MODEL_7063224fb642434d97546f5f55c706ef"
      ],
      "layout": "IPY_MODEL_29ecece00f374776a89b5ce6e7bdc31d"
     }
    },
    "604053a05295405da7d14ecbde3539f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6dc665dfcc44c02a4fdb349764d1f3a",
      "placeholder": "​",
      "style": "IPY_MODEL_aa995c724d6e48b9bab7e6a96419b3be",
      "value": "Downloading data: "
     }
    },
    "6446fa662a4b40c3b3dd39fe17bba7e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4816d752df349f088eb15d4a8d94475",
      "placeholder": "​",
      "style": "IPY_MODEL_22134f7c3292447d8f2998bc44976122",
      "value": "Generating train split:  96%"
     }
    },
    "65f6c6908d604f1eb196972e7b1c20f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e7ca544decf448aaa3b807925d4f260",
      "placeholder": "​",
      "style": "IPY_MODEL_9030b542946e4327943e74a4fc55f396",
      "value": " 1/1 [00:00&lt;00:00, 12.33it/s]"
     }
    },
    "7063224fb642434d97546f5f55c706ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3515335c7ac54574833cc6fcf50fc797",
      "placeholder": "​",
      "style": "IPY_MODEL_a1993f78862b41aeabd30a5e92a558f8",
      "value": " 1.84k/? [00:00&lt;00:00, 14.0kB/s]"
     }
    },
    "75cdfc780bca4ed38c56ad2b3884e759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6446fa662a4b40c3b3dd39fe17bba7e2",
       "IPY_MODEL_1a73d15415be47efbffd40bbb84fe6fc",
       "IPY_MODEL_c6904de91e2541939601183b9ed97094"
      ],
      "layout": "IPY_MODEL_0e2f4b3f9bc04a8c8e529b4a5be9a008"
     }
    },
    "77692eb292644914b34ad9fba0f3980b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c8aa4225399435097dd95237e5724e7",
      "placeholder": "​",
      "style": "IPY_MODEL_28424ef7db684103a1224dd5e94e018b",
      "value": "Downloading builder script: "
     }
    },
    "7c99bc480b00439eb20565d122e1d060": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f097c2a673345efa5dc5056574f2d17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "885574e0288742f28dc9dd6cc3bcbb5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "888faf1e019744d8906833d08e8c5bde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9030b542946e4327943e74a4fc55f396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "930820d87522448a9f384f823cef1ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96f7ef0a1ced435db2044b7cc0b2cf7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9db1afb3e65e43be93717c57380135d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2a11838bd2e4a37b01b37958fe5e4dd",
       "IPY_MODEL_aa65a8389e724ad0af2879ad52341b55",
       "IPY_MODEL_65f6c6908d604f1eb196972e7b1c20f4"
      ],
      "layout": "IPY_MODEL_b9d6ecdec2da4303b106e1621525188d"
     }
    },
    "a1993f78862b41aeabd30a5e92a558f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3c46c3b134d4b9fb9934cfd6151a66c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd00d4d4c47f422f8dd3581732dd1c0c",
      "placeholder": "​",
      "style": "IPY_MODEL_885574e0288742f28dc9dd6cc3bcbb5d",
      "value": " 3.10M/? [00:00&lt;00:00, 8.69MB/s]"
     }
    },
    "a4816d752df349f088eb15d4a8d94475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6c8c9301391468d8568cdd4af555a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7ba5003ed9349459582a76d15145cf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11638d748b2a403c811bf61162c4d8ac",
      "max": 1448,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_96f7ef0a1ced435db2044b7cc0b2cf7c",
      "value": 1448
     }
    },
    "aa65a8389e724ad0af2879ad52341b55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd3e042646c7428580b2f4dc7e964e25",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afb84b4c7e0946f7a64d4fdb35c3b189",
      "value": 1
     }
    },
    "aa995c724d6e48b9bab7e6a96419b3be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afb84b4c7e0946f7a64d4fdb35c3b189": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3ae8057eca44439950d36d9ec08a987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f14c080703c4f1e859db27476484600",
      "placeholder": "​",
      "style": "IPY_MODEL_3bc8c5dd6474418f83245208c073cbd4",
      "value": "Downloading metadata: "
     }
    },
    "b9d6ecdec2da4303b106e1621525188d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb10b4d0ccf04b4aa5197970072fa5ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0304393e2884ff2ba7b7f274a1f72e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c09c72ec78034334a006ce3684a29412",
      "max": 1276746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb3d59314312417194af36596912f0ee",
      "value": 1276746
     }
    },
    "c09c72ec78034334a006ce3684a29412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2a11838bd2e4a37b01b37958fe5e4dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f097c2a673345efa5dc5056574f2d17",
      "placeholder": "​",
      "style": "IPY_MODEL_930820d87522448a9f384f823cef1ba7",
      "value": "100%"
     }
    },
    "c6904de91e2541939601183b9ed97094": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6e3c67b71ce48d2a24ea54dbf026336",
      "placeholder": "​",
      "style": "IPY_MODEL_a6c8c9301391468d8568cdd4af555a18",
      "value": " 30685/31962 [00:02&lt;00:00, 11829.55 examples/s]"
     }
    },
    "c6dc665dfcc44c02a4fdb349764d1f3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd00d4d4c47f422f8dd3581732dd1c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5c27deea54c416e9b668457f62ad5a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6e3c67b71ce48d2a24ea54dbf026336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1f98dd1e5224d76b6b732ea18716213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f4de580834004ad09b9ddd4cb438e8e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb3d59314312417194af36596912f0ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd3e042646c7428580b2f4dc7e964e25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
