{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1984,"status":"ok","timestamp":1653486694051,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"4pUAKP8dz7vI","outputId":"81a9e849-99f3-46ad-d5b2-462381fe9aa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1652873799597,"user":{"displayName":"Anna Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"Jp5bmFZuNWm-","outputId":"6ea814af-6632-4e83-c523-e68a4391dc24"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssZvGPWfhSEj"},"outputs":[],"source":["!python -m spacy download en_core_web_lg #after running that cell restart the runtime and run everything but this cell"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1653555512229,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"sJTRkmA4z8lr","outputId":"d2421441-9c13-46e4-b5fd-013e14db711a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/DataMining/Data_mining/src/models'\n","/content\n"]}],"source":["%cd drive/MyDrive/DataMining/Data_mining/src/models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEVBt6MALvS6"},"outputs":[],"source":["currentdir =  \"/content/drive/MyDrive/DataMining\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZLiVNl9hwO_"},"outputs":[],"source":["!pip install ray\n","!pip install datasets\n","!pip install demoji"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":4390,"status":"ok","timestamp":1653486747413,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"5maJBJvcdClB","outputId":"9437dd09-2a98-4a7a-c2ea-f4caaa9c3c3e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nmodule_path = os.path.abspath(os.path.join(\\'..\\'))\\nmodule_path = os.path.join(module_path, \"data\")\\nif module_path not in sys.path:\\n    sys.path.append(module_path)\\nprint(sys.path)\\nimport preprocessing\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["from sklearn import preprocessing\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn import BCEWithLogitsLoss\n","import pickle\n","from collections import defaultdict\n","from torch.optim import AdamW\n","import itertools\n","import ray\n","from sklearn.utils import resample\n","import sklearn.model_selection as ms\n","from sklearn.metrics import classification_report\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","import csv\n","from sklearn.metrics import f1_score, accuracy_score\n","import os.path\n","from tqdm import tqdm\n","from functools import partial\n","import psutil\n","import numpy as np\n","import pandas\n","from ast import literal_eval\n","import sys\n","import os\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-qT2c72L43J"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzoJkwgnL6qg"},"outputs":[],"source":["ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total"]},{"cell_type":"markdown","metadata":{"id":"fH2Rz0y3dVWU"},"source":["## ***Basic Neural Network Model***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fm2qVSD2dJSQ"},"outputs":[],"source":["class Net(nn.Module):\n","\n","    def __init__(self, input_size, num_layers, max_layer_size, drop_out):\n","        super(Net, self).__init__()\n","        self.input_size = input_size\n","        self.num_layers = num_layers\n","        self.max_layer_size = max_layer_size\n","        in_size = max_layer_size\n","\n","        self.layers = nn.ModuleList([nn.Linear(input_size, in_size)])\n","        for layer in range(1, num_layers-1):\n","            self.layers.append(nn.Linear(in_size, int(in_size/2)))\n","            in_size = int(in_size/2)\n","        self.layers.append(nn.Linear(in_size, 1))\n","        self.drop_out = nn.Dropout(drop_out)\n","\n","\n","    def forward(self, x):\n","        for layer in self.layers[:-1]:\n","            x = F.relu(self.drop_out(layer(x)))\n","        x = self.layers[-1](x)\n","        x = torch.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSW40gOsI9kl"},"outputs":[],"source":["class NetEnsemble(nn.Module):\n","    #INFERENCE ONLY!\n","    def __init__(self, nets):\n","        super(NetEnsemble, self).__init__()\n","        self.nets = nn.ModuleList(nets)\n","    def forward(self, x):\n","        outputs = []\n","        for net in self.nets:\n","            outputs.append(net(x))\n","        outputs = torch.concat(outputs, dim=1)\n","        outputs = torch.mean(outputs, dim=1)     \n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"4Po55NlbdbxX"},"source":["## ***DataSet Loader***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjG6fTZsTG--"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","import pandas as pd\n","import math\n","import numpy as np\n","\n","def transform_reduce(transformer, reducer, data):\n","        result = reducer.transform(transformer.transform(data.values.tolist()))\n","        #result = transformer.transform(data.values.tolist()).toarray() #Only 600 words in vocabulary... reduction not really necessary ..\n","        return pd.Series(list(result)).values\n","\n","def tfidf_transform_data(source_column, target_column, df_train, df_test, vectorizer, compress_to=300):\n","\n","        #Fit SVD to training data\n","        tfidf_train_data = vectorizer.transform(df_train[source_column].values.tolist())\n","        svd = TruncatedSVD(n_components=compress_to)\n","        svd.fit(tfidf_train_data)\n","\n","        #Transform Data:\n","        df_train[target_column] = transform_reduce(vectorizer, svd, df_train[source_column])\n","        df_test[target_column] = transform_reduce(vectorizer, svd, df_test[source_column])\n","\n","        return df_train, df_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5777,"status":"ok","timestamp":1653486753710,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"3eb3A4pH_zel","outputId":"c0b48f94-96a7-4374-b84d-3bf8a2d10bb1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n"]},{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}],"source":["import string\n","from xmlrpc.client import Boolean\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem.porter import PorterStemmer\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset\n","from string import punctuation\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import sklearn.model_selection as ms\n","from sklearn.utils import resample\n","import demoji\n","import re\n","import spacy\n","from typing import Tuple\n","\n","demoji.download_codes()\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","#!python -m spacy download en_core_web_lg\n","\n","def setup(rem_stop=True, do_stem=True, do_lem=False, split=True, upsample=True, do_emojis=True):\n","    df = load_data()\n","\n","    df['preprocessed'] = preprocess(\n","        df['tweet'], rem_stop=rem_stop, do_stem=do_stem, do_lem=do_lem, do_emojis=do_emojis)\n","\n","    if split is True:\n","        df_train, df_test = split_data(df)\n","        tfidf = train_tfidf(df_train['preprocessed'])\n","        if upsample is True:\n","            df_train = upsampling(df_train)\n","        return tfidf, df_train, df_test\n","    else:\n","        tfidf = train_tfidf(df['preprocessed'])\n","        return tfidf, df\n","\n","\n","def load_data():\n","    dataset = load_dataset(\"tweets_hate_speech_detection\")\n","    df = pd.DataFrame.from_dict(dataset['train'])\n","    return df\n","\n","\n","def preprocess(data, rem_stop=True, do_stem=True, do_lem=False, do_emojis=True):\n","    assert do_stem != do_lem\n","    preprocessed = []\n","    for tweet in data:\n","        if do_emojis is True:\n","            tweet, _ = convert_emoji(tweet)\n","        tokens = tokenization(remove_punctuation(tweet))\n","        if rem_stop is True:\n","            tokens = remove_stopwords(tokens)\n","        if do_stem is True and do_lem is False:\n","            tokens = stemming(tokens)\n","        if do_lem is True and do_stem is False:\n","            tokens = lemmatization(tokens)\n","        preprocessed.append(np.array(tokens))\n","\n","    return preprocessed\n","\n","\n","def train_tfidf(data):\n","    def dummy(text):\n","        return text\n","\n","    tf = TfidfVectorizer(\n","        analyzer='word',\n","        tokenizer=dummy,\n","        preprocessor=dummy,\n","        token_pattern=None)\n","\n","    return tf.fit(data)\n","\n","\n","def split_data(df: pd.DataFrame, test_size=0.2, random_state=17):\n","\n","    df_train, df_test = ms.train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[\"label\"])\n","\n","    return df_train, df_test\n","\n","\n","def upsampling(df: pd.DataFrame, replace=True, random_state=55):\n","    data_minority = df[df.label == 1]\n","    data_majority = df[df.label == 0]\n","    data_minority = resample(\n","        data_minority, replace=replace, n_samples=len(data_majority), random_state=random_state)\n","\n","    return pd.concat([data_majority, data_minority])\n","\n","\n","def tokenization(text: str):\n","    return pd.Series(nltk.word_tokenize(text.lower()))\n","\n","\n","def remove_punctuation(tokens: pd.Series):\n","    return \"\".join([i for i in tokens if i not in punctuation])\n","\n","\n","def remove_stopwords(tokens: pd.Series):\n","    stopwords_list = stopwords.words(\"english\")\n","    return tokens.apply(lambda token: token if token not in stopwords_list and token != '' else None).dropna()\n","\n","\n","def stemming(tokens: pd.Series):\n","    stemmer = PorterStemmer()\n","\n","    return tokens.apply(lambda token: stemmer.stem(token))\n","\n","\n","def lemmatization(tokens: pd.Series):\n","    lemmatizer = WordNetLemmatizer()\n","\n","    return tokens.apply(lambda token: lemmatizer.lemmatize(token))\n","\n","\n","def convert_emoji(text: str):\n","    # convert string to binary representation\n","    binary = ' '.join(format(ord(x), 'b') for x in text)\n","\n","    # convert binary representation to utf8 representation\n","    listRes = list(binary.split(\" \"))\n","    try:\n","        text_with_emoji = bytes([int(x, 2) for x in listRes]).decode('utf-8')\n","    except UnicodeDecodeError:\n","        return text, []\n","\n","    # get all emojis\n","    dictionary = demoji.findall(text_with_emoji)\n","\n","    # replace emojis with text representation\n","    emojis = []\n","    for key in dictionary.keys():\n","        if key in text_with_emoji: emojis.append(dictionary[key])\n","        text_with_emoji = text_with_emoji.replace(key, dictionary[key] + \" \")\n","\n","    return text_with_emoji, emojis\n","\n","def emb_data(data):\n","    nlp = spacy.load(\"en_core_web_lg\") #If you are using colab and this buggs out: Restart runtime but DO NOT install the \"en_core_web_lg\" again.\n","    tweets = data.values.tolist()\n","    nlp.disable_pipes(\"parser\", \"ner\") #remove pipe we do not need\n","    embeddings = [sum([word.vector for word in item])/len(item) for item in nlp.pipe(tweets)] #Takes some time...\n","    return pd.Series(embeddings).values\n","\n","def get_features(df: pd.DataFrame):\n","    df[\"n_mentions\"] = df[\"tweet\"].apply(lambda x: count_user_mentions(x))\n","    df[\"hashtags\"] = df[\"tweet\"].apply(lambda x: identify_hashtags(x))\n","    df[\"emojis\"] = df[\"tweet\"].apply(lambda x: convert_emoji(x)[1])\n","    df[\"emb\"] = emb_data(df[\"tweet\"])\n","    return df\n","\n","def count_user_mentions(text:str) ->int:\n","    return text.count(\"@user\")\n","\n","def identify_hashtags(text:str) -> list:\n","    pattern = re.compile(r\"#(\\w+)\")\n","    return pattern.findall(text)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkczlSvqdLsy"},"outputs":[],"source":["from torch.utils import data\n","class HatespeechDataset(Dataset):\n","    #def __init__(self, dataset=\"train\", rep=\"emb\", emojis=False, hashtags=False):\n","    def __init__(self, dataset, rep=\"emb\", emojis=False, hashtags=False):\n","    \n","        features = [\"id\", \"label\"]\n","        features.append(rep)\n","        if emojis: features.append(\"tfidf_emojis\")\n","        if hashtags: features.append(\"tfidf_hashtags\")\n","       \n","        self.data = dataset[features].values\n","\n","        cleaned = []\n","        for dp in self.data:\n","            point = []\n","            point.extend(dp[:2])\n","            point.extend([np.zeros(self.data[0][i+2].shape) if type(d)==float else np.array(d, dtype=float) for i, d in enumerate(dp[2:])])\n","            cleaned.append(point)\n","\n","        self.data = cleaned\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        ids = self.data[idx][0]\n","        reps = list(self.data[idx][2:])\n","        label = self.data[idx][1]\n","        return ids, reps, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["c5034195ab324e3a998b5561936578d5","f61dd1d3fc9b43d08248a885e390fe32","5a31f852939841f0913c8729c5b527b4","482bf293ea4f45c685a4bd7b06004c02","1200a4ac2dc745b88bec26d7ce718e0a","c30631e2471f44459d0b4f19e71ad958","f36819b434674bf7a4f84c6ed04b9072","d47eb95e8ee641f48ed9c105e7c41585","8cd93b7a0891402bbc4ad6e78e716d76","8871ffdfaf7947f68a67e06fad0d734a","00b424ea20a04179b407cb4762e63606","e49d6fb1b5964cca9f9cd9ae9c200bdf","52fa91b69db84080aae90178cec58f22","14b98a6c023a4baa90fc7672eebc7aba","b1fe768cf5cd4d4e83ffbf04f0cb525f","0cf33e10c7f24ff7a249289a481d00b1","14a2b35cf3e143d18ccb5211ac94e896","518d83c8035d41b2b76e2c36a3d4e36f","15d7e23a0a7b467aa95703d12a312203","1301be2ce7d740359eee40a16ec838b7","6f86f28186f04bad90155312e3178307","5fcdfbff774043e89473e5e72d2682ec","97b70fbd92d34d5f9d04ce5855d78cf9","8d6c1e260645430ea8113ff56e7c2836","0fdb7db4239a4bc89aa571822397dbc9","9020f4c6b2c8439889cd949f250289f3","43895fcf08e44bd88b508b5a872d15d3","6c0b59da8f114338b18c43dbfb99581b","2a34750fff6d409c89a5c824c6881418","d17b73ef7afe4d8b93afaf809473e99f","19b79ceba11e444db56177e868d12ff1","a577ea61f10546d8bc179bcbefbf713d","17db1040c82347c187a235d5f71c3d8b","446ad4db41634458803c4d97737ae7f0","22c68324f1c6495eb3c77fbc888839c7","4681f55d639945918c2204cd01b846b0","3eff738120ac42d4a9164f42afe52609","01582952099443be8999f7be8bb6a6a3","8d84d7bc06234b74b5dc1f44ee0fd8ff","064a4b548e5a44cb8ef82d08995f31d5","8c98f97c169b440495442b60fdcb3370","24c4e08aab45465e8dda6b4bdef82240","bff0663c01084195b176bd5c416f8072","6b80f09d47b44e0ebd55bec5554ac4e7","ea157a5c9c524768b9ab7c0d0d238f73","8d4ae5a866c348e59b411c9fbed24fa1","abbd3372dcb54220bffef2250ceab0a4","4701685f5d9d410ab8924158cc1a135f","90d768e78fd747ff9f0bae9ec60430ce","36c1be22a06e4ec0b45d28b26decef39","a12fe6ebdced4e63b4fa39cee396c472","305700f369b24455a420597c0b58ba82","f90d8e71c253484cab3e6694c09c8705","5fbd47d7afb2407f95c982fc13ee0065","c056696bbcfd42b1870fe7f1418b4441"]},"id":"kDvvijGUV1qx","outputId":"be4c5d0b-707b-442f-8657-adbd9693efc2","executionInfo":{"status":"ok","timestamp":1653486926292,"user_tz":-120,"elapsed":172584,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5034195ab324e3a998b5561936578d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/881 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e49d6fb1b5964cca9f9cd9ae9c200bdf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using custom data configuration default\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset tweets_hate_speech_detection/default (download: 2.96 MiB, generated: 3.04 MiB, post-processed: Unknown size, total: 6.00 MiB) to /root/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b70fbd92d34d5f9d04ce5855d78cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/31962 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"446ad4db41634458803c4d97737ae7f0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset tweets_hate_speech_detection downloaded and prepared to /root/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea157a5c9c524768b9ab7c0d0d238f73"}},"metadata":{}}],"source":["TF_IDF, DF_TRAIN, DF_TEST = setup(upsample=False)\n","DF_TRAIN = get_features(DF_TRAIN)\n","DF_TEST = get_features(DF_TEST)\n","DF_TRAIN, DF_TEST = tfidf_transform_data(\"preprocessed\", \"tfidf\", DF_TRAIN, DF_TEST, TF_IDF)\n","DF_TRAIN, DF_TEST = tfidf_transform_data(\"hashtags\", \"tfidf_hashtags\", DF_TRAIN, DF_TEST, TF_IDF, compress_to=100)\n","DF_TRAIN, DF_TEST = tfidf_transform_data(\"emojis\", \"tfidf_emojis\", DF_TRAIN, DF_TEST, TF_IDF, compress_to=50)\n","DF_TRAIN[\"id\"] = DF_TRAIN.index\n","DF_TEST[\"id\"] = DF_TEST.index"]},{"cell_type":"markdown","metadata":{"id":"akjmOmmZfQve"},"source":["## ***Hyperparameter Optimisation***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHfpY64bfQNc"},"outputs":[],"source":["K = 5\n","\n","kfd = ms.StratifiedKFold(K)\n","\n","train_sets = []\n","dev_sets = []\n","for train_set, dev_set in kfd.split(DF_TRAIN, DF_TRAIN.label):\n","    train_sets.append(train_set)\n","    dev_sets.append(dev_set)\n","print([np.mean(DF_TRAIN.iloc[subset][\"label\"].values) for subset in train_sets])\n","print([np.mean(DF_TRAIN.iloc[subset][\"label\"].values) for subset in dev_sets])\n","print(np.mean(DF_TEST[\"label\"].values))\n","train_sets = [HatespeechDataset(dataset=upsampling(DF_TRAIN.iloc[subset]), rep=\"emb\", emojis=False, hashtags=True) for subset in train_sets]\n","dev_sets = [HatespeechDataset(dataset=DF_TRAIN.iloc[subset], rep=\"emb\", emojis=False, hashtags=True) for subset in dev_sets]\n","\n","vector_size = sum([vec.shape[-1] for vec in train_sets[0].data[0][2:]])\n","\n","test_dataset = HatespeechDataset(dataset=DF_TEST, rep=\"emb\", emojis=False, hashtags=True)\n","\n","checkpoint_dir = currentdir + \"/checkpoints\"\n","data_dir = currentdir + \"/Data_mining/data/\"\n","\n","config = {\n","    \"lr\": tune.loguniform(1e-3, 1e-1),\n","    \"batch_size\": tune.choice([8, 16, 32, 64]),\n","    \"num_layers\": tune.choice([2, 3, 4]),\n","    \"drop_out\" : tune.loguniform(0.1, 0.8),\n","    \"max_layer_size\": tune.choice(list(range(200, 800, 100))),\n","}\n","\n","scheduler = ASHAScheduler(\n","    metric=\"f1\",\n","    mode=\"max\",\n","    max_t=10000, #No time restrictions\n","    grace_period=4, \n","    reduction_factor=2) \n","\n","reporter = CLIReporter(\n","    parameter_columns=[\"lr\", \"batch_size\", \"num_layers\", \"drop_out\", \"max_layer_size\"],\n","    metric_columns=[\"f1\", \"training_iteration\"])\n","\n","result = tune.run(\n","        #tune.with_parameters(train, checkpoint_dir=checkpoint_dir, train_dataset = train_dataset, vector_size=vector_size, K=K),\n","        tune.with_parameters(train, checkpoint_dir=checkpoint_dir, train_sets = train_sets, dev_sets = dev_sets, vector_size=vector_size, K=K),\n","        resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n","        config=config,\n","        num_samples=15, \n","        scheduler=scheduler,\n","        progress_reporter=reporter)\n","    \n","best_trial = result.get_best_trial(\"f1\", \"max\", \"all\")\n","print(\"Best trial config: {}\".format(best_trial.config))\n","print(\"Best trial final validation: {}\".format(\n","    best_trial.last_result[\"f1\"]))\n","\n","#best_trained_model = Net(vector_size, best_trial.config[\"num_layers\"], best_trial.config[\"max_layer_size\"], best_trial.config[\"drop_out\"])\n","nets = [Net(vector_size, best_trial.config[\"num_layers\"], best_trial.config[\"max_layer_size\"], best_trial.config[\"drop_out\"]) for i in range(K)]\n","best_trained_model = NetEnsemble(nets)    \n","\n","best_trained_model.to(device)\n","\n","best_checkpoint_dir = best_trial.checkpoint.value\n","model_state = torch.load(os.path.join(\n","    best_checkpoint_dir, \"checkpoint\"))\n","torch.save(model_state, './nn.model')\n","torch.save(best_trial.config, './nn.config')\n","\n","best_trained_model.load_state_dict(model_state)\n","test(best_trained_model, best_trial.config, test_dataset = test_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-hpNXlKzYs9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653486953861,"user_tz":-120,"elapsed":778,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"}},"outputId":"3f16af62-9213-4704-c9f8-9c63011b0076"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  del sys.path[0]\n"]},{"output_type":"stream","name":"stdout","text":["[31897, 23894, 28409, 3203, 17994, 22185, 30945, 3225, 12242, 25182, 9724, 8877, 6891, 8127, 16993, 11772, 15077, 28402, 19151, 28300, 14185, 14967, 16165, 10892, 20142, 5945, 2770, 19120, 2776, 9198, 10092, 16744, 31709, 21628, 5530, 28827, 17081, 20189, 29862, 24399, 20710, 26026, 4192, 15818, 24205, 15821, 17201, 21670, 1292, 7313, 18175, 21081, 5333, 14749, 23046, 7999, 10690, 10236, 21540, 30571, 17700, 5471, 20610, 27192, 3772, 31083, 6210, 18894, 13162, 14455, 17826, 22641, 17476, 15722, 31431, 26170, 3064, 19567, 29435, 13712, 19106, 19444, 21351, 8467, 1091, 24730, 15806, 27354, 13175, 189, 15521, 7337, 14849, 4249, 21828, 24117, 5214, 4623, 1520, 30213, 26944, 28132, 20713, 26629, 26351, 25161, 24463, 16643, 16400, 283, 7178, 20324, 30245, 23889, 7190, 5808, 29070, 17324, 31177, 17744, 23324, 156, 25966, 15919, 27467, 2753, 5083, 16088, 3056, 24953, 12742, 13079, 10077, 10131, 23198, 16366, 14843, 30512, 10150, 16798, 7958, 6302, 30587, 2710, 6057, 26417, 190, 27796, 4554, 2956, 5308, 2093, 7231, 20231, 6662, 11202, 8642, 21619, 23348, 14562, 20048, 29381, 1488, 5782, 14772, 13289, 15957, 31401, 9462, 18064, 22441, 17779, 28081, 20725, 24224, 8115, 21895, 21923, 16236, 31795, 22972, 21175, 13615, 27662, 733, 10961, 17028, 8284, 30798, 31118, 28035, 18382, 1517, 20010, 16328, 24266, 7801, 258, 17544, 123, 9038, 26860, 22535, 28073, 11810, 30719, 18247, 21520, 19593, 3500, 1919, 3825, 788, 27199, 1779, 22007, 23465, 14075, 24439, 28259, 27829, 19308, 7250, 24288, 7349, 6344, 9484, 29037, 4029, 21304, 25228, 21024, 24954, 8849, 17885, 12672, 26639, 29054, 10812, 30946, 8309, 31661, 11478, 27466, 26885, 31137, 779, 31568, 13771, 8299, 24052, 4098, 21778, 13409, 7675, 29929, 3986, 9140, 28840, 27564, 3737, 12513, 11390, 8795, 16910, 8483, 13640, 19795, 2396, 26729, 17600, 15744, 20572, 7008, 30399, 3593, 17822, 1927, 3309, 180, 31455, 23196, 23703, 22919, 27873, 11389, 31648, 21815, 14292, 25301, 11024, 24664, 903, 21681, 959, 10280, 17997, 25227, 2473, 21392, 8664, 12164, 15650, 27846, 11122, 29069, 17519, 1398, 31419, 19976, 15087, 12776, 20367, 24923, 25088, 11477, 1219, 10929, 814, 16323, 23375, 6151, 19111, 31821, 21150, 11874, 6767, 28907, 19226, 12724, 24259, 8131, 5649, 23536, 10999, 10052, 19785, 11496, 3296, 7983, 17365, 9029, 30485, 31305, 18404, 19569, 21423, 31947, 21246, 13898, 10427, 321, 25315, 19705, 27610, 25339, 9961, 23342, 20992, 14176, 868, 9693, 3364, 5417, 2128, 8204, 7418, 6223, 10586, 9607, 5356, 1977, 26374, 13100, 16131, 12933, 8482, 30449, 2715, 8692, 21136, 3873, 22017, 14160, 16362, 17569, 2382, 18319, 8244, 18797, 16761, 6884, 31317, 20086, 11884, 9208, 6911, 29353, 11032, 3809, 21852, 17870, 23777, 3907, 6771, 12492, 7200, 10984, 28756, 14928, 11608, 319, 8086, 21025, 28847, 3358, 28034, 24476, 30288, 25041, 957, 8462, 26470, 16773, 30988, 10284, 5798, 15372, 29248, 18946, 7848, 27342, 19097, 12556, 11865, 27847, 1088, 29838, 13927, 7696, 2577, 2917, 3588, 2264, 28303, 28817, 8456, 16005, 27373, 15717, 23354, 4136, 13523, 19356, 2673, 15629, 14476, 801, 20064, 21322, 24688, 16622, 16157, 31863, 4431, 12348, 14081, 4999, 20595, 22508, 13071, 18132, 17003, 46, 28208, 10767, 2118, 1853, 29064, 18017, 2731, 11788, 7875, 4435, 8811, 14349, 962, 4852, 8720, 31664, 26772, 882, 18016, 6953, 8873, 15843, 10330, 17262, 4803, 16493, 18511, 17276, 1773, 12119, 12420, 29396, 424, 10346, 459, 5709, 13520, 8264, 22176, 20113, 311, 22908, 14619, 25250, 15065, 16241, 24343, 22846, 17355, 10872, 9689, 3805, 5355, 12980, 18, 3922, 30121, 13150, 16385, 3258, 21441, 51, 13025, 14425, 29093, 13545, 3857, 15857, 12582, 17177, 23659, 26730, 23308, 16116, 12474, 13607, 17486, 16678, 22028, 10688, 5232, 8963, 22570, 26332, 26539, 1214, 31519, 16307, 24789, 31115, 20981, 25678, 6782, 29333, 6709, 17734, 22206, 4471, 458, 30253, 2842, 24520, 31061, 31710, 8217, 28808, 29161, 17089, 20931, 1236, 25001, 8586, 29776, 29759, 14697, 4812, 23672, 5119, 242, 23082, 18951, 26091, 8184, 30895, 23888, 17145, 20043, 17056, 12278, 5780, 8166, 16257, 30794, 10037, 3195, 28751, 25534, 1472, 3837, 13876, 15577, 24678, 21818, 6982, 17589, 29814, 12486, 28804, 14783, 17469, 26393, 31880, 30642, 18947, 26570, 10035, 102, 21477, 29672, 23288, 26704, 8602, 5887, 31031, 18965, 14188, 29797, 28224, 25465, 8910, 28531, 28493, 16471, 18644, 30421, 6469, 22045, 6131, 23315, 26690, 8896, 21909, 27461, 6735, 18533, 1966, 18281, 27914, 14464, 29818, 12870, 958, 31787, 22770, 27306, 17889, 1845, 4939, 22069, 22819, 11982, 20500, 2991, 3410, 30256, 26051, 20796, 15713, 14304, 10199, 11143, 11965, 21425, 4845, 9824, 20734, 23540, 12864, 6146, 7174, 7288, 19762, 8790, 6058, 1533, 18250, 4700, 3883, 31173, 7589, 8889, 13539, 7459, 6432, 23039, 23401, 28889, 1361, 7096, 23272, 26337, 30084, 27534, 1771, 8978, 5392, 24106, 10962, 29005, 11037, 13901, 21750, 6854, 23591, 23076, 22934, 20795, 5236, 6111, 2636, 1059, 17649, 17086, 20381, 25800, 11396, 27477, 14552, 22511, 2286, 11180, 20852, 31528, 4092, 7093, 28588, 18057, 12505, 3830, 3827, 18246, 30670, 11840, 25507, 8647, 9139, 20694, 28389, 21967, 9510, 13383, 27889, 28503, 31194, 9740, 22769, 7654, 31760, 11046, 23849, 5687, 10378, 12661, 6332, 9702, 4601, 29485, 13236, 30908, 17011, 29873, 14972, 6636, 30932, 7583, 24244, 27, 5241, 6308, 8985, 9864, 7558, 22559, 26354, 30526, 14718, 8050, 30591, 28652, 5745, 25081, 29602, 20084, 15206, 6888, 18305, 702, 20769, 22857, 26648, 24146, 12746, 5746, 19987, 1527, 1244, 28718, 6850, 11926, 22097, 12948, 29171, 980, 10738, 26067, 31598, 12863, 11435, 23781, 20452, 27765, 20020, 10887, 9746, 24066, 9425, 26917, 23962, 22415, 1385, 9365, 26022, 20303, 17872, 13087, 10293, 5291, 29989, 22236, 19657, 28111, 11628, 2805, 31459, 16558, 31656, 25876, 282, 15304, 4807, 15666, 26121, 8956, 9397, 18875, 5406, 27375, 294, 3049, 23778, 31677, 22476, 24379, 13373, 4013, 2589, 2398, 9771, 17812, 6703, 21291, 18545, 22355, 1539, 7018, 17558, 2172, 18190, 20247, 26968, 16930, 9585, 30215, 130, 10654, 639, 18340, 23682, 25846, 29921, 9804, 22924, 6892, 17353, 9192, 23095, 28240, 14092, 28497, 17349, 10376, 10792, 5926, 8071, 8444, 14770, 16631, 16483, 8927, 23509, 4704, 28678, 9012, 21985, 15691, 18456, 23693, 5121, 5448, 20300, 333, 5976, 23058, 6012, 5744, 21791, 8529, 8093, 17654, 31563, 29859, 8431, 25939, 18422, 12105, 15420, 3510, 29208, 27601, 21309, 26249, 24976, 21490, 22632, 25963, 11280, 18575, 5566, 31831, 12016, 24169, 14776, 16417, 11819, 18686, 13147, 8121, 20608, 18632, 25370, 19272, 31623, 15010, 5464, 21470, 1857, 14179, 13280, 20133, 11401, 3807, 6649, 7453, 28708, 22032, 7941, 23496, 20126, 28968, 7908, 21381, 29218, 2679, 7881, 16695, 19146, 8250, 31481, 14969, 366, 3565, 18268, 19691, 24794, 6538, 23240, 29884, 1190, 20470, 31955, 17936, 7846, 24773, 26949, 18720, 31001, 31536, 21720, 29676, 5080, 10353, 7629, 25922, 29308, 1097, 10276, 12877, 6514, 15410, 26654, 20866, 30492, 9318, 22827, 28415, 2263, 1578, 4242, 25925, 17721, 5769, 30352, 21232, 23739, 22838, 30709, 18616, 20904, 17667, 24289, 31686, 31191, 28944, 8509, 13070, 23261, 21058, 24623, 18239, 25223, 4457, 3529, 15827, 16282, 31938, 2889, 1106, 11262, 6464, 20958, 8965, 28518, 25214, 11146, 21055, 30739, 29180, 3093, 5125, 4667, 23870, 2520, 10401, 1829, 6389, 29702, 13297, 4121, 2749, 26382, 21176, 8646, 16802, 17125, 19380, 22271, 15088, 6917, 21467, 31140, 17211, 11595, 3716, 1412, 27425, 7078, 31045, 19086, 14666, 15792, 15573, 16774, 23191, 2008, 4805, 25909, 4936, 12996, 24675, 19757, 7763, 19313, 21132, 2627, 10337, 8716, 20544, 16899, 1797, 9037, 23851, 31864, 7482, 27921, 808, 28520, 11646, 27314, 20898, 18307, 17446, 9673, 26504, 28159, 12792, 11456, 28411, 28197, 20044, 31839, 26998, 16563, 14903, 30011, 20340, 12847, 23180, 23416, 14418, 1646, 14207, 9435, 31786, 29511, 13323, 5810, 13767, 14892, 17973, 19818, 28766, 16353, 20514, 22636, 7889, 7684, 5660, 4449, 10603, 24594, 21188, 6583, 23712, 13835, 17128, 29259, 24369, 104, 24388, 10902, 29416, 29573, 17176, 20287, 18999, 24055, 15511, 9830, 30454, 31857, 30973, 6356, 504, 22124, 24342, 14794, 1557, 8416, 22155, 30663, 30574, 8661, 21569, 27651, 20125, 2340, 6078, 30768, 2738, 27678, 8373, 13660, 23917, 22703, 25975, 13662, 19662, 7149, 27332, 22734, 20013, 831, 29414, 1119, 20641, 399, 21333, 23554, 30075, 10241, 31156, 31527, 5444, 19137, 21106, 10618, 18962, 5021, 30456, 20270, 29044, 25450, 29234, 3800, 4357, 13049, 8006, 24821, 23791, 9895, 2606, 28541, 29065, 15356, 26625, 3443, 7719, 30135, 16781, 23497, 19763, 27039, 672, 21000, 15900, 14800, 3590, 28395, 11603, 4533, 22317, 30458, 2792, 1271, 16326, 11160, 29747, 28881, 23345, 8759, 1391, 29501, 5583, 23156, 16364, 3353, 11422, 30648, 23553, 29231, 11783, 9473, 26899, 2884, 27473, 5159, 10286, 11451, 10318, 21416, 19385, 25426, 5301, 28023, 1161, 20337, 9382, 28864, 15570, 29772, 29489, 26075, 10750, 8613, 4571, 10345, 20366, 20022, 28172, 5243, 27159, 19594, 20092, 6105, 31436, 1063, 9238, 31701, 18002, 16318, 18619, 15131, 30727, 7990, 10799, 601, 26769, 29608, 31387, 15275, 14932, 19051, 15901, 16677, 8653, 27813, 26813, 31277, 10076, 31175, 2514, 18394, 19834, 25406, 14278, 29482, 1891, 18668, 2928, 23772, 11313, 21098, 26299, 28012, 25479, 4697, 25178, 11040, 16100, 13454, 6346, 1129, 7465, 19157, 29187, 1168, 22315, 23857, 31092, 1902, 10464, 31854, 5925, 7688, 5442, 29846, 14351, 16422, 23118, 25389, 11541, 2046, 16465, 19255, 5395, 29493, 16309, 6632, 11949, 21975, 21904, 28065, 25377, 14551, 30611, 15243, 16971, 26962, 11923, 6454, 4024, 10222, 2532, 8863, 1721, 21487, 4837, 27084, 24447, 28288, 31356, 20230, 25375, 16089, 17980, 22108, 20491, 29709, 10317, 8433, 16459, 6218, 7372, 1305, 26519, 10755, 7483, 13659, 29250, 29330, 19350, 4373, 23466, 20690, 4039, 25336, 24434, 13873, 27989, 15277, 3823, 778, 18586, 7854, 27129, 20896, 20886, 30600, 15986, 26713, 3960, 4107, 6667, 8553, 13713, 22720, 264, 29328, 6504, 13182, 24911, 28237, 4930, 24955, 23060, 5648, 28897, 5257, 7668, 28921, 9123, 10294, 927, 12636, 245, 23577, 21801, 13701, 30896, 24468, 16256, 1484, 19905, 31293, 24716, 10659, 14872, 18517, 27381, 23941, 26835, 18492, 19865, 2501, 25508, 6721, 15974, 1465, 10303, 6779, 23007, 13449, 6177, 30420, 27782, 20617, 17241, 16190, 35, 18416, 1334, 18760, 2166, 4728, 21002, 9398, 21972, 19740, 30154, 5918, 25910, 23427, 17912, 20223, 19361, 29855, 2750, 10323, 9459, 1686, 12628, 2, 31377, 11977, 24229, 12838, 31316, 13631, 19833, 4234, 10861, 13345, 28358, 5089, 25449, 30588, 28791, 29811, 31180, 8708, 2467, 17922, 29055, 4505, 6447, 7456, 7041, 1775, 10311, 26325, 26662, 12819, 14830, 3416, 15144, 10550, 8562, 7138, 28600, 23331, 24648, 31909, 29340, 15169, 18495, 17403, 1974, 9494, 22555, 16033, 22256, 27303, 23192, 13726, 18045, 14677, 21275, 7994, 24212, 26522, 22629, 18209, 17753, 31601, 8097, 23204, 767, 30860, 13038, 7803, 11314, 28571, 7554, 13262, 29763, 8195, 9649, 11514, 2844, 14267, 18628, 28633, 7162, 21525, 24886, 18582, 3616, 5890, 26805, 31166, 21999, 18645, 4215, 11653, 11993, 24228, 24420, 13829, 14107, 19068, 14951, 17527, 19730, 471, 6714, 14523, 22114, 26677, 19773, 12898, 18229, 11101, 6766, 86, 8197, 20124, 24665, 15504, 11417, 4864, 25881, 18003, 26485, 30865, 7110, 3043, 26558, 2773, 23349, 22434, 16446, 247, 12187, 24130, 23270, 21886, 24577, 26892, 18790, 14822, 12977, 13285, 10536, 24781, 24637, 22700, 28252, 21645, 11230, 17342, 27875, 4706, 28572, 2287, 28330, 14688, 22589, 17330, 31813, 5870, 30419, 21386, 29948, 10917, 24631, 8705, 12091, 26930, 24432, 23292, 14276, 7357, 493, 11817, 13218, 302, 5529, 6140, 7831, 24892, 15274, 31770, 435, 11764, 2410, 6596, 21602, 13709, 3937, 19101, 18984, 1983, 18551, 5852, 2409, 5794, 27653, 12203, 21996, 17184, 8231, 17781, 25353, 16490, 28517, 11633, 22547, 7823, 10078, 23262, 8057, 16443, 13238, 600, 2088, 21861, 27007, 24764, 431, 17635, 465, 3789, 10024, 12319, 15376, 14008, 3996, 17188, 4432, 9903, 29512, 18221, 5097, 1866, 22129, 3692, 2718, 22549, 26612, 23205, 25888, 22893, 22692, 25253, 28748, 17210, 4176, 11411, 1892, 3418, 15089, 28527, 27180, 2457, 14384, 16836, 10341, 23202, 5983, 8178, 25790, 9252, 9044, 12841, 7986, 10540, 28807, 360, 1755, 23218, 2955, 21678, 13920, 3212, 19906, 6937, 29740, 10778, 12221, 15783, 25970, 18143, 17325, 13557, 30243, 25710, 13998, 8313, 26958, 5991, 735, 31838, 23325, 17105, 27136, 3279, 2897, 16500, 14021, 6437, 28202, 8688, 10248, 12994, 31413, 726, 19034, 2135, 2922, 14868, 1976, 27830, 13314, 31827, 10970, 12135, 308, 23311, 22057, 1427, 25190, 29681, 25417, 29911, 4468, 25670, 17805, 5857, 1547, 30199, 8254, 21485, 16953, 12905, 8405, 23483, 17246, 4543, 289, 2289, 5439, 21832, 29472, 1185, 15587, 21710, 30635, 20570, 541, 13067, 23402, 4863, 25283, 7122, 17693, 24833, 10235, 26167, 13882, 11920, 11697, 1468, 30776, 3367, 26487, 14864, 13231, 16397, 17972, 30465, 16711, 25325, 14037, 1463, 1675, 20448, 22542, 29089, 12109, 10340, 172, 4735, 15285, 21927, 28270, 1102, 12507, 9877, 3211, 31834, 12911, 20554, 17231, 14852, 26840, 19464, 3124, 13703, 20977, 24901, 14623, 30952, 6934, 30673, 4541, 4200, 2538, 823, 17590, 29577, 29674, 11311, 13256, 2369, 2588, 15538, 12197, 31828, 2930, 2443, 15494, 23751, 28983, 25981, 4191, 26370, 31040, 15963, 20227, 12591, 29105, 21914, 19457, 7900, 30226, 29673, 21048, 27936, 19523, 13243, 8223, 31495, 10927, 7950, 21982, 4276, 17149, 2905, 30016, 14755, 24134, 15739, 24067, 12665, 14738, 10740, 20812, 28803, 24920, 16827, 29909, 7166, 22642, 7925, 30855, 8427, 10683, 13278, 3672, 29558, 2184, 30992, 31456, 15559, 5235, 25354, 3589, 4607, 3586, 7620, 2911, 12433, 24176, 7944, 14270, 19538, 26792, 24808, 25114, 18126, 10806, 25784, 24135, 27370, 20463, 2445, 24034, 7676, 23956, 20899, 20045, 16473, 15317, 30639, 2836, 21233, 10800, 20117, 1443, 24428, 18429, 29647, 25170, 7039, 8531, 24419, 30920, 30784, 25059, 2050, 2500, 19962, 25767, 26846, 29051, 13929, 23456, 10172, 8158, 27409, 22918, 17448, 40, 18346, 22197, 22159, 6827, 27366, 23924, 7455, 8294, 13015, 7477, 24156, 15233, 29249, 13125, 11447, 5269, 27330, 17924, 29439, 9945, 17481, 3264, 14252, 13388, 31378, 5597, 1555, 1518, 23805, 23506, 707, 31264, 30087, 22651, 22424, 4757, 16042, 1098, 2481, 1595, 7714, 20171, 16404, 17272, 3992, 5534, 2576, 10254, 20135, 18046, 25281, 17098, 9637, 20900, 10974, 19448, 25630, 4372, 22143, 18457, 9021, 15600, 5820, 23701, 3151, 29120, 24367, 22349, 3390, 15102, 4917, 2337, 12508, 16693, 14230, 27537, 15701, 13794, 28401, 19638, 21806, 16027, 10677, 25575, 25962, 6290, 10135, 23690, 13209, 26833, 27053, 7917, 4927, 20687, 9008, 30770, 24962, 30441, 2734, 19124, 19797, 20430, 4542, 23242, 17417, 20887, 21838, 7030, 19694, 10732, 28462, 16684, 13958, 5607, 2516, 12005, 21594, 19927, 26857, 27458, 14073, 24765, 25753, 26293, 3323, 9613, 24563, 10810, 25272, 2655, 31439, 10082, 10267, 479, 25153, 20733, 2417, 21083, 970, 23044, 14401, 26225, 5717, 25256, 29061, 22239, 6198, 17434, 26246, 23884, 8288, 31941, 29781, 19934, 4169, 29945, 26188, 25486, 992, 7590, 17638, 2397, 17631, 13496, 9481, 7395, 27288, 12351, 10641, 9174, 1765, 25245, 26819, 18612, 22381, 18534, 31143, 10905, 18730, 14851, 5763, 31013, 29192, 22794, 20075, 12657, 7756, 4582, 5311, 25262, 2847, 25625, 29378, 12818, 24222, 744, 15545, 25593, 25829, 12045, 9413, 28323, 25628, 21910, 14514, 23278, 26778, 11211, 737, 11952, 6059, 17356, 19973, 12427, 16815, 5210, 26054, 9838, 28539, 3518, 23268, 1198, 9108, 22507, 17837, 26640, 20763, 26579, 21896, 2562, 27083, 22144, 30394, 11676, 12030, 10439, 17019, 18004, 16341, 30820, 7365, 29253, 30807, 17606, 26665, 12608, 29539, 21171, 22533, 1670, 14358, 18514, 4212, 2106, 7602, 4654, 19793, 3820, 2977, 1586, 15992, 13590, 27460, 16398, 16424, 19135, 14343, 6568, 20019, 25971, 10270, 11087, 16057, 8209, 18285, 19881, 26959, 28135, 31163, 18729, 2366, 22837, 30487, 23028, 17648, 8471, 15421, 13537, 2204, 16862, 17277, 31691, 3021, 19406, 14431, 8512, 27563, 4087, 27536, 27969, 139, 5109, 21690, 633, 2258, 21142, 12706, 10043, 16834, 10687, 28471, 10073, 6844, 26027, 18567, 24842, 17347, 20168, 23609, 4384, 6487, 3796, 11408, 3666, 16118, 26798, 27382, 21916, 8045, 17404, 16222, 27018, 26905, 2794, 7072, 6713, 23952, 24750, 2228, 12514, 23280, 17432, 27970, 25984, 1356, 21978, 148, 24185, 14503, 13213, 19286, 6947, 20527, 20106, 9840, 9327, 4464, 29885, 7434, 17395, 29315, 17189, 17974, 4014, 12171, 16764, 30450, 28923, 12885, 23859, 15373, 1749, 2074, 30404, 4283, 13123, 7965, 3297, 4737, 29015, 16229, 8005, 15294, 17498, 8293, 10797, 9291, 22612, 28686, 2290, 7585, 18101, 8039, 4869, 16664, 17317, 18316, 1676, 249, 3741, 26535, 13923, 15507, 16496, 31908, 29658, 13632, 11284, 9803, 6954, 31174, 18412, 23395, 22001, 20163, 7217, 13715, 18931, 25652, 27783, 22728, 22010, 1304, 21814, 15591, 2617, 17099, 30110, 30589, 6576, 21225, 18537, 27106, 28917, 7443, 26002, 24960, 28265, 23666, 9565, 11196, 30127, 16682, 28319, 20581, 4622, 14865, 19238, 29660, 22930, 7262, 21576, 11034, 28941, 27065, 11200, 15860, 30137, 13269, 7575, 18039, 22503, 23404, 9681, 27715, 25931, 3172, 10169, 6694, 7521, 17574, 31472, 9861, 4904, 2012, 19262, 19518, 23135, 30204, 22406, 20619, 31337, 6305, 10940, 8857, 22764, 9337, 19841, 27929, 22727, 20672, 11407, 20444, 11889, 6946, 26394, 5742, 25291, 7528, 28327, 6830, 27515, 23040, 8861, 18971, 18074, 25607, 6781, 21008, 28915, 11848, 7052, 21572, 13680, 22086, 27583, 7867, 5073, 618, 10357, 2628, 12900, 8106, 11154, 16196, 395, 14420, 1877, 25810, 4268, 15187, 12673, 18114, 7927, 11973, 1197, 30854, 191, 30004, 28359, 24620, 13294, 13080, 14259, 3183, 15422, 6956, 17388, 18893, 16627, 8649, 23728, 15482, 28484, 7305, 16479, 19150, 8870, 14817, 2208, 8851, 5930, 12405, 8735, 29924, 30871, 24902, 8569, 9388, 1610, 15345, 27265, 18257, 12358, 15635, 25304, 5909, 8368, 7627, 30030, 28628, 21957, 4506, 17778, 21187, 31789, 21324, 28165, 21902, 6365, 11909, 4687, 19747, 20383, 5009, 14417, 22232, 31773, 16756, 17414, 21190, 14587, 28148, 22582, 13779, 9063, 29581, 22204, 27153, 17391, 4677, 31198, 18970, 24882, 27697, 13569, 31673, 29148, 29146, 25687, 4273, 4625, 28603, 6986, 5973, 4676, 7869, 30412, 25467, 8706, 9433, 30694, 27494, 19368, 29220, 8911, 21406, 16709, 1439, 1491, 4743, 25560, 22779, 6898, 2141, 6590, 13928, 24728, 1328, 14624, 7013, 28156, 31062, 10195, 19249, 24065, 18592, 10715, 17828, 18437, 31213, 26383, 15013, 23757, 3865, 22553, 31327, 5490, 10636, 31055, 15885, 28596, 11208, 25069, 1909, 5712, 22771, 14597, 25097, 25856, 15496, 20519, 20706, 28139, 3661, 6908, 18472, 23679, 22465, 28525, 13777, 7842, 3735, 24848, 9204, 12768, 30844, 22015, 21646, 20864, 9905, 20907, 6802, 4311, 18111, 30297, 11658, 19134, 23942, 29201, 24471, 28097, 31027, 14452, 12839, 19160, 593, 27569, 5849, 21703, 10063, 13031, 31625, 28977, 7002, 3912, 2356, 16943, 2302, 25395, 12239, 14581, 23144, 21656, 20246, 3652, 23866, 6037, 14326, 29810, 16870, 9599, 15048, 4194, 17989, 16101, 7493, 12827, 29579, 21221, 24942, 22759, 8938, 19409, 6354, 21173, 14080, 1624, 28003, 5473, 8814, 1701, 9180, 15484, 29456, 9229, 8364, 31225, 10723, 15049, 26931, 12744, 3848, 7816, 7860, 11320, 18570, 21003, 24841, 29559, 25574, 21731, 12173, 18027, 13428, 24777, 2064, 30380, 21064, 17522, 29992, 31736, 7775, 21243, 26165, 17341, 2855, 30269, 19327, 26190, 30578, 31888, 28281, 22531, 13358, 7771, 19626, 25955, 22091, 15329, 7713, 25515, 27638, 8618, 28608, 16368, 9133, 26836, 19627, 19859, 10906, 15720, 10997, 16178, 28529, 6165, 12718, 26184, 24303, 30391, 4259, 19419, 13736, 3037, 19248, 10365, 28556, 29572, 12551, 27556, 4915, 2976, 29288, 19402, 28431, 1254, 21323, 27686, 7170, 20162, 9657, 14695, 15907, 31207, 7505, 10922, 27253, 26147, 13629, 23212, 9852, 23656, 16886, 30158, 3452, 17457, 2959, 23222, 10031, 28408, 18523, 3254, 8884, 17539, 13971, 26993, 1756, 29123, 9306, 3302, 27950, 3684, 9216, 29792, 7036, 23994, 27923, 25959, 1526, 29523, 2422, 12649, 5817, 3860, 22347, 19550, 19403, 16119, 11185, 22949, 525, 3679, 15389, 14143, 14856, 30063, 5910, 25230, 17421, 14714, 9401, 22711, 23213, 9440, 28857, 23618, 23905, 18134, 3874, 13501, 846, 10060, 28558, 7291, 6444, 4398, 25779, 23281, 1322, 28704, 25355, 17804, 25641, 18341, 21697, 9798, 25452, 9531, 9721, 7092, 13985, 631, 9031, 14047, 23100, 25750, 11236, 27787, 17377, 14109, 16872, 10364, 15877, 13603, 8522, 31004, 30183, 18896, 8817, 29399, 10106, 6053, 13908, 8226, 3560, 19580, 1342, 7542, 27415, 2945, 28615, 2122, 7847, 19315, 23387, 29263, 7808, 3985, 12391, 13346, 25801, 9340, 31758, 3191, 10428, 19445, 2181, 25085, 9113, 22631, 29262, 25873, 11051, 5169, 18902, 30987, 5821, 5369, 20848, 24951, 27773, 17748, 6189, 25798, 6043, 23684, 13554, 17773, 21845, 7229, 26783, 8818, 11535, 18103, 3232, 27940, 1235, 1647, 8571, 31584, 6152, 10627, 16594, 7897, 18934, 31776, 12416, 22923, 24718, 21417, 16314, 6166, 20225, 7734, 21162, 20509, 24933, 13911, 5202, 13367, 11876, 3549, 6250, 22486, 20416, 11263, 23696, 15375, 14085, 23414, 20805, 9742, 7905, 8300, 11552, 10630, 883, 9332, 25758, 16371, 14694, 20952, 7510, 31826, 8848, 20330, 12794, 3754, 1856, 8501, 30392, 29379, 6702, 16502, 2980, 16568, 16699, 18975, 27934, 2535, 31810, 24720, 1264, 16839, 13453, 12943, 2835, 8317, 17651, 31945, 18688, 4968, 5674, 16412, 24075, 21444, 8639, 2278, 4320, 21671, 13338, 28037, 1061, 9188, 15556, 20139, 5577, 19169, 25110, 25857, 14375, 3334, 353, 17835, 31400, 22922, 7514, 16968, 25366, 9463, 28942, 9996, 18921, 17660, 12185, 18717, 23313, 19246, 21201, 2040, 29394, 25861, 21278, 19314, 12658, 4744, 11523, 31634, 287, 9122, 4988, 24191, 15134, 30910, 1249, 7543, 4129, 30171, 6916, 8025, 11830, 12161, 23475, 1502, 11948, 9461, 16327, 7157, 18904, 6095, 20884, 4689, 10166, 1309, 17624, 9110, 8192, 4163, 1212, 20714, 25657, 22120, 18220, 1674, 9573, 16069, 23295, 908, 16349, 3988, 16367, 25404, 25038, 31097, 23734, 28814, 13620, 4714, 31105, 26699, 18847, 4645, 30997, 24406, 21954, 9854, 2140, 13315, 16015, 25744, 31652, 19317, 31659, 19867, 11348, 7271, 15150, 17459, 20423, 24535, 16832, 25233, 19285, 27217, 2777, 15392, 8655, 12707, 7015, 31939, 6659, 6027, 24325, 2357, 12402, 14900, 3332, 405, 23015, 20149, 865, 16873, 2183, 22078, 8333, 24220, 4594, 29390, 8043, 4900, 15247, 22063, 27072, 11551, 9308, 21336, 12225, 3383, 7981, 21651, 27666, 11747, 18070, 4849, 27320, 28709, 23306, 12472, 14306, 18169, 15643, 24423, 18392, 8806, 16218, 13196, 23436, 23982, 23501, 4525, 15892, 11686, 8926, 28256, 11542, 2399, 4753, 13040, 16955, 8318, 20873, 2869, 210, 29196, 4691, 12849, 31357, 16909, 17249, 20248, 8448, 8472, 8466, 4656, 18786, 31819, 26173, 8186, 21614, 24546, 8953, 4285, 18499, 15560, 10777, 15151, 27529, 10140, 25637, 6821, 15339, 24226, 27340, 6391, 15727, 5382, 18365, 25618, 18235, 20167, 396, 14874, 24790, 14765, 31405, 9733, 16151, 14091, 7264, 10138, 8055, 12137, 20688, 5413, 28805, 27202, 6593, 15355, 15858, 7621, 19139, 30568, 7338, 4324, 30381, 31520, 23752, 15070, 3745, 2961, 29477, 22729, 6997, 13566, 15374, 25241, 5339, 21468, 3792, 27938, 31843, 3632, 26300, 20316, 21074, 3530, 15882, 21268, 21029, 11015, 7128, 29052, 2134, 9023, 21843, 5665, 23034, 21979, 28918, 7643, 23430, 23187, 22757, 27348, 19353, 9687, 9676, 14875, 13773, 30453, 15820, 24209, 8540, 10067, 22240, 7306, 17490, 7926, 21080, 5726, 10693, 13288, 19199, 10039, 15930, 693, 29847, 23219, 10476, 6972, 20906, 27244, 23642, 27935, 3847, 17698, 9056, 16662, 5856, 30925, 5567, 1377, 8145, 12004, 19900, 6515, 20667, 24007, 1137, 14405, 120, 23718, 17636, 11581, 508, 21853, 10421, 31572, 25201, 4349, 11204, 17712, 1127, 29869, 10433, 29988, 4493, 2484, 13747, 10594, 27539, 5304, 2222, 28250, 12196, 24968, 20692, 26086, 10399, 30773, 6983, 19417, 6143, 3040, 7457, 25900, 12611, 8624, 11359, 5350, 20220, 18718, 168, 4707, 24184, 1113, 12106, 3919, 7540, 15133, 5994, 3978, 26238, 8742, 17732, 22303, 14942, 9432, 18770, 17340, 31918, 3426, 14938, 12329, 19288, 2638, 16683, 28195, 24175, 12254, 18033, 25481, 16354, 9644, 8794, 18409, 7818, 954, 20598, 14801, 16654, 2542, 21612, 13385, 28760, 1454, 5037, 21527, 2742, 18478, 19682, 6104, 8062, 24752, 6681, 14509, 19318, 14178, 2250, 28495, 18538, 1437, 28629, 17271, 16160, 31270, 7378, 13642, 28663, 13810, 25422, 9534, 26303, 30371, 7845, 5596, 1018, 18834, 23444, 29441, 16145, 12891, 26097, 8830, 30402, 5889, 4893, 1836, 10228, 19700, 15302, 28938, 3730, 824, 5682, 24039, 7600, 15935, 28200, 11590, 17934, 24200, 11661, 26227, 21075, 29853, 27140, 20979, 10474, 29915, 23517, 28639, 26259, 12431, 19541, 17287, 24654, 3230, 29457, 30799, 15988, 15536, 28631, 24609, 8726, 20863, 30538, 13529, 5146, 5283, 19260, 26482, 20663, 24292, 7341, 26994, 1316, 10731, 364, 23569, 3042, 3997, 20905, 5684, 3024, 9719, 26842, 11681, 16022, 5899, 986, 4694, 22829, 18695, 7933, 26016, 21644, 21713, 25615, 24092, 31330, 1425, 10445, 21522, 13217, 31680, 8420, 4553, 21086, 3686, 26848, 18170, 25627, 30961, 21495, 3237, 14708, 18818, 81, 30765, 3961, 17401, 5042, 18258, 31477, 31214, 579, 13560, 8104, 14615, 316, 30227, 20691, 22312, 21866, 7706, 15032, 9202, 16552, 26667, 7799, 6337, 20336, 15839, 15130, 29971, 17874, 20239, 975, 31822, 5165, 9381, 29383, 8403, 9963, 22009, 29976, 11376, 22468, 11751, 17550, 9547, 5811, 17578, 8588, 4371, 24114, 922, 8986, 15652, 1211, 15636, 21539, 30101, 12136, 20830, 26028, 22525, 21338, 21274, 20584, 24284, 8640, 15037, 22182, 26669, 9282, 4196, 7105, 22755, 433, 19022, 12401, 1514, 7738, 21766, 3801, 12062, 23269, 18906, 28468, 23367, 20406, 29314, 1963, 880, 14620, 31924, 3897, 5936, 25706, 26451, 17051, 8060, 13616, 22691, 2695, 1151, 9259, 2619, 7436, 1395, 25617, 7354, 9601, 10047, 16586, 3953, 5066, 14668, 28345, 6132, 7033, 18387, 23767, 24714, 18967, 21551, 29775, 14414, 7097, 29758, 2755, 27994, 18024, 12051, 25152, 22002, 28584, 14009, 14512, 12897, 30043, 23715, 21390, 26904, 194, 31373, 26841, 11739, 31176, 5046, 17896, 25323, 15969, 22475, 5928, 6474, 8623, 4801, 11680, 3312, 31149, 20740, 2203, 5052, 14117, 15223, 13366, 7616, 2242, 25263, 12454, 21850, 13104, 14605, 12813, 12601, 10789, 19206, 16763, 25258, 5535, 220, 26315, 11345, 29794, 30070, 23557, 31782, 5547, 23195, 27109, 1918, 27377, 13028, 7104, 24905, 19932, 31919, 1583, 17833, 15638, 5641, 23675, 15259, 31498, 27147, 4987, 27506, 12396, 13300, 24215, 7, 8792, 6383, 21724, 474, 18037, 26564, 24296, 11002, 3664, 15284, 8297, 24582, 17115, 9900, 4951, 14560, 17095, 21715, 9752, 12159, 25453, 8137, 9967, 4755, 2972, 31948, 14935, 27574, 24059, 23756, 5985, 10091, 30536, 17082, 13020, 2086, 19828, 16735, 29469, 13116, 22056, 14653, 24108, 11864, 11170, 10707, 4662, 13246, 15596, 12415, 26077, 26380, 5059, 21491, 21938, 9047, 23780, 23113, 3201, 28887, 23721, 28605, 29919, 3756, 31804, 7273, 29785, 17864, 28126, 2592, 29159, 14332, 13176, 13377, 5656, 21542, 21897, 30493, 26873, 17630, 12516, 28094, 31619, 5451, 24128, 1944, 29486, 9011, 11307, 29693, 23631, 25982, 20252, 2309, 25302, 11091, 14042, 30853, 21875, 23861, 3649, 28948, 22514, 538, 17068, 3102, 25986, 19896, 7490, 16475, 22546, 17728, 21530, 29153, 27488, 7032, 27249, 7131, 307, 24895, 502, 9175, 22888, 18415, 9385, 11326, 17680, 11512, 8342, 25212, 20901, 14432, 9845, 4350, 7742, 475, 30354, 18109, 2460, 7156, 151, 18178, 29075, 16530, 12338, 31236, 31902, 29779, 15785, 30912, 10697, 16871, 3089, 5371, 16529, 6715, 21987, 1404, 15671, 15443, 7422, 17504, 129, 7084, 30965, 18734, 7150, 30241, 27509, 11151, 26322, 10026, 26288, 26355, 30119, 10147, 6553, 30634, 11206, 31552, 16929, 21178, 27859, 20062, 25504, 28868, 2018, 7885, 19392, 11165, 24612, 11362, 25612, 13924, 944, 26534, 16310, 11132, 9071, 31883, 12504, 17614, 2101, 29807, 1193, 819, 30629, 16716, 12353, 14964, 26403, 17373, 19650, 16023, 18932, 31056, 9541, 10943, 17000, 17222, 30348, 28802, 9292, 13609, 2997, 28506, 13896, 277, 31076, 28264, 28243, 24425, 12650, 24305, 2414, 12668, 10702, 14217, 29589, 21721, 14442, 2900, 10192, 22225, 7918, 7553, 566, 22529, 5237, 23014, 2593, 10356, 1662, 10910, 7639, 22866, 12856, 9602, 26052, 12874, 31713, 29099, 15672, 14919, 17474, 1432, 23533, 9506, 12484, 14488, 18366, 16658, 19054, 10843, 4366, 12950, 5031, 31185, 28601, 22384, 25592, 20983, 1638, 8606, 18441, 1727, 10942, 16303, 28564, 11486, 5968, 9184, 4404, 856, 11125, 20129, 11574, 13241, 28712, 10847, 10545, 13302, 19612, 7580, 12714, 12986, 10694, 27245, 27664, 16838, 18995, 25439, 29316, 3281, 29289, 10971, 3576, 8798, 24910, 13992, 21716, 1373, 14544, 4069, 9942, 5589, 21427, 17707, 338, 654, 11886, 13568, 2639, 29625, 1846, 6079, 2608, 596, 11716, 16660, 26703, 5806, 9800, 15912, 9211, 4611, 16697, 9621, 21050, 14045, 1178, 14527, 5276, 18390, 29012, 31065, 26829, 23532, 24690, 26318, 8632, 26588, 31740, 13512, 19209, 30167, 16734, 29552, 13939, 25580, 23939, 23720, 31063, 24687, 7274, 30342, 9231, 28124, 21199, 11346, 16738, 10714, 6488, 14888, 252, 8366, 28391, 25998, 30533, 6758, 26969, 24852, 6008, 13630, 14643, 5736, 680, 25673, 6461, 8260, 17035, 10561, 29623, 9157, 12929, 2407, 713, 3583, 27013, 18676, 26181, 3969, 11295, 9363, 14426, 7591, 23850, 26210, 8893, 6805, 31347, 25408, 2937, 6938, 3351, 807, 20709, 30168, 5847, 17451, 7678, 5858, 24586, 2411, 26024, 18509, 9269, 8658, 4, 6443, 4411, 25469, 6128, 28559, 11958, 31517, 3427, 3243, 27101, 23549, 14712, 28337, 22877, 6661, 30373, 12436, 3401, 22841, 24248, 1041, 26204, 26330, 8533, 28238, 19701, 21155, 660, 1375, 1761, 21511, 23045, 8674, 18168, 20389, 17847, 23391, 7703, 24497, 29050, 13279, 29755, 6824, 31561, 17838, 17123, 7211, 29729, 15215, 21038, 1777, 18097, 1959, 23563, 23937, 9955, 11072, 29096, 14842, 11918, 23636, 27777, 4211, 8035, 7858, 30735, 6120, 8430, 7532, 8399, 1026, 20857, 17948, 1802, 15092, 371, 13594, 11809, 11152, 14264, 23005, 27611, 14076, 17790, 8221, 27181, 31451, 3538, 214, 5196, 16096, 27380, 24916, 30734, 1140, 4132, 25157, 17747, 1357, 11670, 1521, 17025, 15008, 9330, 1364, 15232, 15212, 1554, 27565, 13271, 7219, 7833, 6408, 25293, 23692, 30751, 24753, 20306, 22191, 9403, 4536, 21976, 25264, 10589, 27785, 4792, 24991, 18596, 13029, 15023, 21148, 14729, 6328, 2649, 25431, 31258, 18876, 13954, 25165, 19727, 20105, 17220, 19452, 29786, 29636, 29088, 23096, 10315, 25932, 9470, 28828, 13397, 16554, 28075, 8198, 19971, 9358, 15975, 22868, 23452, 157, 9400, 13730, 28660, 3222, 1509, 14644, 24904, 23477, 12283, 12192, 14636, 4759, 30309, 30944, 20382, 15645, 22100, 19320, 2158, 8424, 23818, 22157, 4963, 3403, 1431, 4657, 7873, 30754, 1374, 25099, 29701, 11198, 22247, 13727, 11089, 26816, 9373, 20137, 15881, 10624, 16300, 29028, 20296, 13627, 22127, 8008, 11736, 25865, 31243, 29402, 18162, 30777, 11079, 12585, 2768, 9350, 3176, 29326, 1787, 22329, 20031, 1009, 31935, 3585, 28280, 18375, 17252, 15311, 13722, 10880, 8123, 17983, 10573, 23381, 4292, 11469, 27394, 3342, 30601, 1281, 1985, 9876, 17059, 20308, 26605, 5472, 18291, 384, 29549, 23804, 26492, 22573, 2488, 23632, 17759, 24461, 8118, 23355, 28060, 26882, 28533, 11092, 4675, 5079, 2474, 27918, 9419, 16052, 16294, 6707, 11500, 27912, 30436, 14475, 25421, 19536, 25089, 14345, 14319, 28093, 12902, 17300, 19240, 11141, 7767, 21134, 1599, 18674, 25461, 22359, 6193, 18260, 26201, 10605, 29661, 8180, 31142, 298, 16569, 1871, 1210, 10155, 2763, 3300, 17953, 11081, 29369, 7177, 23435, 12205, 8778, 11562, 13351, 25340, 23480, 881, 6482, 1324, 11976, 11139, 225, 4994, 25367, 27360, 764, 7049, 28315, 11278, 15879, 12456, 24778, 26469, 17692, 27480, 16969, 14672, 31523, 22302, 4986, 23998, 25902, 30653, 17485, 7793, 711, 2637, 24094, 12243, 1848, 7327, 9704, 7038, 382, 4160, 4210, 21863, 426, 29876, 31329, 27747, 5961, 12165, 29803, 15097, 18090, 15853, 12388, 205, 22480, 28227, 9483, 15721, 436, 19366, 17385, 17647, 16989, 24754, 16450, 14404, 10170, 7646, 16429, 1874, 6733, 2098, 2311, 17710, 16829, 3951, 5877, 16219, 2127, 4020, 28424, 21266, 6285, 21621, 27958, 19745, 20100, 3599, 21049, 7564, 8387, 781, 11121, 28448, 7450, 1435, 18935, 25211, 13546, 25277, 25893, 19415, 2234, 26334, 1552, 25401, 11175, 5457, 25671, 28759, 10703, 21581, 17209, 14995, 14233, 17268, 20513, 9801, 22275, 31775, 25855, 20370, 17794, 17354, 8824, 2918, 16078, 8932, 7946, 29598, 14570, 28954, 19631, 6561, 31134, 2789, 5591, 10001, 19482, 27514, 29908, 27042, 8775, 13582, 31915, 7027, 10068, 3397, 23882, 21687, 19088, 17017, 31251, 17013, 11224, 31171, 31025, 31219, 17265, 24138, 28140, 11675, 4888, 6879, 27096, 31744, 19830, 17917, 14604, 2303, 5481, 15569, 1881, 19639, 25501, 8556, 22385, 21236, 21054, 16810, 18107, 29230, 26452, 3633, 22004, 27465, 554, 1965, 28379, 4241, 16979, 20594, 14067, 25306, 6853, 2864, 16976, 28516, 19530, 16333, 25004, 31769, 26467, 12008, 17916, 24418, 23875, 877, 20363, 8481, 16436, 4758, 19102, 11875, 17898, 10838, 24380, 17772, 27881, 29954, 14403, 11244, 27992, 2680, 30698, 11009, 16083, 4104, 4367, 7658, 30996, 6203, 2334, 5881, 15383, 4699, 7790, 93, 12140, 6871, 13605, 25863, 17363, 8662, 28880, 22442, 30222, 26974, 11116, 26544, 6625, 31325, 15210, 11021, 19954, 661, 11281, 18624, 12667, 1665, 7348, 15174, 18440, 2735, 23891, 1022, 17859, 18071, 21802, 29155, 12129, 7850, 10370, 11811, 9758, 15126, 29422, 21771, 29276, 12895, 12835, 26220, 11159, 31352, 27386, 16856, 20098, 21375, 22319, 17525, 1948, 7709, 9882, 21812, 29066, 30521, 24028, 20592, 4180, 4362, 2512, 10262, 30021, 24330, 25917, 19369, 27876, 1335, 19778, 17949, 13802, 18956, 15532, 21825, 20894, 16621, 198, 28901, 13491, 12743, 7401, 24178, 5952, 3973, 18829, 31438, 23987, 16779, 7632, 21534, 7108, 3060, 8261, 4914, 20716, 9486, 4557, 11726, 14386, 21317, 26282, 20546, 17109, 3113, 27062, 15862, 6041, 21517, 25851, 23697, 213, 15829, 5050, 23413, 6842, 31020, 12562, 22090, 870, 8098, 6473, 28472, 10866, 2616, 6173, 10811, 25148, 24941, 26489, 23450, 23989, 28959, 520, 26521, 27454, 10136, 2852, 5963, 18910, 15466, 2809, 10977, 20869, 28729, 4282, 5420, 13419, 23440, 9690, 22301, 30994, 5520, 13774, 25675, 15437, 11364, 16297, 10664, 26375, 27518, 25848, 2082, 8821, 5571, 13847, 9116, 29067, 13833, 612, 1864, 23201, 13126, 17472, 19184, 12061, 6995, 22064, 10420, 20680, 20411, 3697, 5602, 15903, 26964, 9554, 3280, 17932, 3136, 322, 18874, 7221, 16765, 6221, 30688, 18031, 29017, 5462, 23454, 30724, 10679, 3343, 18452, 24981, 11519, 21363, 24538, 1780, 9165, 17380, 24255, 9976, 1973, 12814, 10518, 31323, 20433, 21745, 5226, 16003, 201, 26989, 21714, 16389, 31732, 11792, 3492, 4423, 6980, 1650, 8962, 1313, 22049, 15597, 19069, 16293, 31524, 2490, 4382, 7579, 17809, 28963, 5541, 5288, 14195, 15812, 13621, 6341, 30459, 19091, 2171, 11108, 16844, 24168, 21657, 19931, 9452, 27227, 24879, 19829, 27851, 17599, 25381, 10528, 19854, 2624, 21241, 31808, 22696, 25584, 2211, 26378, 1242, 8046, 5805, 31058, 5140, 9154, 29030, 21094, 15516, 13283, 26881, 15864, 15799, 21515, 20274, 27828, 5883, 20146, 30630, 11766, 2246, 10460, 29556, 21399, 20876, 16974, 1301, 16783, 4942, 1719, 27152, 21871, 11812, 23991, 2860, 570, 6547, 3389, 20563, 5348, 29906, 27704, 13204, 3568, 2764, 31375, 28143, 8208, 10790, 30948, 5686, 285, 257, 26444, 17813, 487, 18315, 31545, 25772, 11086, 23356, 8970, 10242, 9792, 21666, 26791, 2527, 25087, 10030, 5145, 18572, 1352, 3359, 12090, 439, 5980, 9115, 12613, 29708, 12962, 6792, 19505, 19755, 10045, 27700, 26927, 2260, 18327, 24294, 4174, 25257, 15064, 16757, 15182, 22898, 22958, 16901, 10056, 31338, 24677, 13654, 13766, 13166, 19679, 30264, 7407, 7531, 443, 8922, 10741, 11398, 14289, 27844, 27293, 27820, 13380, 20821, 27166, 30742, 5825, 22860, 30597, 15932, 12359, 10713, 3336, 19269, 26531, 9299, 18334, 2363, 5953, 5264, 18738, 1897, 17141, 18264, 2822, 28980, 9577, 12683, 18502, 30319, 25440, 24784, 14412, 25437, 20998, 4302, 26831, 27603, 23561, 8100, 21046, 15811, 29246, 23476, 1111, 16938, 5637, 25600, 4576, 2176, 1176, 2231, 30061, 8281, 11790, 21846, 7024, 17921, 29519, 15061, 27711, 11448, 3090, 24819, 29235, 26618, 17299, 27693, 20632, 17561, 24898, 19603, 17827, 18933, 23881, 10208, 25347, 5495, 9818, 29514, 11761, 26336, 3766, 14730, 13972, 5574, 6034, 27703, 22484, 14524, 7737, 16107, 26808, 13160, 2389, 20639, 17070, 13622, 19595, 15478, 25740, 29182, 28613, 17858, 19654, 2823, 9767, 22971, 2990, 12568, 27527, 1360, 18837, 29173, 28163, 10549, 24548, 21951, 14998, 27590, 15407, 14318, 15687, 6745, 15332, 24634, 20036, 7298, 12671, 26292, 23534, 28545, 5051, 2796, 8230, 8266, 27063, 875, 19257, 12126, 1746, 4296, 13849, 17940, 25999, 13945, 11229, 3941, 10455, 30654, 9893, 30686, 11845, 16391, 19503, 29168, 27736, 27737, 15852, 5205, 8324, 2132, 29080, 16857, 25143, 5532, 3496, 22907, 10949, 8305, 10546, 15168, 20457, 5639, 15159, 10180, 10531, 2856, 7187, 2816, 3841, 30049, 6314, 673, 24676, 25313, 14333, 28902, 30888, 17133, 8327, 26207, 408, 3450, 18635, 15855, 7608, 16451, 7970, 18444, 18255, 5056, 15078, 18397, 25018, 9622, 21449, 11329, 28302, 6988, 965, 15929, 20286, 30169, 10632, 13056, 2575, 21823, 20531, 21689, 13488, 22663, 9870, 27305, 23938, 13430, 15035, 16073, 9489, 7175, 6963, 8765, 22516, 5861, 25176, 15433, 15145, 24736, 9576, 16141, 12985, 19780, 9799, 14784, 28432, 2365, 26583, 19622, 18253, 413, 25363, 27299, 15411, 30024, 31720, 13068, 20764, 10440, 16726, 29034, 22242, 30633, 9270, 3314, 28146, 2235, 24351, 1885, 30721, 23815, 10754, 30593, 26083, 4096, 18735, 11805, 30729, 30832, 28407, 22788, 20670, 6774, 25134, 20413, 9371, 5427, 4491, 14976, 18816, 6692, 11588, 14211, 25513, 12080, 5258, 9170, 17899, 23530, 5710, 15221, 8442, 18355, 10957, 7611, 24786, 20029, 13657, 23621, 25958, 10937, 18802, 20604, 28190, 559, 6519, 3850, 15952, 11381, 18961, 10985, 21844, 10385, 7358, 23125, 4867, 23576, 20242, 21114, 27205, 31435, 13535, 30964, 7261, 23109, 19420, 18672, 6190, 27547, 17697, 14356, 7902, 31128, 3266, 9878, 15213, 24001, 28456, 2034, 12859, 14598, 25993, 27675, 31832, 17681, 15828, 30218, 11797, 16142, 11901, 27254, 20826, 2833, 28286, 8000, 17438, 3734, 29074, 24404, 20968, 6450, 11561, 31465, 19055, 15132, 4027, 20750, 16470, 21326, 13957, 23832, 17765, 11410, 6382, 1913, 27031, 24300, 22193, 31873, 4560, 14495, 21090, 20689, 3400, 6594, 26920, 5502, 5738, 12337, 2072, 26136, 18598, 12037, 29691, 7414, 15682, 27387, 8779, 11906, 3420, 10816, 16138, 14994, 9465, 16517, 16117, 19576, 17702, 19060, 18963, 2931, 7216, 12867, 6876, 15769, 4309, 23177, 1712, 11585, 19148, 17653, 11418, 27037, 17311, 12748, 20408, 11625, 25743, 16284, 1849, 31393, 5675, 10585, 30530, 12414, 22999, 25186, 15319, 21288, 3769, 2042, 25334, 20637, 23474, 4884, 1604, 6530, 18587, 4271, 15379, 26491, 15208, 4198, 16439, 10728, 19876, 25005, 30715, 28384, 17008, 4865, 27904, 25425, 27552, 23963, 994, 7872, 3238, 20483, 11857, 26995, 18043, 28882, 29275, 3894, 17216, 9402, 22681, 13295, 9095, 9683, 17217, 9019, 6388, 7158, 21149, 26820, 17839, 21228, 11148, 29542, 27004, 25546, 24357, 29176, 6246, 16715, 17154, 27168, 11483, 8834, 28996, 920, 5799, 4901, 3711, 28972, 26936, 16040, 383, 29084, 13201, 22288, 2830, 22855, 3228, 11778, 21164, 1808, 17565, 2110, 7208, 13163, 15343, 23624, 262, 5504, 31289, 16667, 19080, 21955, 17331, 19192, 24033, 10108, 25445, 22458, 9288, 15237, 2547, 28643, 24149, 31009, 8287, 2666, 15207, 19263, 3854, 16651, 851, 2522, 12564, 9812, 14791, 28481, 2521, 10890, 26516, 18887, 27352, 19127, 25699, 21604, 246, 15387, 26339, 21650, 27708, 25756, 24504, 31928, 1033, 14, 5285, 14719, 19557, 17343, 17622, 15258, 15199, 11576, 19999, 5942, 22616, 15594, 4561, 3625, 6301, 4507, 30547, 21813, 19472, 17368, 3460, 31458, 26525, 18799, 25419, 13077, 3179, 10543, 3932, 9880, 8489, 7236, 17400, 27670, 21370, 28255, 17487, 13541, 28591, 20203, 17296, 7526, 13606, 15209, 18565, 21041, 15474, 27995, 6390, 12361, 26223, 30532, 22460, 26515, 7513, 26681, 8636, 17725, 10856, 2087, 17180, 24118, 13179, 14123, 15488, 29476, 16406, 11106, 8614, 19306, 18825, 24772, 13250, 28671, 30379, 2114, 18779, 18848, 23548, 8983, 12852, 20449, 13708, 14399, 30632, 15869, 6333, 13643, 10224, 24580, 9240, 28487, 10877, 26642, 28744, 4608, 23129, 26490, 24268, 1500, 12264, 15641, 4709, 25597, 21095, 21418, 27730, 26770, 12118, 29821, 2424, 13266, 2529, 1446, 23223, 16386, 13130, 1261, 18571, 19717, 10285, 19180, 10466, 11063, 19634, 18174, 16103, 6291, 19072, 7518, 29301, 16410, 7794, 28818, 11103, 11018, 2506, 19884, 17563, 6738, 15368, 17761, 19665, 11677, 4574, 2381, 30628, 8936, 21546, 31046, 9367, 20859, 19449, 6172, 18885, 18347, 1045, 1878, 25665, 30769, 24992, 17619, 29304, 21878, 26058, 15966, 17603, 28375, 1146, 5103, 6475, 15487, 13907, 24617, 9200, 27493, 12424, 28446, 5192, 20991, 16925, 4945, 9654, 10583, 15548, 5204, 17975, 27826, 7535, 547, 17235, 2306, 22732, 3139, 25039, 9501, 22374, 27596, 20583, 28189, 15358, 22950, 30310, 12660, 4475, 3294, 27869, 9843, 9589, 25470, 30882, 28491, 22994, 18058, 9249, 13854, 27150, 12855, 4721, 12726, 25774, 4638, 14315, 27597, 15310, 22634, 4149, 4730, 17713, 7019, 16002, 10259, 26563, 25372, 10576, 17755, 14531, 24083, 14779, 20112, 1716, 25611, 18728, 12444, 28095, 2659, 27868, 24162, 25713, 31875, 18878, 13965, 27444, 29135, 26914, 16534, 30280, 7400, 29793, 29949, 31222, 19975, 28778, 19516, 6925, 29363, 2496, 28047, 8740, 7114, 8301, 9837, 16458, 14210, 22505, 16712, 27738, 17754, 229, 23965, 30326, 4219, 30643, 6023, 29490, 25220, 10918, 1907, 5933, 7388, 4774, 3971, 14392, 7480, 3320, 9046, 22937, 20492, 2335, 16340, 25229, 30159, 17497, 6949, 22103, 19030, 10036, 10749, 14111, 8478, 21147, 25547, 13813, 1683, 29079, 528, 1855, 27652, 26164, 8372, 18146, 17364, 19845, 15679, 24927, 27727, 12014, 16275, 9989, 31303, 28311, 14621, 1306, 11815, 14825, 31800, 18042, 15533, 5411, 10522, 19801, 17780, 7370, 17067, 324, 13941, 3520, 23912, 17595, 29073, 14374, 21547, 26601, 6205, 17117, 16600, 5391, 710, 3223, 31512, 13755, 3934, 23471, 22990, 3601, 31582, 25853, 2932, 30838, 12088, 7220, 29009, 7316, 3540, 6656, 13984, 23255, 30801, 19204, 18805, 10307, 2798, 28041, 16590, 25, 10559, 19325, 10760, 5765, 5274, 15098, 25314, 3215, 13296, 20128, 29713, 17157, 7751, 12160, 13192, 8901, 20097, 30161, 2674, 24076, 9826, 9227, 19866, 14577, 14796, 12522, 27833, 31161, 11084, 11342, 21502, 6897, 12445, 20944, 25552, 28598, 25591, 20839, 6570, 1758, 24132, 18957, 23749, 9887, 27657, 14990, 13341, 20655, 20996, 15710, 3437, 23407, 21711, 9239, 20585, 30626, 24565, 2156, 16567, 26683, 1620, 4790, 26241, 28112, 9422, 4295, 21986, 2923, 20441, 23558, 5876, 22648, 10925, 24507, 19067, 19726, 23178, 2565, 9936, 1939, 21420, 18034, 983, 10701, 30524, 23848, 12315, 3822, 30900, 29060, 8776, 18776, 26478, 4827, 9333, 8747, 6048, 26737, 29464, 10320, 11026, 2962, 15252, 1461, 22798, 5318, 11814]\n","TEST SET F1 SCORE: 0.7196652719665272\n","TEST SET ACCURACY: 0.9580791490692946\n","              precision    recall  f1-score   support\n","\n","           0      0.982     0.972     0.977      5945\n","           1      0.677     0.768     0.720       448\n","\n","    accuracy                          0.958      6393\n","   macro avg      0.830     0.870     0.849      6393\n","weighted avg      0.961     0.958     0.959      6393\n","\n"]}],"source":["K=5\n","test_dataset = HatespeechDataset(dataset=DF_TEST, rep=\"emb\", emojis=False, hashtags=True)\n","vector_size = sum([vec.shape[-1] for vec in test_dataset.data[0][2:]])\n","\n","best_trained_model_state = torch.load(\"./nn.model\")\n","best_trial_config = torch.load(\"./nn.config\")\n","nets = [Net(vector_size, best_trial_config[\"num_layers\"], best_trial_config[\"max_layer_size\"], best_trial_config[\"drop_out\"]) for i in range(K)]\n","best_trained_model = NetEnsemble(nets)\n","best_trained_model.load_state_dict(best_trained_model_state)\n","best_trained_model = best_trained_model.to(device)\n","label_list, preds, id_list = test(best_trained_model, best_trial_config, test_dataset = test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"-QCe3iDXdf-z"},"source":["## ***Train***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4aZRuiOdNgE"},"outputs":[],"source":["def train(config, checkpoint_dir, train_sets, dev_sets, vector_size, K):\n","    net = Net(vector_size, config[\"num_layers\"], config[\"max_layer_size\"], config[\"drop_out\"]).to(device)\n","\n","    criterion = nn.BCELoss() \n","    optimizer = AdamW(net.parameters(), lr=config[\"lr\"])\n","\n","    nets = [Net(vector_size, config[\"num_layers\"], config[\"max_layer_size\"], config[\"drop_out\"]).to(device) for i in range(K)]\n","    optimizers = [AdamW(net.parameters(), lr=config[\"lr\"]) for net in nets]\n","\n","    criterion = nn.BCELoss() \n","   \n","    for epoch in range(12):  # loop over the dataset multiple times\n","        eval_score = 0\n","        for k in range(K):\n","            net = nets[k]#.to(device)\n","            optimizer = optimizers[k]\n","            train_dataloader = DataLoader(train_sets[k], batch_size=config[\"batch_size\"], shuffle=True)\n","            print(\"LEN TRAIN: \", len(train_dataloader))\n","            dev_dataloader = DataLoader(dev_sets[k], batch_size=config[\"batch_size\"], shuffle=True)\n","            print(\"LEN DEV: \", len(dev_dataloader))\n","\n","            net.train()\n","            running_loss = 0.0\n","            for i, data in enumerate(tqdm(train_dataloader)):\n","                ids, tfidfs, labels = data\n","                tfidfs = torch.concat((tfidfs), dim=1).to(device)\n","                labels = torch.tensor(labels).to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                outputs = net(tfidfs.float())\n","\n","                loss = criterion(outputs.squeeze(), labels.float())\n","                loss.backward()\n","                optimizer.step()\n","                running_loss += loss.item()\n","                if i % 2000 == 1999:\n","                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","                    running_loss = 0.0\n","            net.eval()\n","\n","            preds = []\n","            label_list = []\n","            with torch.no_grad():\n","                for i, data in enumerate(dev_dataloader):\n","                    ids, tfidfs, labels = data\n","                    tfidfs = torch.concat((tfidfs), dim=1).to(device)\n","                    labels = torch.tensor(labels).to(device)\n","\n","                    outputs = net(tfidfs.float())\n","                    outputs = outputs.squeeze()\n","\n","                    outputs = outputs.tolist()\n","                    labels = labels.tolist()\n","\n","                    if type(outputs) is float:\n","                        preds.append(bool(round(outputs)))\n","                    else:\n","                        preds.extend([bool(round(output)) for output in outputs])\n","\n","                    if type(labels) is float:\n","                        label_list.append(labels)\n","                    else:\n","                        label_list.extend([label for label in labels])\n","            print(\"SUBMODEL F1: \", f1_score(label_list, preds))\n","            eval_score += f1_score(label_list, preds)/K\n","     \n","        print(\"ENSEMBLE F1: \", eval_score)\n","        tune.report(f1=eval_score)\n","        \n","        ensemble = NetEnsemble(nets)   \n","        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n","            path = os.path.join(checkpoint_dir, \"checkpoint\")\n","            torch.save((ensemble.state_dict()), path)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UGIXOVftdiTI"},"source":["## ***Test***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4LLqyZLudQyG"},"outputs":[],"source":["def test(net, config, test_dataset):\n","\n","    test_dataloader = DataLoader(test_dataset, batch_size=config[\"batch_size\"])\n","\n","    net.eval()\n","    id_list = []\n","    preds = []\n","    label_list = []\n","    with torch.no_grad():\n","        for i, data in enumerate(test_dataloader):\n","            ids, tfidfs, labels = data\n","            tfidfs = torch.concat((tfidfs), dim=1).to(device)\n","            labels = torch.tensor(labels).to(device)\n","\n","            outputs = net(tfidfs.float())\n","            outputs = outputs.squeeze()\n","\n","            outputs = outputs.tolist()\n","            labels = labels.tolist()\n","            ids = ids.tolist()            \n","            if type(outputs) is float:\n","                preds.append(bool(round(outputs)))\n","            else:\n","                preds.extend([bool(round(output)) for output in outputs])\n","\n","            if type(labels) is float:\n","                label_list.append(labels)\n","            else:\n","                label_list.extend([label for label in labels])\n","            if type(ids) is float:\n","                id_list.append(ids)\n","            else:\n","                id_list.extend([id for id in ids])\n","    print(id_list)\n","        \n","    f1 = f1_score(label_list, preds)\n","    print(\"TEST SET F1 SCORE:\", f1)\n","    acc = accuracy_score(label_list, preds)\n","    print(\"TEST SET ACCURACY:\", acc)\n","\n","    print(classification_report(label_list, preds, digits=3))\n","\n","    return label_list, preds, id_list\n"]},{"cell_type":"markdown","source":["#Error Analyse"],"metadata":{"id":"nv-Vka5omtl8"}},{"cell_type":"code","source":["def bias(word):\n","    a = DF_TRAIN[['label','tweet']].values.tolist()\n","    a = [item for item in a if word in item[1]]\n","    try:\n","        return sum([item[0] for item in a])/len(a)\n","    except Exception:\n","        return None\n","\n","\n","FPs = []\n","for i in range(len(preds)):\n","    if label_list[i] == 0 and preds[i] == 1:\n","        FPs.append(DF_TEST.loc[id_list[i],[\"tweet\", \"preprocessed\"]])\n","\n","TPs = []\n","for i in range(len(preds)):\n","    if label_list[i] == 1 and preds[i] == 1:\n","        TPs.append(DF_TEST.loc[id_list[i],[\"tweet\", \"preprocessed\"]])\n","\n","\n","FNs = []\n","for i in range(len(preds)):\n","    if label_list[i] == 1 and preds[i] == 0:\n","        FNs.append(DF_TEST.loc[id_list[i],[\"tweet\", \"preprocessed\"]])\n","\n","TNs = []\n","for i in range(len(preds)):\n","    if label_list[i] == 0 and preds[i] == 0:\n","        TNs.append(DF_TEST.loc[id_list[i],[\"tweet\", \"preprocessed\"]])\n","\n","fp_tokens = []\n","print(\"\\n\\n\\nFALSE POSITIVES:\\n\")\n","for fp in FPs:\n","    print(\"========FP=======\")            \n","    print(fp[\"tweet\"])\n","    fp_tokens.extend(set(fp[\"preprocessed\"].tolist()))\n","\n","tp_tokens = []\n","for tp in TPs:\n","    tp_tokens.extend(set(tp[\"preprocessed\"].tolist()))\n","\n","a = sorted([[item, fp_tokens.count(item)-tp_tokens.count(item)] for item in set(fp_tokens)], key=lambda x: x[1], reverse=True)\n","print([[item[0], item[1], bias(item[0])] for item in a[:100]])\n","\n","\n","fn_tokens = []\n","print(\"\\n\\n\\nFALSE NEGATIVES:\\n\")\n","for fn in FNs:\n","    print(\"========FN=======\")\n","    print(fn[\"tweet\"])\n","    fn_tokens.extend(set(fn[\"preprocessed\"].tolist()))\n","\n","\n","tn_tokens = []\n","for tn in TNs:\n","    tn_tokens.extend(set(tn[\"preprocessed\"].tolist()))\n","\n","\n","a = sorted([[item, fn_tokens.count(item)-tn_tokens.count(item)] for item in set(fn_tokens)], key=lambda x: x[1], reverse=True)\n","print([[item[0], item[1], bias(item[0])] for item in a[:100]])\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nrm6ALUpdw1I","executionInfo":{"status":"ok","timestamp":1653492560613,"user_tz":-120,"elapsed":13502,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"}},"outputId":"2deea4d8-1406-4c2f-8615-1f234501eb6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","FALSE POSITIVES:\n","\n","========FP=======\n","bihday sexy girl anal granny movie  \n","========FP=======\n"," @user #schools should produce  , healthy and productive people. forget #exams, #handwriting and facts. @user @user #fant\n","========FP=======\n","a good old fashioned public shaming is in order. \n","========FP=======\n","@user @user @user  from #bbuk have same outlook on a relationship  \n","========FP=======\n","@user plz don't u dare forget @user majority @user vote against #gunsense bills 4 @user long $$! @user @user \n","========FP=======\n","#orlandonightclubshooting disgusting   #shocked \n","========FP=======\n","@user @user @user i find this rather disappointing, liked the black suit.  \n","========FP=======\n","@user woke 2horrific orlando news.i don't give a fuck if you r straight or gay orgoblins with blu hair. no 1 deserves this #orla\n","========FP=======\n","xbox one reverses drm! angry rant pt.3 #video #xbox #one #reverses #drm   #rant #sverigesweden\n","========FP=======\n","father lying through his ass. #terrorism #homophobia #orlando #killings   #bad #evil #religitards #lie  \n","========FP=======\n","please note this story is fake! (read the comments) \"africans are lazy good at sex theft\" - #hillarydesperation   \n","========FP=======\n","slime invasion    #lol #ios   #videogames #indiedev #reddit #retweet #gamer #crowdfunding #games #apple\n","========FP=======\n","#story #294 - the #baker and the #narrator #onestoryaday #amreading #amwriting #reading #agn #argument #fight   \n","========FP=======\n","@user why do you always have to slurr ppl. every time! every!  im suprised you havent called me a racist   \n","========FP=======\n","@user this is a shockingly   and increasingly #violent #world we live in and the #uk has gun control laws. i feel for the mp'\n","========FP=======\n"," @user why is your mother friending your ex on facebook? if you wanna homewreck, involve only yourself    #teaandshade ht\n","========FP=======\n","@user you're right, we do need education reform seeing as you failed at reading comprehension several times now.   #pathetic\n","========FP=======\n","thinking maybe i should have bought @user instead of @user   #gettingold #becomingboring #notborderlands #goblizzard\n","========FP=======\n","@user with @user only being a matter of weeks away:  #pridemonth #pride #londonlgbtpride #exc\n","========FP=======\n","it's called prostitution #justsayin #iknowthingsuthinkidon'tknow #getajob #knowurwoh #morals #itget'sold #that'snotalife #uhaditall  \n","========FP=======\n","college kids at a graduation celebrate in #iran along comes morality police &amp; punish them 4 being   #99lashes \n","========FP=======\n","unbelievable that #akrotiri and #knossos arguably the oldest european cities are not @user #worldheritage sites  \n","========FP=======\n","@user it's sad that a comedian can debunk your bs you spew out on cnn regarding guns  \n","========FP=======\n"," @user @user @user  unfounately, current #gop only see #reagan like this now...  ! \n","========FP=======\n","sex blonde free online white girlvideo porn black step dad  \n","========FP=======\n","@user @user why did you omit his previous 2 tweets that had plenty of empathy?  you too are a #sleeze not to mention a #liar.  #\n","========FP=======\n","racism is still alive!   #huful\n","========FP=======\n"," @user nah, i ain't jewish, i just don't dig on swine, that's all \n","========FP=======\n","slapping porn irish girls pussy pics  \n","========FP=======\n","i do not understand at what point @user will stop giving aiime to racist jeffrey lord. i don't get it @user @user #cheap  \n","========FP=======\n","@user anyone who suppos clinton on a feminist basis only cares about white centered feminism and that's disturbing and disgustin\n","========FP=======\n","@user @user @user @user you're a   #lonewolf who'll probably snap 1 day! go #kill something. you're a #hate #merchant\n","========FP=======\n","what happened to #humanity   \n","========FP=======\n","@user @user @user   #yes lol omg\n","========FP=======\n","@user @user mustbe in #denial reince. #gop &amp; #rnc willbe leftin dust-bin #of history b/c of #trump!  ! \n","========FP=======\n","@user @user @user not sure you understand what bigotry is.  \n","========FP=======\n","@user i guess you don't actually get paid by @user you just pretend to be a journalist.   #corruption\n","========FP=======\n","so the lily white liars of the #lnp do not tolerate corruption!! except if it #lnp #corruption! #deceitful   \n","========FP=======\n","#dumbest repoing of the day @user did everything they cld 2 blame   #crazy #whiteguy w #legalgun instead what it is #islamicterror\n","========FP=======\n","#immigration in #europe today.   #ramadan! \n","========FP=======\n","@user sick sad concept is that majority of women woman don't want her to be president b/c of gender and she's democrat #ohio  \n","========FP=======\n","wow, this #violence needs to stop    \n","========FP=======\n","#bahrain   #youth #protesters #clash with #riot #police and  #armoured #vehicles # # \n","========FP=======\n","diabetes,  cancer, pneumonia,  kidney disease, hea disease ,,, what the heck is keeping this poor man alive?  \n","========FP=======\n","women used to be responsible for men's behavior.   \n","========FP=======\n","@user @user are you being spiteful, did you see my last tweet. this is my is that helpful look   \n","========FP=======\n","senate #gop drops push to defund #obamacare    \n","========FP=======\n","so of assumed @user would have a deep yinzer accent. apparently not.  \n","========FP=======\n","#whitewash quite literally   \n","========FP=======\n","i thought lesbians were suppose to be good at oral.  \n","========FP=======\n","@user if they could vote us out, they would.  \n","========FP=======\n","@user see my previous tweet. all #leavers are now muderous racist savages according to polly. had enough today going to bed.  .\n","========FP=======\n","so @user could not simply delete flagged vids? reinstate @user account of @user  \n","========FP=======\n","what the fuck man this flopping ass nigga!#word  \n","========FP=======\n","when will ghana stop flooding?   \n","========FP=======\n","why '2day' and not 'today'? does our queen not deserve a message in the queen's english? #justhelping \n","========FP=======\n","you   for 1968 @user in @user iii? #checkout @user aicle on its #culture ? #gamemusic - \n","========FP=======\n","500 post at #arff2016 @user  name change &amp; super \n","========FP=======\n","@user @user @user ppffttt used none of my puns. #punfail   #lasttimeiwingit\n","========FP=======\n","@user let me chill and do this  \n","========FP=======\n","@user @user @user @user the mayor is nothing like @user - can't one defend against false attacks?  \n","========FP=======\n","black men hate on black women the most!   ... so do y'all hate y'all mommas too? \n","========FP=======\n","  #juneteenth, our #annual #celebration of the end of #slavery -  \n","========FP=======\n","stfu bitch , if u have anything against me or wanna talk shit about me , then come to my fucking face bro #bitch  \n","========FP=======\n","study history, @user a #gop president spawned #isis. fearing you'll be booted, you're desperate; you play the \"#trump\" card.  \n","========FP=======\n","bihday to me .\n","========FP=======\n","the bear has attempted to kill himself from the the 4th floor..  #suicide   #livestream \n","========FP=======\n","@user @user @user @user i don't think it's that. sma progressives are revolted by her. but some ju\n","========FP=======\n"," @user what bitches need to do is goto back to school , dropping out to lay with niggas   !!\n","========FP=======\n","@user seriously? what next? calling out for the pope?   #sick \n","========FP=======\n","@user #poppetmaster simon cowell still unable to accept his own or his aists' homosexuality?   \n","========FP=======\n","@user accepting unceainty: we can be   without all the answers @user  #mindfulness ht\n","========FP=======\n","#humanrights #women don't have a voice in south asia  \n","========FP=======\n","to the guy sitting beside me: you're mansplaining your apple watch to me, while i'm wearing one.  \n","========FP=======\n","#justice has a way of doing that  \n","========FP=======\n","@user @user @user invoking #hitler because you're losing the #debate   what was #wwii fought for? \n","========FP=======\n","@user give us a \"w\", what, people are moving?  give us an \"i\"!  what? stick my #blueballs up my what? no fun here #blueballs  \n","========FP=======\n","@user @user watching this  ! congressman parse his words re: tr*mp, his own pay, racism is giving me life!  #schadenfreude\n","========FP=======\n","5 years is not enough. hanning is accused of bein an accessory ta the murder of 170,000 people in auschwitz. an ss guard from 1942-44  \n","========FP=======\n","@user how did you slip through?  you are a threat to america  ! #bigotry #misogyny #ignorance #alwaystrup @user\n","========FP=======\n","@user another sad thing about #brexit &amp; #eureferendum is that a family is destroyed &amp; 2 kids left without a mum #disgusting  \n","========FP=======\n","@user @user @user   #thnkz 4 ua  commitment as u retire from chief justice  #  bihday\n","========FP=======\n","@user @user  mate try addressing my argument rather than #trolling me? #staups   #rude\n","========FP=======\n","@user i was made an honorary poll worker by gretchen knauff and connecticut p&amp;a!   #itslikebeingknighted #ndrn2016 \n","========FP=======\n","@user #sellout i fully expect her to change her stance on tpp as well! #sodisappointed #twofaced #clayfeet   \n","========FP=======\n"," @user the question isn't who is going to let you, it's who is going to stop you! @user @user #positive\n","========FP=======\n","nobody, and i mean nobody, out-stupids @user like #trump. this how #whaon taught you to count?   \n","========FP=======\n","@user is this where you're going? \n","========FP=======\n","watch \"elizabeth warren endorses hillary clinton\" on youtube -     #betrayal #feelthebern\n","========FP=======\n","quack quack quack fuack quack quack     #duck #quack #animal \n","========FP=======\n","this world is so fucking racist  (they asked the manager at wells fargo for here social security number just because she sounds mexican) \n","========FP=======\n","#towerofboleme #pougal all countries have sacrificed in #war   \n","========FP=======\n","@user what pa of \"no mayo, no oil\" was not clear? here they both are oozing out #gross #unhappytraveler   \n","========FP=======\n","@user i am increasingly angered by the leave campaign.   #stupidity #blinkered #lostforwords ########## \n","========FP=======\n","@user @user lol...since you're not voting or not voting 4 hillary or trump why say anything...oh never mind i...i know  \n","========FP=======\n","@user i'm so sorry that in this day and age people can hate so much to kill. just because of their sexuality,religion or colour.  \n","========FP=======\n","@user @user @user @user @user @user i yet to kill them is ok?  \n","========FP=======\n","wtf cares abt him as a father he's a racist ass clown why r u giving him free press @user   he's the poster child of hate #tmzlive\n","========FP=======\n","that's not diversity, you dipshits! \n","========FP=======\n","@user #lgbtqhatestrumppay i guess we are done with #loveislove and #peace intead we spit hate on someone on his bihday t\n","========FP=======\n","@user @user a muslim friend of mine told me if his young son ever came out as gay he would never speak to him again   #shocking\n","========FP=======\n","#leadership 101.  this weekend is a good time to happy out &amp; hack your neighborhood w/ the   virus on   #locally\n","========FP=======\n","nude sexy amature girls fucked hardly   monkey sex  \n","========FP=======\n","what a splendid #nosie,   me, probably not this #year #wrc #rallypoland @user @user \n","========FP=======\n","i'm actually really #hu. a game i once loved is totally fake. to the @user be careful, it's getting obvious and truly   #nbafinals\n","========FP=======\n","it happened, folks.  do you think desensitization is a myth? #orlandoshooting \n","========FP=======\n","instead of explaining his positions to those he disagrees with @user blocks them.  . #climatechange #leadership #wws #renewables\n","========FP=======\n","horny australian women   pussy  \n","========FP=======\n","this makes me   to answer your question @user - all of you &amp; all of these moments \n","========FP=======\n","why would there be any reason to call @user out of her name? haters!!!!   #sistahsgetit2gether \n","========FP=======\n","this is the secret sauce for   employees  #productivity #leadership #management\n","========FP=======\n"," @user study history, @user a #gop president spawned #isis. fearing you'll be booted, you're desperate; you play th\n","========FP=======\n","@user you're a great talent but just an idiot on political and social issues.   #learnwhyamericaisgreat\n","========FP=======\n","we think greg is   with his order. don't you?    pls keep voting for \n","========FP=======\n","#russian default position when faced with accusations of doping,violence in #marseille,barrel bombs on hospitals in #syria is to lie !  \n","========FP=======\n","#trump: #obama '#was more   at me than he #was at the #shooter' \n","========FP=======\n"," @user if the gorgeous day isn't resonating on the inside for you, give us a call.  there is such a thing as summeime blues\n","========FP=======\n","(the huffington post):  woman drops f-bombs on 'dodgy dave' cameron at buzzfeed #eu.. \n","========FP=======\n","@user @user @user @user and you're profiling based on looks? isn't that illegal? #butthu   #feelthebern\n","========FP=======\n"," @user if you do not suppo #equality, #womensrights, #reason, #education, #truth, #science, or critical thinking, then vote\n","========FP=======\n","isis burns alive 19 girls, feminist in the west complain about mythical patriarchy and wage gap.   #factsoverfeelings #altright\n","========FP=======\n","#peoplefeelvoiceless #disenfranchised   #injustice #inequality #division #vacuum is created #filled by oppounists #notinmyname name\n","========FP=======\n","see you this christmas hahahhaha \n","========FP=======\n","what a   way to treat who are under the fairuse policy. #wtfu \n","========FP=======\n","@user so your intelligence is picking out typos on twitter then giving yourself a congratulations wank because you told em  \n","========FP=======\n","@user @user @user @user amazing comment. google dunning-kruger effect. see if u see yourself. probably not.  \n","========FP=======\n","@user you should probably read this account. this is our candidate? i'm mod-right &amp; i'm not voting for this guy.   \n","========FP=======\n","@user @user if they want reelection money. #ksleg  \n","========FP=======\n","#shabbat #shalom &amp;   #holiday!  the #torah was given to the #jewish people on #mount sinai \n","========FP=======\n","i #would rather be aiiight than  .\n","========FP=======\n","preach pres preach  \n","========FP=======\n","@user @user @user is on the other side of history and our allies on this issue.  #embarrassing  \n","========FP=======\n","turkey threw in the towel against spain, says  #spos #_towel_ #against   #coach \n","========FP=======\n","who has two thumbs and a new job? this girl!  \n","========FP=======\n","@user i cant believe that the @user account of @user is supsended! seriously @user are you fucking kidding me\n","========FP=======\n","@user punching things&gt;&gt;   #ihateschool\n","========FP=======\n","can ppl #change? husband called me a \"fucking bitch\" &amp; a \"cunt\" yesterday. is this #abuse? #emotionallyscarred #worried  . now what?\n","========FP=======\n","#bbuk line up has to be worst ever. bunch of z listers. thought this was for general public? absolutely no eye candy for girls or boys.  \n","========FP=======\n"," @user stop looking for reasons to be unhappy. focus on the things you do have, and the reasons you should be  . @user #wedn\n","========FP=======\n","@user warning: ladyzaradurose on @user is not me! it's someone impersonating me and using my information.  someone needs a l\n","========FP=======\n","@user new post! self love is impoant!  @user @user  #mumlife #socialanxiety #blog   #\n","========FP=======\n","you've got nothing to say, so you assume that?! ahahahahahah \n","========FP=======\n","@user @user are you some like bible banger or tree hugger or something? to like a tweet that doesn't hold parents accountable\n","========FP=======\n","what is the #world coming to? so much #hatred, #anger, and #violence! very   to see and hear about. stay #safe, #love all and #enjoylife\n","========FP=======\n","@user @user @user you best stick to selling younique. you're not a writer but you are a theif.  \n","========FP=======\n"," wakeuppeopl3: duck motherfucker! misinformation, conspiracy    #motivation\n","========FP=======\n","@user what lies these dt suppoers are spreading.  looks like propaganda from the 1930s \n","========FP=======\n","i literally bleed for you. don't fucking tell me you don't want my help. fuck you.   #takeitoutonme #fuck\n","========FP=======\n"," @user if you're   and you know it, you're one of a very small minority of people and everybody else is jealous. so clap hands\n","========FP=======\n","@user _animaladvocate: go to hashtag #milk &amp; all you'll see is #dairy #propaganda.  here are real   #cows at gentle \n","========FP=======\n","@user    cassidy_evans #model  \n","========FP=======\n","justice has been served #bosmatrial   \n","========FP=======\n","#upset   in abbotabad\n","========FP=======\n","@user   reality! #clintonforprison \n","========FP=======\n","@user @user @user women voting for trump are just  \n","========FP=======\n"," #pat robeson: orlando shooting is gods punishment for scotus same-sex marriage ruling   #blog #silver\n","========FP=======\n","#sheisoftenconfused #unfit   #beyondourcontrol @user  this should be the end. \n","========FP=======\n","@user   #stoptheviolence  #pulse the puppets from #themusicofregret @user #abasel2016 \n","========FP=======\n","@user @user grown men getting offended is hilarious. #pussies  \n","========FP=======\n","bosses of @user 4 @user s/b fired! #deadliestplaceoneah 4 the price 2 go-u shld expect 2b safe 4 god's sake! 4c a #boycott soon  \n","========FP=======\n","black and white     \n","========FP=======\n","@user is like a battered woman: \"i love him, i don't expect u 2 understand, u don't have to approve\".   \n","========FP=======\n","journalism is what you do ? \n","========FP=======\n","hey @user prez doesn't like politicians who appear on cable news but presidents on jimmy kimmel and the view are dignified  \n","[['gop', 5, 0.1864406779661017], ['your', 5, 0.05080213903743316], ['see', 5, 0.03945885005636979], ['face', 5, 0.07234042553191489], ['tweet', 4, 0.2455621301775148], ['bihday', 4, 0.0], ['fuck', 4, 0.21608040201005024], ['care', 3, 0.04716981132075472], ['account', 3, 0.06779661016949153], ['youll', 3, None], ['u', 3, 0.07609939138791012], ['pussi', 3, 0.5], ['expect', 3, 0.13636363636363635], ['aliv', 3, 0.09375], ['good', 3, 0.02631578947368421], ['isi', 3, 0.05860805860805861], ['go', 3, 0.046278625954198474], ['rather', 3, 0.02564102564102564], ['sad', 3, 0.0468384074941452], ['orlando', 3, 0.004338394793926247], ['drop', 3, 0.022727272727272728], ['probabl', 3, 0.02857142857142857], ['bitch', 3, 0.10606060606060606], ['w', 3, 0.07617678763923823], ['understand', 3, 0.09375], ['justic', 2, 0.5454545454545454], ['lol', 2, 0.04891304347826087], ['ass', 2, 0.13421828908554573], ['increasingli', 2, None], ['moral', 2, 0.75], ['product', 2, 0.036585365853658534], ['spawn', 2, None], ['could', 2, 0.07602339181286549], ['appl', 2, 0.05333333333333334], ['shock', 2, 0.06521739130434782], ['question', 2, 0.13725490196078433], ['posit', 2, 0.008484848484848486], ['guess', 2, 0.08823529411764706], ['accus', 2, 0.375], ['gun', 2, 0.04430379746835443], ['thing', 2, 0.06157112526539278], ['give', 2, 0.06756756756756757], ['stick', 2, 0.030303030303030304], ['argument', 2, 0.23076923076923078], ['hand', 2, 0.05232558139534884], ['mind', 2, 0.035856573705179286], ['answer', 2, 0.16279069767441862], ['studi', 2, 0.0196078431372549], ['punish', 2, 0.0], ['anger', 2, 0.12658227848101267], ['liter', 2, 0.05263157894736842], ['assum', 2, 0.5], ['play', 2, 0.03416856492027335], ['reason', 2, 0.1702127659574468], ['previou', 2, 0.030303030303030304], ['duck', 2, 0.13333333333333333], ['2', 2, 0.09450436569080636], ['instead', 2, 0.05555555555555555], ['help', 2, 0.07547169811320754], ['friend', 2, 0.013280212483399735], ['told', 2, 0.0975609756097561], ['kid', 2, 0.04150943396226415], ['desper', 2, 0.0], ['feelthebern', 2, 0.0], ['social', 2, 0.13793103448275862], ['blog', 2, 0.0199501246882793], ['vote', 2, 0.36153846153846153], ['safe', 2, 0.04938271604938271], ['order', 2, 0.08270676691729323], ['celebr', 2, 0.03910614525139665], ['bbuk', 2, 0.0], ['propaganda', 2, 0.7], ['father', 2, 0.007863695937090432], ['gay', 2, 0.04827586206896552], ['1', 2, 0.07560296846011132], ['soon', 1, 0.010810810810810811], ['uhadital', 1, None], ['fun', 1, 0.02278481012658228], ['getajob', 1, None], ['reelect', 1, None], ['gamer', 1, 0.0], ['scotu', 1, 0.25], ['dairi', 1, None], ['produc', 1, 0.057692307692307696], ['paid', 1, 0.0625], ['dad', 1, 0.018823529411764704], ['accent', 1, 0.16666666666666666], ['bro', 1, 0.04576659038901602], ['cassidyevan', 1, None], ['husband', 1, 0.06818181818181818], ['baker', 1, 0.0], ['4', 1, 0.06992230854605994], ['suicid', 1, 0.06060606060606061], ['shabbat', 1, 0.5], ['divis', 1, 0.2], ['animaladvoc', 1, 0.0], ['momma', 1, 0.0], ['wink', 1, 0.0], ['justhelp', 1, None], ['syria', 1, 0.375]]\n","\n","\n","\n","FALSE NEGATIVES:\n","\n","========FN=======\n","why does this get so low key of a play when trump's foolish request to change judges got wall to wall coverage? \n","========FN=======\n","2016 is almost over, so ... #bunch #darkest #moviefone #postholiday  #nowthattheholidaysaredone #news \n","========FN=======\n","as us citizens we find ourselves in a period of great contradictions. ie..#fascistdemocracy  seems to be... \n","========FN=======\n","lessons to be learned   why do we...hate?    don't shoot d messenger...just press play ... \n","========FN=======\n","i don't even know what is/isn't  anymore. \n","========FN=======\n","@user and it leads to more violence \n","========FN=======\n","the immature @user is just trying to make a fool of @user   #xenophobe #immature #moron \n","========FN=======\n","@user who the hell is juan to decide if kellyann can raise her kids and work? we've been doing it for years! can't stand \n","========FN=======\n","also #keyboard is  when i type \"cause coopting terrorists\" reg syria it autocorrects to \"cause colored terrorists\"\n","========FN=======\n","no,we can see they have been instrumental in promoting false narrative &amp; abetting divisive blm agenda. \n","========FN=======\n","hmmm...sounds familiar. @user @user @user @user  @user hasn't held a news co \n","========FN=======\n","@user  is not a problem in america today.  #dumbism is.  dumb is an equal oppounity killer of dreams.\n","========FN=======\n","#cologne - keep going stupids, keep commenting - already  30,- donations for #refugeeswelcome  sucks \n","========FN=======\n","aptly named... we have whitesboro in ny with its ndn killing town seal, and whiteland with its mascot \n","========FN=======\n","@user go take your anti  meds\n","========FN=======\n","when the waiter asks @user if he wants to eat the plate aswell... \n","========FN=======\n","a animation by rima regas, blog#42 \n","========FN=======\n","mixed race couples still face  in australia \n","========FN=======\n","@user  ain't hip, trendy. it scalds, it aches, it is chronic, &amp; chokes like smog. ever present but no sees it. it is a\n","========FN=======\n","@user is this your relation? yeah... that's a right... i see you all as the same  \n","========FN=======\n","incredible content! @user @user @user #beforesex  @user @user \n","========FN=======\n","what a stellar year it's been for   \n","========FN=======\n","@user @user i've had these experiences in europe as an american.  is alive and unwell.\n","========FN=======\n","@user has happened far too often  @user\n","========FN=======\n","fox news anchor tells #laurenduca to stick to thigh-high boots rather than politics \n","========FN=======\n","is @user trafficking in ? @user &amp; his \"for profit\" use of the word nigger to sell music @user @user @user\n","========FN=======\n","here's what ignorance &amp;  looks like. it ain't all swastikas &amp; burning crosses... \n","========FN=======\n","i am disgusted watching @user defend her career &amp; intelligence to @user so informing the future gen is laughable?  ..\n","========FN=======\n","@user @user has happened far too often  @user\n","========FN=======\n","'the #mummersparade, by its very dna, is a largely-unrepentant  affair that has no business existing' \n","========FN=======\n","black dad puts  baby mama on blast after he takes their biracial daughter to get braids \n","========FN=======\n","#happy #white #kwanzaa, the #holiday only #african #whitesupremacists #celebrate. #happykwanzaa #happyholidays  #merrychristmas\n","========FN=======\n","@user @user ya he is a real winner  #loser\n","========FN=======\n","white nationalist leader reveals 5 of his most horrifying hopes for #america  #usa  #haters @user\n","========FN=======\n","the latest \"say what?!?!\"  thanks to @user #culturesways \n","========FN=======\n","so, who do you think told those dictionaries what  is?\n","========FN=======\n","@user watch one u.s. #marine fearlessly take on violent angry  mob of pro-palestine protesters ... \n","========FN=======\n","7 ways #facebooks #repoingsystem fails its #communitystandards, its users by @user   #blacklivesmatter\n","========FN=======\n","would be the best thing he has done yet \n","========FN=======\n","@user why is #obamalegacy only showing negative stuff??... i'm so confused.  #obama #potus #donuldtrump\n","========FN=======\n","@user best think i've ever heard about nicola sturgeon. so it can't be true. \n","========FN=======\n","but #carlpalidino can vomit a monster truckload of shit about the #usa #firstfamily and they don't jail him for #hatecrime ?  pigs\n","========FN=======\n","@user i will not buy or dl a @user  book in #2017 after their deal with #whitenationalist #miloyiannopoulos  #wh\n","========FN=======\n","#instagram's #bestfeature when you don't want to read #stupid  #childish #rude #comments  \n","========FN=======\n","if krakow is so beautiful then go &amp; stay there, &amp; let us build our #love &amp; #peace here uk. i have east european  #relatives.  @user\n","========FN=======\n","@user my family's horrible  attack at #thegreenpalmcottage in #plettenburgbay #westerncape thyini thiza! we want t \n","========FN=======\n","#bama #alabama is the most  st. in the south but as long as those #ncaa #dollars roll in you keep #silent on \n","========FN=======\n","#whitenationalist leader reveals 5 of his most horrifying hopes for america   \n","========FN=======\n","haha wow. @user is a  for using the n-word &amp; the equivalent of it in arabic \"abd\" which means slave: \n","========FN=======\n","#bustyescos  haha really great! @user @user @user \n","========FN=======\n","@user @user is good place to sta learning abt how one person can be a  &amp; #bigot #mtvwhiteguys\n","========FN=======\n","#us why weneed #empathy #ageoftrump #grassrootsaction #citizenaction  #citizenry #publicpolicy #socialjustice \n","========FN=======\n","@user just terming ppl as bhakt because they denounce terrorism and anti national acts shows ur sense to reason! never mi \n","========FN=======\n","@user @user only #ass #hole is u in your #head #big hole= #no #brain #hea #love #truth #kindness #peace #compass\n","========FN=======\n","scapelliti:  progresverebel: ha! good riddance! #blacklivesmatter \n","========FN=======\n","good afternoon sweety!  send me letter   \n","========FN=======\n","just saying they would have let a guy fall to the ground and get wailed on for 10 seconds before calling the fight  @user\n","========FN=======\n","those replies.   is dead tho.  \n","========FN=======\n","my family's horrible  attack at #thegreenpalmcottage in #plettenburgbay #westerncape thyini thiza! we want t \n","========FN=======\n","if you think about it you are the  one  we love @user \n","========FN=======\n","one thing i agree with evan on #gop are  #liars #cheaters \n","========FN=======\n"," makes you ask yourself, who am i? then am i anybody? until ....god . oh thank you god!\n","========FN=======\n","@user #auspo;l #hansen #pauline #muslims #senate  chat with maria  \n","========FN=======\n","#happyholidays and try not to be a  this #christmaseve :-d \n","========FN=======\n","@user  tonight in #cologne. proudly presented by goverment, police + media! it's a big staging going on there!\n","========FN=======\n","someone find this man  #stopracism \n","========FN=======\n","one powerful picture. it takes great humanity and kindness to save the life of someone who hates your existence \n","========FN=======\n","new york bistro faces shocking accusations: hosts hid minorities at cramped tables out of sight   \n","========FN=======\n","@user homegrown rightie white americans are 100 times more likely to harm you than a refugee.  #fear\n","========FN=======\n","and again @user - they are flight attendants  #gender #genderequity have a word with your journos  \n","========FN=======\n","@user it's going to be a great year!!! i can't wait till this happens :) #treason #traitorump #liar \n","========FN=======\n","people spit on the face of #god \n","========FN=======\n","like msian opposition and their claim that bangladeshis voted for bn. no evidence yet people believe it anyway \n","========FN=======\n","the cowboys racist. i'm convince fooh. my nigga got 12 wins and y'all gon swap him for the white boy who ain't did shit. \n","========FN=======\n","what over-rode journalists' integrity was greed and ambition, along with a total absence of courage. \n","========FN=======\n","@user it's not just lasses... \n","========FN=======\n","#conormcgregor runs his mouth endlessly like #rondarousey. both have lost. and yet, ppl only take glee in her losing.  perhaps?\n","========FN=======\n","that's why  \n","========FN=======\n","everyone ask @user why they endorse such blatant    @user @user \n","========FN=======\n","shut up rat \n","========FN=======\n","@user everyone ask @user why they endorse such blatant    @user @user \n","========FN=======\n","dear #leftistlunatics, change a few words and tell me how your aicle isn't ? you people are sick. \n","========FN=======\n","a good man or woman is measured by stable relationships with opposite sex. not #money #parenting #homosex  cliches or semantics #2017\n","========FN=======\n","@user boycotting #fathersday because it's blatantly . many #sistersofcolour don't know who their father is, so please #\n","========FN=======\n","that is why  is systemic, rather than just humanity being human. it is power and reinforced each minute!\n","========FN=======\n","4 #whitepeople? all 2 cou. no media coverage. or wp were victims and feared for their lives. maybe probation. #blackperson. who??? \n","========FN=======\n","wew i only know they are diff couples when i look at the guys.   \n","========FN=======\n","obama/jarretts who agenda was to destroy everything good about this country and inflict even bit of hate \n","========FN=======\n","thank you   santa  , for the best christmas present ever #cdnpoli #abpoli #yyc #yeg #canada #ottawa @user \n","========FN=======\n","another  comment on social media!! idiot!!! \n","========FN=======\n","\"the education of public servants is a critical pa of the path forward...\" so true. \n","========FN=======\n","jessica want christmas bdsm       #  #cam\n","========FN=======\n","hello there my love!  i will be glad to see you here   \n","========FN=======\n","girls in the world natt chanapa nu sex fuck \n","========FN=======\n","wow @user was a real  at times back in the day on #smackdown #unitedstateschampion #uschampion #sdlive great more #illegal talk\n","========FN=======\n","it impossible to be  and hateful of someones skin color or social status or gender and believe in #god\n","========FN=======\n","@user you forgot: small hands, orange skin, weird hair, big teeth #sociopath #insanity #misogynist  #bigot \n","========FN=======\n","read and understand how  berniebros chose sanders over hillary    \n","========FN=======\n","#thanks to all those  #dead #white #dudes from #europe.  ain't a #nigga in da #list. blm #rapechucktodd \n","========FN=======\n","the 4th remake of hi-5 doesn't have the token asian chick.    #carolsbycandlelight\n","========FN=======\n","# universityofwisconsinmadison offering #problemofwhiteness course. if they're gonna be blatantly , why not? #snowflakes orgasmic.\n","========FN=======\n","@user obama/jarretts who agenda was to destroy everything good about this country and inflict even bit of hate \n","========FN=======\n","#kindledeals  publishing industry tell-all!  just $3.99!  #bookpublishing #publishing #kindle #kindledeals \n","========FN=======\n","@user #thanks to all those  #dead #white #dudes from #europe.  ain't a #nigga in da #list. blm #rapechucktodd \n","[['blm', 3, 0.8620689655172413], ['thyini', 2, None], ['whitenationalist', 2, 1.0], ['blacklivesmatt', 2, 0.9333333333333333], ['thegreenpalmcottag', 2, None], ['obamajarrett', 2, None], ['coverag', 2, 0.16666666666666666], ['thiza', 2, None], ['inflict', 2, None], ['plettenburgbay', 2, None], ['blatantli', 2, None], ['rapechucktodd', 2, None], ['happyholiday', 2, 0.0], ['anti', 2, 0.39568345323741005], ['westerncap', 2, None], ['refugeeswelcom', 1, 1.0], ['miloyiannopoulo', 1, None], ['existence', 1, None], ['token', 1, 0.0], ['syria', 1, 0.375], ['sdlive', 1, None], ['antenna', 1, 0.0], ['propalestin', 1, None], ['berniebro', 1, 0.0], ['moviefon', 1, None], ['journo', 1, 1.0], ['contradict', 1, 0.0], ['iefascistdemocraci', 1, None], ['ageoftrump', 1, None], ['gender', 1, 0.4444444444444444], ['abpoli', 1, None], ['ndn', 1, 0.058823529411764705], ['sistersofcolour', 1, None], ['autocorrect', 1, None], ['communitystandard', 1, None], ['ncaa', 1, 1.0], ['familiar', 1, 0.75], ['scald', 1, None], ['carolsbycandlelight', 1, None], ['ambit', 1, 0.0], ['kwanzaa', 1, 1.0], ['scapel', 1, 1.0], ['overrod', 1, None], ['compass', 1, None], ['co', 1, None], ['hatecrim', 1, 0.8], ['unwel', 1, None], ['probat', 1, None], ['orgasm', 1, 0.0], ['whitesupremacist', 1, 1.0], ['riddanc', 1, 0.6666666666666666], ['tellal', 1, 0.0], ['gover', 1, 0.23684210526315788], ['beforesex', 1, None], ['arab', 1, 0.38095238095238093], ['merrychristma', 1, 1.0], ['truckload', 1, None], ['endlessli', 1, None], ['bistro', 1, 0.0], ['trendi', 1, 0.029411764705882353], ['jail', 1, 0.5], ['donuldtrump', 1, None], ['christmasev', 1, 1.0], ['smackdown', 1, 0.0], ['wail', 1, None], ['aptli', 1, None], ['vomit', 1, 0.0], ['culturesway', 1, None], ['sweeti', 1, 0.08333333333333333], ['mascot', 1, 0.0], ['kellyann', 1, None], ['blackperson', 1, None], ['postholiday', 1, None], ['wew', 1, 0.0], ['dl', 1, 0.04960835509138381], ['slave', 1, 0.6428571428571429], ['hansen', 1, None], ['messengerjust', 1, None], ['xenophob', 1, 0.7777777777777778], ['bangladeshi', 1, 1.0], ['spit', 1, 0.047619047619047616], ['isisnt', 1, None], ['biraci', 1, None], ['hmmmsound', 1, None], ['publicpolici', 1, None], ['boycot', 1, 0.8947368421052632], ['denounc', 1, 0.8], ['repoingsystem', 1, None], ['choke', 1, 0.25], ['cramp', 1, 0.0], ['laurenduca', 1, None], ['profit', 1, 0.36363636363636365], ['floor', 1, 0.0], ['liar', 1, None], ['clich', 1, 0.0], ['kindled', 1, None], ['absenc', 1, 0.0], ['homosex', 1, 0.5], ['happykwanzaa', 1, None], ['largelyunrepent', 1, None]]\n"]}]},{"cell_type":"code","source":["a = DF_TRAIN[['label','tweet']].values.tolist()\n","a = [item for item in a if 'trump' in item[1]]\n","print(sum([item[0] for item in a])/len(a))\n","#a.loc[DF_TRAIN['label'] == 0]\n","#a.loc[DF_TRAIN['label'] == 1]"],"metadata":{"id":"0KNjJpBJhLMW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653488470438,"user_tz":-120,"elapsed":300,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"}},"outputId":"cbce038a-9020-4136-a4f9-fdb2659ba6a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.515625\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of NN_class.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c5034195ab324e3a998b5561936578d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f61dd1d3fc9b43d08248a885e390fe32","IPY_MODEL_5a31f852939841f0913c8729c5b527b4","IPY_MODEL_482bf293ea4f45c685a4bd7b06004c02"],"layout":"IPY_MODEL_1200a4ac2dc745b88bec26d7ce718e0a"}},"f61dd1d3fc9b43d08248a885e390fe32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c30631e2471f44459d0b4f19e71ad958","placeholder":"","style":"IPY_MODEL_f36819b434674bf7a4f84c6ed04b9072","value":"Downloading builder script: "}},"5a31f852939841f0913c8729c5b527b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d47eb95e8ee641f48ed9c105e7c41585","max":1448,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cd93b7a0891402bbc4ad6e78e716d76","value":1448}},"482bf293ea4f45c685a4bd7b06004c02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8871ffdfaf7947f68a67e06fad0d734a","placeholder":"","style":"IPY_MODEL_00b424ea20a04179b407cb4762e63606","value":" 3.14k/? [00:00&lt;00:00, 34.9kB/s]"}},"1200a4ac2dc745b88bec26d7ce718e0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c30631e2471f44459d0b4f19e71ad958":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f36819b434674bf7a4f84c6ed04b9072":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d47eb95e8ee641f48ed9c105e7c41585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cd93b7a0891402bbc4ad6e78e716d76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8871ffdfaf7947f68a67e06fad0d734a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00b424ea20a04179b407cb4762e63606":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e49d6fb1b5964cca9f9cd9ae9c200bdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52fa91b69db84080aae90178cec58f22","IPY_MODEL_14b98a6c023a4baa90fc7672eebc7aba","IPY_MODEL_b1fe768cf5cd4d4e83ffbf04f0cb525f"],"layout":"IPY_MODEL_0cf33e10c7f24ff7a249289a481d00b1"}},"52fa91b69db84080aae90178cec58f22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14a2b35cf3e143d18ccb5211ac94e896","placeholder":"","style":"IPY_MODEL_518d83c8035d41b2b76e2c36a3d4e36f","value":"Downloading metadata: "}},"14b98a6c023a4baa90fc7672eebc7aba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15d7e23a0a7b467aa95703d12a312203","max":881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1301be2ce7d740359eee40a16ec838b7","value":881}},"b1fe768cf5cd4d4e83ffbf04f0cb525f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f86f28186f04bad90155312e3178307","placeholder":"","style":"IPY_MODEL_5fcdfbff774043e89473e5e72d2682ec","value":" 1.84k/? [00:00&lt;00:00, 27.1kB/s]"}},"0cf33e10c7f24ff7a249289a481d00b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14a2b35cf3e143d18ccb5211ac94e896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"518d83c8035d41b2b76e2c36a3d4e36f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15d7e23a0a7b467aa95703d12a312203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1301be2ce7d740359eee40a16ec838b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f86f28186f04bad90155312e3178307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fcdfbff774043e89473e5e72d2682ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97b70fbd92d34d5f9d04ce5855d78cf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d6c1e260645430ea8113ff56e7c2836","IPY_MODEL_0fdb7db4239a4bc89aa571822397dbc9","IPY_MODEL_9020f4c6b2c8439889cd949f250289f3"],"layout":"IPY_MODEL_43895fcf08e44bd88b508b5a872d15d3"}},"8d6c1e260645430ea8113ff56e7c2836":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0b59da8f114338b18c43dbfb99581b","placeholder":"","style":"IPY_MODEL_2a34750fff6d409c89a5c824c6881418","value":"Downloading data: "}},"0fdb7db4239a4bc89aa571822397dbc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d17b73ef7afe4d8b93afaf809473e99f","max":1276746,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19b79ceba11e444db56177e868d12ff1","value":1276746}},"9020f4c6b2c8439889cd949f250289f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a577ea61f10546d8bc179bcbefbf713d","placeholder":"","style":"IPY_MODEL_17db1040c82347c187a235d5f71c3d8b","value":" 3.10M/? [00:00&lt;00:00, 8.81MB/s]"}},"43895fcf08e44bd88b508b5a872d15d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0b59da8f114338b18c43dbfb99581b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a34750fff6d409c89a5c824c6881418":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d17b73ef7afe4d8b93afaf809473e99f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19b79ceba11e444db56177e868d12ff1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a577ea61f10546d8bc179bcbefbf713d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17db1040c82347c187a235d5f71c3d8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"446ad4db41634458803c4d97737ae7f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22c68324f1c6495eb3c77fbc888839c7","IPY_MODEL_4681f55d639945918c2204cd01b846b0","IPY_MODEL_3eff738120ac42d4a9164f42afe52609"],"layout":"IPY_MODEL_01582952099443be8999f7be8bb6a6a3"}},"22c68324f1c6495eb3c77fbc888839c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d84d7bc06234b74b5dc1f44ee0fd8ff","placeholder":"","style":"IPY_MODEL_064a4b548e5a44cb8ef82d08995f31d5","value":"Generating train split:  99%"}},"4681f55d639945918c2204cd01b846b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c98f97c169b440495442b60fdcb3370","max":31962,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24c4e08aab45465e8dda6b4bdef82240","value":31962}},"3eff738120ac42d4a9164f42afe52609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bff0663c01084195b176bd5c416f8072","placeholder":"","style":"IPY_MODEL_6b80f09d47b44e0ebd55bec5554ac4e7","value":" 31700/31962 [00:02&lt;00:00, 13522.54 examples/s]"}},"01582952099443be8999f7be8bb6a6a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d84d7bc06234b74b5dc1f44ee0fd8ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"064a4b548e5a44cb8ef82d08995f31d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c98f97c169b440495442b60fdcb3370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24c4e08aab45465e8dda6b4bdef82240":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bff0663c01084195b176bd5c416f8072":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b80f09d47b44e0ebd55bec5554ac4e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea157a5c9c524768b9ab7c0d0d238f73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d4ae5a866c348e59b411c9fbed24fa1","IPY_MODEL_abbd3372dcb54220bffef2250ceab0a4","IPY_MODEL_4701685f5d9d410ab8924158cc1a135f"],"layout":"IPY_MODEL_90d768e78fd747ff9f0bae9ec60430ce"}},"8d4ae5a866c348e59b411c9fbed24fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36c1be22a06e4ec0b45d28b26decef39","placeholder":"","style":"IPY_MODEL_a12fe6ebdced4e63b4fa39cee396c472","value":"100%"}},"abbd3372dcb54220bffef2250ceab0a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_305700f369b24455a420597c0b58ba82","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f90d8e71c253484cab3e6694c09c8705","value":1}},"4701685f5d9d410ab8924158cc1a135f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fbd47d7afb2407f95c982fc13ee0065","placeholder":"","style":"IPY_MODEL_c056696bbcfd42b1870fe7f1418b4441","value":" 1/1 [00:00&lt;00:00,  9.20it/s]"}},"90d768e78fd747ff9f0bae9ec60430ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c1be22a06e4ec0b45d28b26decef39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a12fe6ebdced4e63b4fa39cee396c472":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"305700f369b24455a420597c0b58ba82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f90d8e71c253484cab3e6694c09c8705":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fbd47d7afb2407f95c982fc13ee0065":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c056696bbcfd42b1870fe7f1418b4441":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}